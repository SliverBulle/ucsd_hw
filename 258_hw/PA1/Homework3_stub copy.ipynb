{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "301bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "userPerItem = defaultdict(set)\n",
    "itemPerUser = defaultdict(set)\n",
    "for u,b,r in allRatings:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    userPerItem[b].add(u)\n",
    "    itemPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead*0.7: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45dfa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in[12] 定义负采样函数\n",
    "def sample_negative(user, positive_books, all_books, num_samples=1):\n",
    "    negative_samples = []\n",
    "    while len(negative_samples) < num_samples:\n",
    "        neg_book = random.choice(all_books)\n",
    "        if neg_book not in positive_books:\n",
    "            negative_samples.append(neg_book)\n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0711caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in[13] 构建验证集\n",
    "validation_positive = ratingsValid\n",
    "validation_negative = []\n",
    "all_books = list(bookCount.keys())\n",
    "\n",
    "user_positive_books = defaultdict(set)\n",
    "for u, b, r in ratingsTrain:\n",
    "    user_positive_books[u].add(b)\n",
    "\n",
    "for u, b, r in validation_positive:\n",
    "    negative_books = sample_negative(u, user_positive_books[u], all_books)\n",
    "    for neg_b in negative_books:\n",
    "        validation_negative.append((u, neg_b, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672a9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并正负样本\n",
    "validation_set = [(u, b, 1) for u, b, r in validation_positive] + validation_negative\n",
    "\n",
    "# in[14] 评估基线模型的准确率\n",
    "def evaluate_baseline(validation_set, mostPopular_set):\n",
    "    correct = 0\n",
    "    for u, b, label in validation_set:\n",
    "        prediction = 1 if b in mostPopular_set else 0\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(validation_set)\n",
    "    return accuracy\n",
    "\n",
    "acc1 = evaluate_baseline(validation_set, return1)\n",
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba5ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71295\n"
     ]
    }
   ],
   "source": [
    "print(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6839df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50491907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in[16] 寻找最佳阈值\n",
    "def find_best_threshold(book_counts, total_read, validation_set):\n",
    "    thresholds = sorted(book_counts.values())\n",
    "    best_acc = 0\n",
    "    best_threshold = thresholds[0]\n",
    "    for threshold in thresholds:\n",
    "        popular_set = set([book for book, count in book_counts.items() if count >= threshold])\n",
    "        acc = evaluate_baseline(validation_set, popular_set)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "threshold, acc2 = find_best_threshold(bookCount, totalRead, validation_set)\n",
    "answers['Q2'] = [threshold, acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_threshold = set()\n",
    "count = 0\n",
    "\n",
    "threshold = 0.01*threshold\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return_threshold.add(i)\n",
    "    if count > totalRead*threshold: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55592cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 0.7586]\n"
     ]
    }
   ],
   "source": [
    "print(answers['Q2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [threshold, acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcb6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b753559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1, s2):\n",
    "    intersection = s1 & s2\n",
    "    union = s1 | s2\n",
    "    if not union:\n",
    "        return 0\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4e24514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_jaccard(validation_set, ratingsPerUser, ratingsPerItem, threshold):\n",
    "    correct = 0\n",
    "    for u, b, label in validation_set:\n",
    "        read_items = [item for item, r in ratingsPerUser[u]]\n",
    "        similarities = [jaccard_similarity(userPerItem[b], userPerItem[b_prime]) for b_prime in read_items]\n",
    "        max_similarity = max(similarities) if similarities else 0\n",
    "        prediction = 1 if max_similarity > threshold else 0\n",
    "        if prediction == 0:\n",
    "            users = [user for user, r in ratingsPerItem[b]]\n",
    "            user_similarities = [jaccard_similarity(itemPerUser[b], itemPerUser[user]) for user in users]\n",
    "            max_user_similarity = max(user_similarities) if user_similarities else 0\n",
    "            prediction = 1 if max_user_similarity > threshold else 0\n",
    "        popularity_pred = 1 if b in return1 else 0\n",
    "        prediction = 1 if max(popularity_pred, prediction) else 0\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(validation_set)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "178350dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "def find_best_jaccard_threshold(validation_set, ratingsPerUser, ratingsPerItem):\n",
    "    thresholds = [i * 0.001 for i in range(110, 116,1)]\n",
    "    best_acc = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in tqdm.tqdm(thresholds):\n",
    "        acc = evaluate_jaccard(validation_set, ratingsPerUser, ratingsPerItem, threshold)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "threshold_jaccard, acc3 = find_best_jaccard_threshold(validation_set, ratingsPerUser, ratingsPerItem)\n",
    "answers['Q3'] = acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d10e01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.112 0.9083\n"
     ]
    }
   ],
   "source": [
    "print(threshold_jaccard,acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "feeaa7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09 1.0\n"
     ]
    }
   ],
   "source": [
    "# in[24] 结合 Jaccard 和流行度阈值\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_combined(validation_set, mostPopular_set, ratingsPerUser, ratingsPerItem, jaccard_threshold):\n",
    "    correct = 0\n",
    "    features = []\n",
    "    labels = []\n",
    "    for u, b, label in validation_set:\n",
    "        popularity_pred = 1 if b in mostPopular_set else 0\n",
    "        read_items = [item for item, r in ratingsPerUser[u]]\n",
    "        similarities = [jaccard_similarity(b, b_prime, ratingsPerItem) for b_prime in read_items]\n",
    "        if similarities:\n",
    "            jaccard_pred = 1 if max(similarities) > jaccard_threshold else 0\n",
    "        else:\n",
    "            jaccard_pred = 0\n",
    "\n",
    "        users = [user for user, r in ratingsPerItem[b]]\n",
    "        user_similarity = [jaccard_similarity(u, u_prime, ratingsPerUser) for u_prime in users]\n",
    "        max_user_similarity = int(max(user_similarity)>jaccard_threshold) if user_similarity else 0\n",
    "        user_pred = 1 if max_user_similarity > jaccard_threshold else 0 \n",
    "\n",
    "        features.append([popularity_pred, jaccard_pred, user_pred])\n",
    "        labels.append(label)\n",
    "    df_features = pd.DataFrame(features, columns=['popularity', 'similarity', 'user_similarity'])\n",
    "    df_labels = pd.Series(labels, name='label')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_features, df_labels, test_size=0.2, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy,clf\n",
    "\n",
    "# 找到最佳组合阈值\n",
    "def find_best_combined_threshold(validation_set, mostPopular_set, ratingsPerUser, ratingsPerItem):\n",
    "    thresholds = [i * 0.01 for i in range(0, 21)]\n",
    "    best_acc = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in tqdm.tqdm(thresholds):\n",
    "        acc = evaluate_combined(validation_set, mostPopular_set, ratingsPerUser, ratingsPerItem, threshold)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "#threshold_combined, acc4 = find_best_combined_threshold(validation_set, return_threshold, ratingsPerUser, ratingsPerItem)\n",
    "answers['Q4'] = acc4\n",
    "print(threshold_combined,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0920756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09 1.0\n"
     ]
    }
   ],
   "source": [
    "print(threshold_combined,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38c755cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,clf = evaluate_combined(validation_set, return_threshold, ratingsPerUser, ratingsPerItem, threshold_combined)\n",
    "with open(\"predictions_Read.csv\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, b = l.strip().split(',')\n",
    "        # 使用结合后的模型进行预测\n",
    "        popularity_pred = 1 if b in return_threshold else 0\n",
    "\n",
    "        read_items = [item for item, r in ratingsPerUser[u]]\n",
    "        similarities = [jaccard_similarity(b, b_prime, ratingsPerItem) for b_prime in read_items]\n",
    "        max_similarity = max(similarities) if similarities else 0\n",
    "        jaccard_pred = 1 if max_similarity > threshold_combined else 0\n",
    "\n",
    "        users = [user for user, r in ratingsPerItem[b]]\n",
    "        user_similarity = [jaccard_similarity(u, u_prime, ratingsPerUser) for u_prime in users]\n",
    "        max_user_similarity = max(user_similarity) if user_similarity else 0 \n",
    "        user_pred = 1 if max_user_similarity > threshold_combined else 0\n",
    "\n",
    "        prediction = clf.predict([[popularity_pred, jaccard_pred, user_pred]])\n",
    "        predictions.write(f\"{u},{b},{prediction[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e0ebe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集成方法验证集准确率: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 构建特征和标签\n",
    "features = []\n",
    "labels = []\n",
    "for u, b, label in validation_set:\n",
    "    # 流行度特征\n",
    "    popularity = 1 if b in return_threshold else 0\n",
    "    # 相似度特征\n",
    "    read_items = [item for item, r in ratingsPerUser[u]]\n",
    "    similarities = [jaccard_similarity(b, b_prime, ratingsPerItem) for b_prime in read_items]\n",
    "    similarity = max(similarities) if similarities else 0\n",
    "    # 添加到特征列表\n",
    "    features.append([popularity, similarity])\n",
    "    labels.append(label)\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df_features = pd.DataFrame(features, columns=['popularity', 'similarity'])\n",
    "df_labels = pd.Series(labels, name='label')\n",
    "\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_features, df_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练随机森林分类器\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred = clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"集成方法验证集准确率: {accuracy:.4f}\")\n",
    "\n",
    "# 更新答案字典\n",
    "answers['Q4_ensemble'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33071557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict([[1, 0.9,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfad2b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 0.75025\n"
     ]
    }
   ],
   "source": [
    "print(threshold_combined,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83ab0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbdd0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in[26] 生成 predictions_Read.csv\n",
    "with open(\"predictions_Read.csv\", 'w') as predictions:\n",
    "    for l in open(\"pairs_Read.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        u, b = l.strip().split(',')\n",
    "        # 使用结合后的模型进行预测\n",
    "        popularity_pred = 1 if b in return1 else 0\n",
    "        read_items = [item for item, r in ratingsPerUser[u]]\n",
    "        similarities = [jaccard_similarity(b, b_prime, ratingsPerItem) for b_prime in read_items]\n",
    "        if similarities:\n",
    "            jaccard_pred = 1 if max(similarities) > 0.09 else 0\n",
    "        else:\n",
    "            jaccard_pred = 0\n",
    "        prediction = 1 if max(popularity_pred, jaccard_pred) else 0\n",
    "        predictions.write(f\"{u},{b},{prediction}\\n\")\n",
    "\n",
    "# 将答案提交到 Gradescope\n",
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3cb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bcf70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
