{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a6d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://cseweb.ucsd.edu/classes/fa24/cse258-b/files/steam.json.gz\n",
    "z = gzip.open(\"data/steam.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2ef14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in z:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a06fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e18445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hours': 0.3,\n",
       " 'gameID': 'g35322304',\n",
       " 'hours_transformed': 0.37851162325372983,\n",
       " 'early_access': False,\n",
       " 'date': '2015-04-08',\n",
       " 'text': '+1',\n",
       " 'userID': 'u55351001'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e80cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37e48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def MSE(y, ypred):\n",
    "    return mean_squared_error(y, ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90c72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def feat1(d):\n",
    "import numpy as np\n",
    "def feat1(X,y):\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b79820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[len(data[\"text\"])] for data in dataset])\n",
    "y = np.array([data['hours'] for data in dataset])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9beef925",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = feat1(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed47adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse1 = MSE(y, mod.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3907759f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00104228])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32ed5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [float(mod.coef_[0]), float(mse1)] # Remember to cast things to float rather than (e.g.) np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0b7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e26bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a2aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = dataset[:int(len(dataset)*0.8)]\n",
    "dataTest = dataset[int(len(dataset)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e5094b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[len(data[\"text\"])] for data in dataTrain])\n",
    "y_train = np.array([data['hours'] for data in dataTrain])  \n",
    "X_test = np.array([[len(data[\"text\"])] for data in dataTest])\n",
    "y_test = np.array([data['hours'] for data in dataTest])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89ec0d0b-54be-4e77-9970-ce32d30c787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = feat1(X_train,y_train)\n",
    "y_pred = mod2.predict(X_test)\n",
    "mse2 = MSE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0620a9b-f9e9-4c43-846d-5d66eb0254b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "under = 0\n",
    "over = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] > y_pred[i]:\n",
    "        under += 1\n",
    "    elif y_test[i] < y_pred[i]:\n",
    "        over += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f55430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5249 29751\n"
     ]
    }
   ],
   "source": [
    "print(under, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a5d7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [mse2, under, over]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad4744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a690f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fccd01-77e6-450b-976b-096a9d5dd01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e524edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a\n",
    "y2 = y[:]\n",
    "y2.sort()\n",
    "perc90 = y2[int(len(y2)*0.9)] # 90th percentile\n",
    "\n",
    "X3a = []\n",
    "y3a = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] <= perc90:\n",
    "        X3a.append(X_train[i])\n",
    "        y3a.append(y_train[i])\n",
    "mod3a = linear_model.LinearRegression()\n",
    "mod3a.fit(X3a,y3a)\n",
    "pred3a = mod3a.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90de762d-2a60-4e3b-ba47-8f8d71a7936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "under3a = sum(y_test[i] > pred3a[i] for i in range(len(y_test)))\n",
    "over3a = sum(y_test[i] <= pred3a[i] for i in range(len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6a7160f-3836-4a36-be1b-4bb928c08f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc. for 3b and 3c\n",
    "y3b = np.array([d[\"hours_transformed\"] for d in dataset])\n",
    "X3b = X[:]\n",
    "\n",
    "Xtrain3b = X3b[:int(len(X3b)*0.8)]\n",
    "ytrain3b = y3b[:int(len(y3b)*0.8)]\n",
    "Xtest3b = X3b[int(len(X3b)*0.8):]\n",
    "ytest3b = y3b[int(len(y3b)*0.8):]\n",
    "\n",
    "mod3b = linear_model.LinearRegression()\n",
    "mod3b.fit(Xtrain3b,ytrain3b)\n",
    "pred3b = mod3b.predict(Xtest3b)\n",
    "under3b = sum(ytest3b[i] >= pred3b[i] for i in range(len(ytest3b)))\n",
    "over3b = sum(ytest3b[i] < pred3b[i] for i in range(len(ytest3b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f50dd269-673b-4706-9d25-fb5a1ffdcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3c\n",
    "theta0 = mod2.intercept_  \n",
    "\n",
    "\n",
    "median_length = np.median([len(d[\"text\"]) for d in dataTrain])\n",
    "median_hours = np.median([d[\"hours\"] for d in dataTrain])\n",
    "\n",
    "theta1 = (median_hours - theta0) / median_length\n",
    "\n",
    "pred3c = theta0 + theta1 * X_test.reshape(-1)\n",
    "\n",
    "\n",
    "under3c = sum(y_test[i] >= pred3c[i] for i in range(len(y_test)))\n",
    "over3c = sum(y_test[i] < pred3c[i] for i in range(len(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "017eeef8-6a78-4872-b6b5-b297abe6213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = [under3a, over3a, under3b, over3b, under3c, over3c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3e8c251-70ea-4213-a384-f684476772e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3'], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15645595-b793-42ae-bf08-51ed4aa11b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10b65330-4eb3-4ce8-a43f-ec7b2b23f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1 if d[\"hours\"] > median_hours else 0 for d in dataset])\n",
    "ytest = np.array([1 if d[\"hours\"] > median_hours else 0 for d in dataTest])\n",
    "\n",
    "X = np.array([[len(d[\"text\"])] for d in dataset])\n",
    "Xtest = np.array([[len(d[\"text\"])] for d in dataTest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0968ced0-1b35-4032-b4bf-ee4d0c32182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod4 = linear_model.LogisticRegression(C=1)\n",
    "mod4.fit(X,y)\n",
    "predictions = mod4.predict(Xtest) # Binary vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82e3f6ec-8911-4249-927e-c78dc891197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4550 13873 3677 12900 0.47362857142857145\n"
     ]
    }
   ],
   "source": [
    "TP = sum((predictions == 1) & (ytest == 1))\n",
    "TN = sum((predictions == 0) & (ytest == 0))\n",
    "FP = sum((predictions == 1) & (ytest == 0))\n",
    "FN = sum((predictions == 0) & (ytest == 1))\n",
    "BER = (FP + FN) / (TP + TN + FP + FN)\n",
    "print(TP, TN, FP, FN, BER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33548639-8b44-402d-940f-256ace3e35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87e91291-ab44-49b9-8965-9ac820877740",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b357a12a-a71c-4562-a407-5fdaaece6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd34df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "under5 = FP\n",
    "over5 = FN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9094734d-209b-44ac-8459-2bcbc8d25e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = [under5, over5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d05f199-a588-44f8-9ea5-5764b957e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b4a2fd5-6773-4bc2-90ee-faeb629c6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01bd99c6-acc7-4d85-81a1-9da9a14bd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#6a\n",
    "X2014 = np.array([[len(d[\"text\"])] for d in dataset if int(d[\"date\"][:4]) <= 2014])\n",
    "y2014 = np.array([1 if d[\"hours\"] > median_hours else 0 for d in dataset if int(d[\"date\"][:4]) <= 2014])\n",
    "\n",
    "X2014train = X2014[:int(len(X2014)*0.8)]\n",
    "y2014train = y2014[:int(len(y2014)*0.8)]\n",
    "X2014test = X2014[int(len(X2014)*0.8):]\n",
    "y2014test = y2014[int(len(y2014)*0.8):]\n",
    "\n",
    "mod6a = linear_model.LogisticRegression(C=1)\n",
    "mod6a.fit(X2014train,y2014train)\n",
    "pred6a = mod6a.predict(X2014test)\n",
    "\n",
    "cm6a = confusion_matrix(y2014test, pred6a)\n",
    "BER_A = (cm6a[0][1] + cm6a[1][0]) / (cm6a[0][0] + cm6a[1][1] + cm6a[0][1] + cm6a[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f05b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6b\n",
    "X2015 = np.array([[len(d[\"text\"])] for d in dataset if int(d[\"date\"][:4]) > 2014])\n",
    "y2015 = np.array([1 if d[\"hours\"] > median_hours else 0 for d in dataset if int(d[\"date\"][:4]) > 2014])\n",
    "\n",
    "X2015train = X2015[:int(len(X2015)*0.8)]\n",
    "y2015train = y2015[:int(len(y2015)*0.8)]\n",
    "X2015test = X2015[int(len(X2015)*0.8):]\n",
    "y2015test = y2015[int(len(y2015)*0.8):]\n",
    "\n",
    "mod6b = linear_model.LogisticRegression(C=1)\n",
    "mod6b.fit(X2015train,y2015train)\n",
    "pred6b = mod6b.predict(X2015test)\n",
    "cm6b = confusion_matrix(y2015test, pred6b)\n",
    "BER_B = (cm6b[0][1] + cm6b[1][0]) / (cm6b[0][0] + cm6b[1][1] + cm6b[0][1] + cm6b[1][0])\n",
    "\n",
    "#6c\n",
    "mod6c = linear_model.LogisticRegression(C=1)\n",
    "mod6c.fit(X2014,y2014)\n",
    "pred6c = mod6c.predict(X2015)\n",
    "cm6c = confusion_matrix(y2015, pred6c)\n",
    "BER_C = (cm6c[0][1] + cm6c[1][0]) / (cm6c[0][0] + cm6c[1][1] + cm6c[0][1] + cm6c[1][0])\n",
    "\n",
    "#6d\n",
    "mod6d = linear_model.LogisticRegression(C=1)\n",
    "mod6d.fit(X2015,y2015)\n",
    "pred6d = mod6d.predict(X2014)\n",
    "cm6d = confusion_matrix(y2014, pred6d)\n",
    "BER_D = (cm6d[0][1] + cm6d[1][0]) / (cm6d[0][0] + cm6d[1][1] + cm6d[0][1] + cm6d[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77349259-dc23-4051-a7af-d8becaf9a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = [BER_A, BER_B, BER_C, BER_D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6530d65-871b-40bc-8bd5-7b1f64e00402",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q6'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b4c89bb-4a6e-4ff4-8178-a8519bb72151",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a7f0b9c-307d-4376-aabc-300882bb71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "\n",
    "\n",
    "for d in dataTrain:\n",
    "    usersPerItem[d[\"gameID\"]].add(d[\"userID\"])\n",
    "    itemsPerUser[d[\"userID\"]].add(d[\"gameID\"])\n",
    "    reviewsPerUser[d[\"userID\"]].append(d)\n",
    "    reviewsPerItem[d[\"gameID\"]].append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c59b51b-4d40-489f-8f02-6c7b646be571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48f2a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(user, N):\n",
    "    similarities = []\n",
    "    items = itemsPerUser[user]\n",
    "    for u2 in itemsPerUser:\n",
    "        if u2 == user: continue\n",
    "        sim = Jaccard(items, itemsPerUser[u2])\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c40046cf-4900-4efb-b161-60e62dd0705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = similarity(dataset[0][\"userID\"], 10)\n",
    "first = sim[0][0]\n",
    "tenth = sim[9][0]\n",
    "\n",
    "answers['Q7'] = [first, tenth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2943745-40c5-44ae-9464-89603b0b62f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de1c320a-37b2-42e3-9362-4294b31047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "358db1e9-d9ad-432e-a233-74dc1ab44279",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = np.mean([d[\"hours_transformed\"] for d in dataTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7681c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_based(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return global_mean\n",
    "    hours  = []\n",
    "    similarities  = []\n",
    "    #v is users who comment on game i \n",
    "    for d in reviewsPerItem[item]:\n",
    "        v = d[\"userID\"]\n",
    "        if v == user:\n",
    "            continue\n",
    "        hours.append(d[\"hours_transformed\"])\n",
    "        similarities.append(Jaccard(itemsPerUser[user],itemsPerUser[v]))\n",
    "\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(hours,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        return global_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41c1dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_item_based(item, user):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return global_mean\n",
    "    hours = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d[\"gameID\"]\n",
    "        hours.append(d[\"hours_transformed\"])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(hours,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        return global_mean\n",
    "predictionsUser = []\n",
    "actualsUser = []\n",
    "for d in dataTest:\n",
    "    pred = predict_user_based(d[\"userID\"], d[\"gameID\"])\n",
    "    predictionsUser.append(pred)\n",
    "    actualsUser.append(d[\"hours_transformed\"])\n",
    "\n",
    "MSEU = mean_squared_error(actualsUser, predictionsUser)\n",
    "\n",
    "predictionsItem = []\n",
    "actualsItem = []\n",
    "for d in dataTest:\n",
    "    pred = predict_item_based(d[\"gameID\"], d[\"userID\"])\n",
    "    predictionsItem.append(pred)\n",
    "    actualsItem.append(d[\"hours_transformed\"])\n",
    "MSEI = mean_squared_error(actualsItem, predictionsItem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d2d046-6faa-4a73-ae47-f013aaa51d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = [MSEU, MSEI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecffcfba-394a-4b79-be85-c7c5ca7a3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q8'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2adb115b-2007-47a6-a29f-096f287cf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16be0fa6-d7c9-459c-bf94-7ccd84fa24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time_weighted(user, item):\n",
    "    if user not in itemsPerUser or item not in usersPerItem:\n",
    "        return global_mean\n",
    "    hours  = []\n",
    "    similarities  = []\n",
    "    e_list = []\n",
    "    for d in reviewsPerItem[item]:\n",
    "        v = d[\"userID\"]\n",
    "        if v == user:\n",
    "            continue\n",
    "        hours.append(d[\"hours_transformed\"])\n",
    "        similarities.append(Jaccard(itemsPerUser[user],itemsPerUser[v]))\n",
    "        data_u = [int(reviewsPerUser[user][i][\"date\"][:4]) for i in range(len(reviewsPerUser[user])) if reviewsPerUser[user][i][\"gameID\"] == item]        \n",
    "        if not data_u:\n",
    "            data_u = [int(d[\"date\"][:4])]\n",
    "        \n",
    "        e = math.exp(-abs(data_u[0] - int(d[\"date\"][:4])))\n",
    "        e_list.append(e)\n",
    "\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y*e) for x,y,e in zip(hours,similarities,e_list)]\n",
    "        similarities = [e*y for e,y in zip(e_list,similarities)]\n",
    "        return sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        return global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74faf00b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79b5e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "for d in dataTest:\n",
    "    pred = predict_time_weighted(d[\"userID\"], d[\"gameID\"])\n",
    "    predictions.append(pred)\n",
    "    actuals.append(d[\"hours_transformed\"])\n",
    "\n",
    "MSE9 = mean_squared_error(actuals, predictions)\n",
    "answers['Q9'] = MSE9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a321b8c9-56de-4b34-bbcf-2552bc5d4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q9'] = MSE9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17374d80-9ab3-4877-845e-836524d8aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de71bdd6-92d8-430d-b419-7e37e3ddc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"float\" in str(answers) or \"int\" in str(answers):\n",
    "    print(\"it seems that some of your answers are not native python ints/floats;\")\n",
    "    print(\"the autograder will not be able to read your solution unless you convert them to ints/floats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3fb9831-179f-4354-b4f0-48a4ea5b767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
