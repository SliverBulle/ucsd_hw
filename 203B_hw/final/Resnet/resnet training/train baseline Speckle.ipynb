{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c44bf7-acb0-481c-88cf-03e9298a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/DnCNN_sigma4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, args\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(sigma))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_dir):\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDnCNN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/DnCNN_sigma4'"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '64', '--train_data', 'data/Train400', '--sigma', '4', '--epoch', '3', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=3, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "        \n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, out_channels=64, in_channels=1, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_layers = []\n",
    "        for _ in range(10):\n",
    "            for sub in self.make_Residual():\n",
    "                output_layers.append(sub)\n",
    "        self.out = nn.Sequential(*output_layers)\n",
    "        self.res = nn.Conv2d(64, 1, kernel_size=3, padding=1, stride=1)\n",
    "        \n",
    "    def make_Residual(self, in_channels=64, out_channels=64, kernel_size=3):\n",
    "        i = 0\n",
    "        layers = []\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, bias=True))\n",
    "            layers.append(nn.BatchNorm2d(64, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return layers\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.relu(self.BN(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.res(out)\n",
    "        return dn\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^-training data finished-^_^\n",
      "   1    0 / 2728 loss = 85.9471\n",
      "   1   10 / 2728 loss = 2.1606\n",
      "   1   20 / 2728 loss = 0.4749\n",
      "   1   30 / 2728 loss = 0.1781\n",
      "   1   40 / 2728 loss = 0.1614\n",
      "   1   50 / 2728 loss = 0.1119\n",
      "   1   60 / 2728 loss = 0.0978\n",
      "   1   70 / 2728 loss = 0.0800\n",
      "   1   80 / 2728 loss = 0.0704\n",
      "   1   90 / 2728 loss = 0.0792\n",
      "   1  100 / 2728 loss = 0.1086\n",
      "   1  110 / 2728 loss = 0.0731\n",
      "   1  120 / 2728 loss = 0.0676\n",
      "   1  130 / 2728 loss = 0.0673\n",
      "   1  140 / 2728 loss = 0.0854\n",
      "   1  150 / 2728 loss = 0.0631\n",
      "   1  160 / 2728 loss = 0.0723\n",
      "   1  170 / 2728 loss = 0.0736\n",
      "   1  180 / 2728 loss = 0.0583\n",
      "   1  190 / 2728 loss = 0.0807\n",
      "   1  200 / 2728 loss = 0.0583\n",
      "   1  210 / 2728 loss = 0.0612\n",
      "   1  220 / 2728 loss = 0.0556\n",
      "   1  230 / 2728 loss = 0.0656\n",
      "   1  240 / 2728 loss = 0.0698\n",
      "   1  250 / 2728 loss = 0.0646\n",
      "   1  260 / 2728 loss = 0.0827\n",
      "   1  270 / 2728 loss = 0.0564\n",
      "   1  280 / 2728 loss = 0.0583\n",
      "   1  290 / 2728 loss = 0.0698\n",
      "   1  300 / 2728 loss = 0.0609\n",
      "   1  310 / 2728 loss = 0.0609\n",
      "   1  320 / 2728 loss = 0.0504\n",
      "   1  330 / 2728 loss = 0.0846\n",
      "   1  340 / 2728 loss = 0.0655\n",
      "   1  350 / 2728 loss = 0.0641\n",
      "   1  360 / 2728 loss = 0.0608\n",
      "   1  370 / 2728 loss = 0.0607\n",
      "   1  380 / 2728 loss = 0.0549\n",
      "   1  390 / 2728 loss = 0.0594\n",
      "   1  400 / 2728 loss = 0.0567\n",
      "   1  410 / 2728 loss = 0.0671\n",
      "   1  420 / 2728 loss = 0.0528\n",
      "   1  430 / 2728 loss = 0.0593\n",
      "   1  440 / 2728 loss = 0.0592\n",
      "   1  450 / 2728 loss = 0.0552\n",
      "   1  460 / 2728 loss = 0.0513\n",
      "   1  470 / 2728 loss = 0.0727\n",
      "   1  480 / 2728 loss = 0.0659\n",
      "   1  490 / 2728 loss = 0.0513\n",
      "   1  500 / 2728 loss = 0.0522\n",
      "   1  510 / 2728 loss = 0.0525\n",
      "   1  520 / 2728 loss = 0.0512\n",
      "   1  530 / 2728 loss = 0.0483\n",
      "   1  540 / 2728 loss = 0.0451\n",
      "   1  550 / 2728 loss = 0.0591\n",
      "   1  560 / 2728 loss = 0.0548\n",
      "   1  570 / 2728 loss = 0.0623\n",
      "   1  580 / 2728 loss = 0.0736\n",
      "   1  590 / 2728 loss = 0.0547\n",
      "   1  600 / 2728 loss = 0.0500\n",
      "   1  610 / 2728 loss = 0.0530\n",
      "   1  620 / 2728 loss = 0.0544\n",
      "   1  630 / 2728 loss = 0.0660\n",
      "   1  640 / 2728 loss = 0.0496\n",
      "   1  650 / 2728 loss = 0.0456\n",
      "   1  660 / 2728 loss = 0.0536\n",
      "   1  670 / 2728 loss = 0.0488\n",
      "   1  680 / 2728 loss = 0.0522\n",
      "   1  690 / 2728 loss = 0.0525\n",
      "   1  700 / 2728 loss = 0.0566\n",
      "   1  710 / 2728 loss = 0.0667\n",
      "   1  720 / 2728 loss = 0.0458\n",
      "   1  730 / 2728 loss = 0.0564\n",
      "   1  740 / 2728 loss = 0.0605\n",
      "   1  750 / 2728 loss = 0.0463\n",
      "   1  760 / 2728 loss = 0.0548\n",
      "   1  770 / 2728 loss = 0.0477\n",
      "   1  780 / 2728 loss = 0.0517\n",
      "   1  790 / 2728 loss = 0.0562\n",
      "   1  800 / 2728 loss = 0.0562\n",
      "   1  810 / 2728 loss = 0.0490\n",
      "   1  820 / 2728 loss = 0.0497\n",
      "   1  830 / 2728 loss = 0.0479\n",
      "   1  840 / 2728 loss = 0.0484\n",
      "   1  850 / 2728 loss = 0.0582\n",
      "   1  860 / 2728 loss = 0.0452\n",
      "   1  870 / 2728 loss = 0.0574\n",
      "   1  880 / 2728 loss = 0.0576\n",
      "   1  890 / 2728 loss = 0.0522\n",
      "   1  900 / 2728 loss = 0.0546\n",
      "   1  910 / 2728 loss = 0.0569\n",
      "   1  920 / 2728 loss = 0.0496\n",
      "   1  930 / 2728 loss = 0.0434\n",
      "   1  940 / 2728 loss = 0.0538\n",
      "   1  950 / 2728 loss = 0.0611\n",
      "   1  960 / 2728 loss = 0.0510\n",
      "   1  970 / 2728 loss = 0.0551\n",
      "   1  980 / 2728 loss = 0.0500\n",
      "   1  990 / 2728 loss = 0.0481\n",
      "   1 1000 / 2728 loss = 0.0530\n",
      "   1 1010 / 2728 loss = 0.0490\n",
      "   1 1020 / 2728 loss = 0.0519\n",
      "   1 1030 / 2728 loss = 0.0518\n",
      "   1 1040 / 2728 loss = 0.0513\n",
      "   1 1050 / 2728 loss = 0.0547\n",
      "   1 1060 / 2728 loss = 0.0541\n",
      "   1 1070 / 2728 loss = 0.0497\n",
      "   1 1080 / 2728 loss = 0.0509\n",
      "   1 1090 / 2728 loss = 0.0491\n",
      "   1 1100 / 2728 loss = 0.0626\n",
      "   1 1110 / 2728 loss = 0.0509\n",
      "   1 1120 / 2728 loss = 0.0512\n",
      "   1 1130 / 2728 loss = 0.0470\n",
      "   1 1140 / 2728 loss = 0.0512\n",
      "   1 1150 / 2728 loss = 0.0493\n",
      "   1 1160 / 2728 loss = 0.0488\n",
      "   1 1170 / 2728 loss = 0.0476\n",
      "   1 1180 / 2728 loss = 0.0549\n",
      "   1 1190 / 2728 loss = 0.0551\n",
      "   1 1200 / 2728 loss = 0.0492\n",
      "   1 1210 / 2728 loss = 0.0571\n",
      "   1 1220 / 2728 loss = 0.0480\n",
      "   1 1230 / 2728 loss = 0.0515\n",
      "   1 1240 / 2728 loss = 0.0536\n",
      "   1 1250 / 2728 loss = 0.0503\n",
      "   1 1260 / 2728 loss = 0.0439\n",
      "   1 1270 / 2728 loss = 0.0529\n",
      "   1 1280 / 2728 loss = 0.0451\n",
      "   1 1290 / 2728 loss = 0.0465\n",
      "   1 1300 / 2728 loss = 0.0515\n",
      "   1 1310 / 2728 loss = 0.0480\n",
      "   1 1320 / 2728 loss = 0.0441\n",
      "   1 1330 / 2728 loss = 0.0515\n",
      "   1 1340 / 2728 loss = 0.0514\n",
      "   1 1350 / 2728 loss = 0.0541\n",
      "   1 1360 / 2728 loss = 0.0500\n",
      "   1 1370 / 2728 loss = 0.0494\n",
      "   1 1380 / 2728 loss = 0.0580\n",
      "   1 1390 / 2728 loss = 0.0474\n",
      "   1 1400 / 2728 loss = 0.0513\n",
      "   1 1410 / 2728 loss = 0.0587\n",
      "   1 1420 / 2728 loss = 0.0509\n",
      "   1 1430 / 2728 loss = 0.0508\n",
      "   1 1440 / 2728 loss = 0.0494\n",
      "   1 1450 / 2728 loss = 0.0614\n",
      "   1 1460 / 2728 loss = 0.0415\n",
      "   1 1470 / 2728 loss = 0.0490\n",
      "   1 1480 / 2728 loss = 0.0477\n",
      "   1 1490 / 2728 loss = 0.0507\n",
      "   1 1500 / 2728 loss = 0.0515\n",
      "   1 1510 / 2728 loss = 0.0463\n",
      "   1 1520 / 2728 loss = 0.0459\n",
      "   1 1530 / 2728 loss = 0.0463\n",
      "   1 1540 / 2728 loss = 0.0452\n",
      "   1 1550 / 2728 loss = 0.0552\n",
      "   1 1560 / 2728 loss = 0.0493\n",
      "   1 1570 / 2728 loss = 0.0513\n",
      "   1 1580 / 2728 loss = 0.0488\n",
      "   1 1590 / 2728 loss = 0.0421\n",
      "   1 1600 / 2728 loss = 0.0497\n",
      "   1 1610 / 2728 loss = 0.0440\n",
      "   1 1620 / 2728 loss = 0.0454\n",
      "   1 1630 / 2728 loss = 0.0491\n",
      "   1 1640 / 2728 loss = 0.0443\n",
      "   1 1650 / 2728 loss = 0.0460\n",
      "   1 1660 / 2728 loss = 0.0486\n",
      "   1 1670 / 2728 loss = 0.0531\n",
      "   1 1680 / 2728 loss = 0.0450\n",
      "   1 1690 / 2728 loss = 0.0490\n",
      "   1 1700 / 2728 loss = 0.0474\n",
      "   1 1710 / 2728 loss = 0.0496\n",
      "   1 1720 / 2728 loss = 0.0401\n",
      "   1 1730 / 2728 loss = 0.0533\n",
      "   1 1740 / 2728 loss = 0.0413\n",
      "   1 1750 / 2728 loss = 0.0470\n",
      "   1 1760 / 2728 loss = 0.0477\n",
      "   1 1770 / 2728 loss = 0.0507\n",
      "   1 1780 / 2728 loss = 0.0555\n",
      "   1 1790 / 2728 loss = 0.0476\n",
      "   1 1800 / 2728 loss = 0.0401\n",
      "   1 1810 / 2728 loss = 0.0486\n",
      "   1 1820 / 2728 loss = 0.0483\n",
      "   1 1830 / 2728 loss = 0.0580\n",
      "   1 1840 / 2728 loss = 0.0450\n",
      "   1 1850 / 2728 loss = 0.0538\n",
      "   1 1860 / 2728 loss = 0.0534\n",
      "   1 1870 / 2728 loss = 0.0479\n",
      "   1 1880 / 2728 loss = 0.0464\n",
      "   1 1890 / 2728 loss = 0.0536\n",
      "   1 1900 / 2728 loss = 0.0597\n",
      "   1 1910 / 2728 loss = 0.0499\n",
      "   1 1920 / 2728 loss = 0.0443\n",
      "   1 1930 / 2728 loss = 0.0556\n",
      "   1 1940 / 2728 loss = 0.0514\n",
      "   1 1950 / 2728 loss = 0.0519\n",
      "   1 1960 / 2728 loss = 0.0534\n",
      "   1 1970 / 2728 loss = 0.0505\n",
      "   1 1980 / 2728 loss = 0.0425\n",
      "   1 1990 / 2728 loss = 0.0442\n",
      "   1 2000 / 2728 loss = 0.0510\n",
      "   1 2010 / 2728 loss = 0.0455\n",
      "   1 2020 / 2728 loss = 0.0495\n",
      "   1 2030 / 2728 loss = 0.0518\n",
      "   1 2040 / 2728 loss = 0.0571\n",
      "   1 2050 / 2728 loss = 0.0490\n",
      "   1 2060 / 2728 loss = 0.0431\n",
      "   1 2070 / 2728 loss = 0.0493\n",
      "   1 2080 / 2728 loss = 0.0511\n",
      "   1 2090 / 2728 loss = 0.0484\n",
      "   1 2100 / 2728 loss = 0.0539\n",
      "   1 2110 / 2728 loss = 0.0429\n",
      "   1 2120 / 2728 loss = 0.0491\n",
      "   1 2130 / 2728 loss = 0.0444\n",
      "   1 2140 / 2728 loss = 0.0546\n",
      "   1 2150 / 2728 loss = 0.0498\n",
      "   1 2160 / 2728 loss = 0.0485\n",
      "   1 2170 / 2728 loss = 0.0485\n",
      "   1 2180 / 2728 loss = 0.0505\n",
      "   1 2190 / 2728 loss = 0.0497\n",
      "   1 2200 / 2728 loss = 0.0440\n",
      "   1 2210 / 2728 loss = 0.0455\n",
      "   1 2220 / 2728 loss = 0.0460\n",
      "   1 2230 / 2728 loss = 0.0436\n",
      "   1 2240 / 2728 loss = 0.0466\n",
      "   1 2250 / 2728 loss = 0.0490\n",
      "   1 2260 / 2728 loss = 0.0564\n",
      "   1 2270 / 2728 loss = 0.0473\n",
      "   1 2280 / 2728 loss = 0.0469\n",
      "   1 2290 / 2728 loss = 0.0564\n",
      "   1 2300 / 2728 loss = 0.0490\n",
      "   1 2310 / 2728 loss = 0.0478\n",
      "   1 2320 / 2728 loss = 0.0513\n",
      "   1 2330 / 2728 loss = 0.0482\n",
      "   1 2340 / 2728 loss = 0.0466\n",
      "   1 2350 / 2728 loss = 0.0497\n",
      "   1 2360 / 2728 loss = 0.0466\n",
      "   1 2370 / 2728 loss = 0.0542\n",
      "   1 2380 / 2728 loss = 0.0525\n",
      "   1 2390 / 2728 loss = 0.0427\n",
      "   1 2400 / 2728 loss = 0.0517\n",
      "   1 2410 / 2728 loss = 0.0552\n",
      "   1 2420 / 2728 loss = 0.0498\n",
      "   1 2430 / 2728 loss = 0.0477\n",
      "   1 2440 / 2728 loss = 0.0444\n",
      "   1 2450 / 2728 loss = 0.0420\n",
      "   1 2460 / 2728 loss = 0.0569\n",
      "   1 2470 / 2728 loss = 0.0431\n",
      "   1 2480 / 2728 loss = 0.0612\n",
      "   1 2490 / 2728 loss = 0.0567\n",
      "   1 2500 / 2728 loss = 0.0490\n",
      "   1 2510 / 2728 loss = 0.0459\n",
      "   1 2520 / 2728 loss = 0.0560\n",
      "   1 2530 / 2728 loss = 0.0505\n",
      "   1 2540 / 2728 loss = 0.0461\n",
      "   1 2550 / 2728 loss = 0.0425\n",
      "   1 2560 / 2728 loss = 0.0500\n",
      "   1 2570 / 2728 loss = 0.0452\n",
      "   1 2580 / 2728 loss = 0.0534\n",
      "   1 2590 / 2728 loss = 0.0435\n",
      "   1 2600 / 2728 loss = 0.0414\n",
      "   1 2610 / 2728 loss = 0.0576\n",
      "   1 2620 / 2728 loss = 0.0525\n",
      "   1 2630 / 2728 loss = 0.0496\n",
      "   1 2640 / 2728 loss = 0.0458\n",
      "   1 2650 / 2728 loss = 0.0487\n",
      "   1 2660 / 2728 loss = 0.0441\n",
      "   1 2670 / 2728 loss = 0.0531\n",
      "   1 2680 / 2728 loss = 0.0581\n",
      "   1 2690 / 2728 loss = 0.0519\n",
      "   1 2700 / 2728 loss = 0.0510\n",
      "   1 2710 / 2728 loss = 0.0651\n",
      "   1 2720 / 2728 loss = 0.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:45<07:31, 225.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:50:26: epcoh =    1 , loss = 13.6429 , time = 223.74 s\n",
      "^_^-training data finished-^_^\n",
      "   2    0 / 2728 loss = 0.0432\n",
      "   2   10 / 2728 loss = 0.0546\n",
      "   2   20 / 2728 loss = 0.0454\n",
      "   2   30 / 2728 loss = 0.0454\n",
      "   2   40 / 2728 loss = 0.0473\n",
      "   2   50 / 2728 loss = 0.0506\n",
      "   2   60 / 2728 loss = 0.0413\n",
      "   2   70 / 2728 loss = 0.0440\n",
      "   2   80 / 2728 loss = 0.0510\n",
      "   2   90 / 2728 loss = 0.0495\n",
      "   2  100 / 2728 loss = 0.0454\n",
      "   2  110 / 2728 loss = 0.0409\n",
      "   2  120 / 2728 loss = 0.0459\n",
      "   2  130 / 2728 loss = 0.0499\n",
      "   2  140 / 2728 loss = 0.0602\n",
      "   2  150 / 2728 loss = 0.0691\n",
      "   2  160 / 2728 loss = 0.0642\n",
      "   2  170 / 2728 loss = 0.0529\n",
      "   2  180 / 2728 loss = 0.0567\n",
      "   2  190 / 2728 loss = 0.0487\n",
      "   2  200 / 2728 loss = 0.0526\n",
      "   2  210 / 2728 loss = 0.0445\n",
      "   2  220 / 2728 loss = 0.0477\n",
      "   2  230 / 2728 loss = 0.0502\n",
      "   2  240 / 2728 loss = 0.0584\n",
      "   2  250 / 2728 loss = 0.0548\n",
      "   2  260 / 2728 loss = 0.0438\n",
      "   2  270 / 2728 loss = 0.0457\n",
      "   2  280 / 2728 loss = 0.0458\n",
      "   2  290 / 2728 loss = 0.0512\n",
      "   2  300 / 2728 loss = 0.0539\n",
      "   2  310 / 2728 loss = 0.0487\n",
      "   2  320 / 2728 loss = 0.0483\n",
      "   2  330 / 2728 loss = 0.0496\n",
      "   2  340 / 2728 loss = 0.0619\n",
      "   2  350 / 2728 loss = 0.0524\n",
      "   2  360 / 2728 loss = 0.0462\n",
      "   2  370 / 2728 loss = 0.0477\n",
      "   2  380 / 2728 loss = 0.0526\n",
      "   2  390 / 2728 loss = 0.0553\n",
      "   2  400 / 2728 loss = 0.0496\n",
      "   2  410 / 2728 loss = 0.0457\n",
      "   2  420 / 2728 loss = 0.0493\n",
      "   2  430 / 2728 loss = 0.0487\n",
      "   2  440 / 2728 loss = 0.0478\n",
      "   2  450 / 2728 loss = 0.0452\n",
      "   2  460 / 2728 loss = 0.0609\n",
      "   2  470 / 2728 loss = 0.0543\n",
      "   2  480 / 2728 loss = 0.0473\n",
      "   2  490 / 2728 loss = 0.0467\n",
      "   2  500 / 2728 loss = 0.0543\n",
      "   2  510 / 2728 loss = 0.0540\n",
      "   2  520 / 2728 loss = 0.0468\n",
      "   2  530 / 2728 loss = 0.0513\n",
      "   2  540 / 2728 loss = 0.0511\n",
      "   2  550 / 2728 loss = 0.0460\n",
      "   2  560 / 2728 loss = 0.0430\n",
      "   2  570 / 2728 loss = 0.0530\n",
      "   2  580 / 2728 loss = 0.0575\n",
      "   2  590 / 2728 loss = 0.0465\n",
      "   2  600 / 2728 loss = 0.0490\n",
      "   2  610 / 2728 loss = 0.0459\n",
      "   2  620 / 2728 loss = 0.0565\n",
      "   2  630 / 2728 loss = 0.0502\n",
      "   2  640 / 2728 loss = 0.0463\n",
      "   2  650 / 2728 loss = 0.0561\n",
      "   2  660 / 2728 loss = 0.0488\n",
      "   2  670 / 2728 loss = 0.0422\n",
      "   2  680 / 2728 loss = 0.0614\n",
      "   2  690 / 2728 loss = 0.0464\n",
      "   2  700 / 2728 loss = 0.0432\n",
      "   2  710 / 2728 loss = 0.0487\n",
      "   2  720 / 2728 loss = 0.0513\n",
      "   2  730 / 2728 loss = 0.0506\n",
      "   2  740 / 2728 loss = 0.0434\n",
      "   2  750 / 2728 loss = 0.0550\n",
      "   2  760 / 2728 loss = 0.0494\n",
      "   2  770 / 2728 loss = 0.0516\n",
      "   2  780 / 2728 loss = 0.0547\n",
      "   2  790 / 2728 loss = 0.0503\n",
      "   2  800 / 2728 loss = 0.0429\n",
      "   2  810 / 2728 loss = 0.0543\n",
      "   2  820 / 2728 loss = 0.0710\n",
      "   2  830 / 2728 loss = 0.1209\n",
      "   2  840 / 2728 loss = 0.0484\n",
      "   2  850 / 2728 loss = 0.0539\n",
      "   2  860 / 2728 loss = 0.0472\n",
      "   2  870 / 2728 loss = 0.0507\n",
      "   2  880 / 2728 loss = 0.0477\n",
      "   2  890 / 2728 loss = 0.0526\n",
      "   2  900 / 2728 loss = 0.0637\n",
      "   2  910 / 2728 loss = 0.0548\n",
      "   2  920 / 2728 loss = 0.0437\n",
      "   2  930 / 2728 loss = 0.0539\n",
      "   2  940 / 2728 loss = 0.0483\n",
      "   2  950 / 2728 loss = 0.0396\n",
      "   2  960 / 2728 loss = 0.0474\n",
      "   2  970 / 2728 loss = 0.0447\n",
      "   2  980 / 2728 loss = 0.0405\n",
      "   2  990 / 2728 loss = 0.0516\n",
      "   2 1000 / 2728 loss = 0.0442\n",
      "   2 1010 / 2728 loss = 0.0482\n",
      "   2 1020 / 2728 loss = 0.0478\n",
      "   2 1030 / 2728 loss = 0.0490\n",
      "   2 1040 / 2728 loss = 0.0489\n",
      "   2 1050 / 2728 loss = 0.0468\n",
      "   2 1060 / 2728 loss = 0.0488\n",
      "   2 1070 / 2728 loss = 0.0426\n",
      "   2 1080 / 2728 loss = 0.0557\n",
      "   2 1090 / 2728 loss = 0.0458\n",
      "   2 1100 / 2728 loss = 0.0486\n",
      "   2 1110 / 2728 loss = 0.0406\n",
      "   2 1120 / 2728 loss = 0.0452\n",
      "   2 1130 / 2728 loss = 0.0461\n",
      "   2 1140 / 2728 loss = 0.0473\n",
      "   2 1150 / 2728 loss = 0.0482\n",
      "   2 1160 / 2728 loss = 0.0538\n",
      "   2 1170 / 2728 loss = 0.0533\n",
      "   2 1180 / 2728 loss = 0.0480\n",
      "   2 1190 / 2728 loss = 0.0547\n",
      "   2 1200 / 2728 loss = 0.0453\n",
      "   2 1210 / 2728 loss = 0.0485\n",
      "   2 1220 / 2728 loss = 0.0467\n",
      "   2 1230 / 2728 loss = 0.0474\n",
      "   2 1240 / 2728 loss = 0.0522\n",
      "   2 1250 / 2728 loss = 0.0522\n",
      "   2 1260 / 2728 loss = 0.0429\n",
      "   2 1270 / 2728 loss = 0.0610\n",
      "   2 1280 / 2728 loss = 0.0695\n",
      "   2 1290 / 2728 loss = 0.0474\n",
      "   2 1300 / 2728 loss = 0.0493\n",
      "   2 1310 / 2728 loss = 0.0552\n",
      "   2 1320 / 2728 loss = 0.0446\n",
      "   2 1330 / 2728 loss = 0.0506\n",
      "   2 1340 / 2728 loss = 0.0452\n",
      "   2 1350 / 2728 loss = 0.0402\n",
      "   2 1360 / 2728 loss = 0.0427\n",
      "   2 1370 / 2728 loss = 0.0408\n",
      "   2 1380 / 2728 loss = 0.0494\n",
      "   2 1390 / 2728 loss = 0.0513\n",
      "   2 1400 / 2728 loss = 0.0444\n",
      "   2 1410 / 2728 loss = 0.0454\n",
      "   2 1420 / 2728 loss = 0.0488\n",
      "   2 1430 / 2728 loss = 0.0551\n",
      "   2 1440 / 2728 loss = 0.0419\n",
      "   2 1450 / 2728 loss = 0.0485\n",
      "   2 1460 / 2728 loss = 0.0491\n",
      "   2 1470 / 2728 loss = 0.0479\n",
      "   2 1480 / 2728 loss = 0.0502\n",
      "   2 1490 / 2728 loss = 0.0416\n",
      "   2 1500 / 2728 loss = 0.0507\n",
      "   2 1510 / 2728 loss = 0.0411\n",
      "   2 1520 / 2728 loss = 0.0457\n",
      "   2 1530 / 2728 loss = 0.0463\n",
      "   2 1540 / 2728 loss = 0.0462\n",
      "   2 1550 / 2728 loss = 0.0456\n",
      "   2 1560 / 2728 loss = 0.0604\n",
      "   2 1570 / 2728 loss = 0.0710\n",
      "   2 1580 / 2728 loss = 0.0544\n",
      "   2 1590 / 2728 loss = 0.0519\n",
      "   2 1600 / 2728 loss = 0.0577\n",
      "   2 1610 / 2728 loss = 0.0424\n",
      "   2 1620 / 2728 loss = 0.0503\n",
      "   2 1630 / 2728 loss = 0.0463\n",
      "   2 1640 / 2728 loss = 0.0565\n",
      "   2 1650 / 2728 loss = 0.0400\n",
      "   2 1660 / 2728 loss = 0.0451\n",
      "   2 1670 / 2728 loss = 0.0395\n",
      "   2 1680 / 2728 loss = 0.0457\n",
      "   2 1690 / 2728 loss = 0.0445\n",
      "   2 1700 / 2728 loss = 0.0485\n",
      "   2 1710 / 2728 loss = 0.0477\n",
      "   2 1720 / 2728 loss = 0.0405\n",
      "   2 1730 / 2728 loss = 0.0489\n",
      "   2 1740 / 2728 loss = 0.0407\n",
      "   2 1750 / 2728 loss = 0.0493\n",
      "   2 1760 / 2728 loss = 0.0521\n",
      "   2 1770 / 2728 loss = 0.0528\n",
      "   2 1780 / 2728 loss = 0.0444\n",
      "   2 1790 / 2728 loss = 0.0438\n",
      "   2 1800 / 2728 loss = 0.0449\n",
      "   2 1810 / 2728 loss = 0.0592\n",
      "   2 1820 / 2728 loss = 0.0665\n",
      "   2 1830 / 2728 loss = 0.0599\n",
      "   2 1840 / 2728 loss = 0.0523\n",
      "   2 1850 / 2728 loss = 0.0424\n",
      "   2 1860 / 2728 loss = 0.0557\n",
      "   2 1870 / 2728 loss = 0.0406\n",
      "   2 1880 / 2728 loss = 0.0445\n",
      "   2 1890 / 2728 loss = 0.0419\n",
      "   2 1900 / 2728 loss = 0.0418\n",
      "   2 1910 / 2728 loss = 0.0400\n",
      "   2 1920 / 2728 loss = 0.0467\n",
      "   2 1930 / 2728 loss = 0.0460\n",
      "   2 1940 / 2728 loss = 0.0458\n",
      "   2 1950 / 2728 loss = 0.0591\n",
      "   2 1960 / 2728 loss = 0.0520\n",
      "   2 1970 / 2728 loss = 0.0462\n",
      "   2 1980 / 2728 loss = 0.0412\n",
      "   2 1990 / 2728 loss = 0.0421\n",
      "   2 2000 / 2728 loss = 0.0537\n",
      "   2 2010 / 2728 loss = 0.0418\n",
      "   2 2020 / 2728 loss = 0.0483\n",
      "   2 2030 / 2728 loss = 0.0484\n",
      "   2 2040 / 2728 loss = 0.0528\n",
      "   2 2050 / 2728 loss = 0.0690\n",
      "   2 2060 / 2728 loss = 0.0462\n",
      "   2 2070 / 2728 loss = 0.0441\n",
      "   2 2080 / 2728 loss = 0.0434\n",
      "   2 2090 / 2728 loss = 0.0438\n",
      "   2 2100 / 2728 loss = 0.0384\n",
      "   2 2110 / 2728 loss = 0.0448\n",
      "   2 2120 / 2728 loss = 0.0385\n",
      "   2 2130 / 2728 loss = 0.0510\n",
      "   2 2140 / 2728 loss = 0.0419\n",
      "   2 2150 / 2728 loss = 0.0532\n",
      "   2 2160 / 2728 loss = 0.0443\n",
      "   2 2170 / 2728 loss = 0.0466\n",
      "   2 2180 / 2728 loss = 0.0714\n",
      "   2 2190 / 2728 loss = 0.0462\n",
      "   2 2200 / 2728 loss = 0.0408\n",
      "   2 2210 / 2728 loss = 0.0654\n",
      "   2 2220 / 2728 loss = 0.0416\n",
      "   2 2230 / 2728 loss = 0.0367\n",
      "   2 2240 / 2728 loss = 0.0484\n",
      "   2 2250 / 2728 loss = 0.0448\n",
      "   2 2260 / 2728 loss = 0.0672\n",
      "   2 2270 / 2728 loss = 0.0423\n",
      "   2 2280 / 2728 loss = 0.0441\n",
      "   2 2290 / 2728 loss = 0.0477\n",
      "   2 2300 / 2728 loss = 0.0446\n",
      "   2 2310 / 2728 loss = 0.0445\n",
      "   2 2320 / 2728 loss = 0.0470\n",
      "   2 2330 / 2728 loss = 0.0516\n",
      "   2 2340 / 2728 loss = 0.0529\n",
      "   2 2350 / 2728 loss = 0.0475\n",
      "   2 2360 / 2728 loss = 0.0496\n",
      "   2 2370 / 2728 loss = 0.0489\n",
      "   2 2380 / 2728 loss = 0.0531\n",
      "   2 2390 / 2728 loss = 0.0603\n",
      "   2 2400 / 2728 loss = 0.0419\n",
      "   2 2410 / 2728 loss = 0.0476\n",
      "   2 2420 / 2728 loss = 0.0542\n",
      "   2 2430 / 2728 loss = 0.0442\n",
      "   2 2440 / 2728 loss = 0.0436\n",
      "   2 2450 / 2728 loss = 0.0455\n",
      "   2 2460 / 2728 loss = 0.0460\n",
      "   2 2470 / 2728 loss = 0.0546\n",
      "   2 2480 / 2728 loss = 0.0359\n",
      "   2 2490 / 2728 loss = 0.0387\n",
      "   2 2500 / 2728 loss = 0.0415\n",
      "   2 2510 / 2728 loss = 0.0542\n",
      "   2 2520 / 2728 loss = 0.0464\n",
      "   2 2530 / 2728 loss = 0.0428\n",
      "   2 2540 / 2728 loss = 0.0435\n",
      "   2 2550 / 2728 loss = 0.0434\n",
      "   2 2560 / 2728 loss = 0.0403\n",
      "   2 2570 / 2728 loss = 0.0398\n",
      "   2 2580 / 2728 loss = 0.0484\n",
      "   2 2590 / 2728 loss = 0.0469\n",
      "   2 2600 / 2728 loss = 0.0366\n",
      "   2 2610 / 2728 loss = 0.0476\n",
      "   2 2620 / 2728 loss = 0.0475\n",
      "   2 2630 / 2728 loss = 0.0429\n",
      "   2 2640 / 2728 loss = 0.0457\n",
      "   2 2650 / 2728 loss = 0.0373\n",
      "   2 2660 / 2728 loss = 0.0444\n",
      "   2 2670 / 2728 loss = 0.0455\n",
      "   2 2680 / 2728 loss = 0.0499\n",
      "   2 2690 / 2728 loss = 0.0631\n",
      "   2 2700 / 2728 loss = 0.0449\n",
      "   2 2710 / 2728 loss = 0.0417\n",
      "   2 2720 / 2728 loss = 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [07:31<03:45, 225.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:54:12: epcoh =    2 , loss = 3.1423 , time = 223.82 s\n",
      "^_^-training data finished-^_^\n",
      "   3    0 / 2728 loss = 0.0410\n",
      "   3   10 / 2728 loss = 0.0447\n",
      "   3   20 / 2728 loss = 0.0414\n",
      "   3   30 / 2728 loss = 0.0382\n",
      "   3   40 / 2728 loss = 0.0407\n",
      "   3   50 / 2728 loss = 0.0395\n",
      "   3   60 / 2728 loss = 0.0492\n",
      "   3   70 / 2728 loss = 0.0425\n",
      "   3   80 / 2728 loss = 0.0445\n",
      "   3   90 / 2728 loss = 0.0520\n",
      "   3  100 / 2728 loss = 0.0379\n",
      "   3  110 / 2728 loss = 0.0407\n",
      "   3  120 / 2728 loss = 0.0418\n",
      "   3  130 / 2728 loss = 0.0439\n",
      "   3  140 / 2728 loss = 0.0374\n",
      "   3  150 / 2728 loss = 0.0391\n",
      "   3  160 / 2728 loss = 0.0445\n",
      "   3  170 / 2728 loss = 0.0394\n",
      "   3  180 / 2728 loss = 0.0390\n",
      "   3  190 / 2728 loss = 0.0375\n",
      "   3  200 / 2728 loss = 0.0415\n",
      "   3  210 / 2728 loss = 0.0380\n",
      "   3  220 / 2728 loss = 0.0398\n",
      "   3  230 / 2728 loss = 0.0429\n",
      "   3  240 / 2728 loss = 0.0395\n",
      "   3  250 / 2728 loss = 0.0729\n",
      "   3  260 / 2728 loss = 0.0501\n",
      "   3  270 / 2728 loss = 0.0507\n",
      "   3  280 / 2728 loss = 0.0398\n",
      "   3  290 / 2728 loss = 0.0506\n",
      "   3  300 / 2728 loss = 0.0361\n",
      "   3  310 / 2728 loss = 0.0382\n",
      "   3  320 / 2728 loss = 0.0355\n",
      "   3  330 / 2728 loss = 0.0400\n",
      "   3  340 / 2728 loss = 0.0398\n",
      "   3  350 / 2728 loss = 0.0391\n",
      "   3  360 / 2728 loss = 0.0444\n",
      "   3  370 / 2728 loss = 0.0418\n",
      "   3  380 / 2728 loss = 0.0449\n",
      "   3  390 / 2728 loss = 0.0471\n",
      "   3  400 / 2728 loss = 0.0423\n",
      "   3  410 / 2728 loss = 0.0404\n",
      "   3  420 / 2728 loss = 0.0453\n",
      "   3  430 / 2728 loss = 0.0380\n",
      "   3  440 / 2728 loss = 0.0408\n",
      "   3  450 / 2728 loss = 0.0424\n",
      "   3  460 / 2728 loss = 0.0400\n",
      "   3  470 / 2728 loss = 0.0429\n",
      "   3  480 / 2728 loss = 0.0404\n",
      "   3  490 / 2728 loss = 0.0460\n",
      "   3  500 / 2728 loss = 0.0351\n",
      "   3  510 / 2728 loss = 0.0383\n",
      "   3  520 / 2728 loss = 0.0338\n",
      "   3  530 / 2728 loss = 0.0463\n",
      "   3  540 / 2728 loss = 0.0456\n",
      "   3  550 / 2728 loss = 0.0427\n",
      "   3  560 / 2728 loss = 0.0368\n",
      "   3  570 / 2728 loss = 0.0374\n",
      "   3  580 / 2728 loss = 0.0362\n",
      "   3  590 / 2728 loss = 0.0582\n",
      "   3  600 / 2728 loss = 0.0482\n",
      "   3  610 / 2728 loss = 0.0375\n",
      "   3  620 / 2728 loss = 0.0369\n",
      "   3  630 / 2728 loss = 0.0382\n",
      "   3  640 / 2728 loss = 0.0380\n",
      "   3  650 / 2728 loss = 0.0370\n",
      "   3  660 / 2728 loss = 0.0406\n",
      "   3  670 / 2728 loss = 0.0372\n",
      "   3  680 / 2728 loss = 0.0353\n",
      "   3  690 / 2728 loss = 0.0425\n",
      "   3  700 / 2728 loss = 0.0635\n",
      "   3  710 / 2728 loss = 0.0759\n",
      "   3  720 / 2728 loss = 0.0525\n",
      "   3  730 / 2728 loss = 0.0437\n",
      "   3  740 / 2728 loss = 0.0397\n",
      "   3  750 / 2728 loss = 0.0415\n",
      "   3  760 / 2728 loss = 0.0454\n",
      "   3  770 / 2728 loss = 0.0425\n",
      "   3  780 / 2728 loss = 0.0437\n",
      "   3  790 / 2728 loss = 0.0405\n",
      "   3  800 / 2728 loss = 0.0531\n",
      "   3  810 / 2728 loss = 0.0485\n",
      "   3  820 / 2728 loss = 0.0375\n",
      "   3  830 / 2728 loss = 0.0495\n",
      "   3  840 / 2728 loss = 0.0421\n",
      "   3  850 / 2728 loss = 0.0400\n",
      "   3  860 / 2728 loss = 0.0432\n",
      "   3  870 / 2728 loss = 0.0476\n",
      "   3  880 / 2728 loss = 0.0703\n",
      "   3  890 / 2728 loss = 0.0349\n",
      "   3  900 / 2728 loss = 0.0504\n",
      "   3  910 / 2728 loss = 0.0397\n",
      "   3  920 / 2728 loss = 0.0380\n",
      "   3  930 / 2728 loss = 0.0369\n",
      "   3  940 / 2728 loss = 0.0403\n",
      "   3  950 / 2728 loss = 0.0392\n",
      "   3  960 / 2728 loss = 0.0434\n",
      "   3  970 / 2728 loss = 0.0382\n",
      "   3  980 / 2728 loss = 0.0483\n",
      "   3  990 / 2728 loss = 0.0391\n",
      "   3 1000 / 2728 loss = 0.0416\n",
      "   3 1010 / 2728 loss = 0.0466\n",
      "   3 1020 / 2728 loss = 0.0470\n",
      "   3 1030 / 2728 loss = 0.0390\n",
      "   3 1040 / 2728 loss = 0.0421\n",
      "   3 1050 / 2728 loss = 0.0301\n",
      "   3 1060 / 2728 loss = 0.0367\n",
      "   3 1070 / 2728 loss = 0.0418\n",
      "   3 1080 / 2728 loss = 0.0470\n",
      "   3 1090 / 2728 loss = 0.0486\n",
      "   3 1100 / 2728 loss = 0.0531\n",
      "   3 1110 / 2728 loss = 0.0706\n",
      "   3 1120 / 2728 loss = 0.0424\n",
      "   3 1130 / 2728 loss = 0.0508\n",
      "   3 1140 / 2728 loss = 0.0558\n",
      "   3 1150 / 2728 loss = 0.0409\n",
      "   3 1160 / 2728 loss = 0.0337\n",
      "   3 1170 / 2728 loss = 0.0405\n",
      "   3 1180 / 2728 loss = 0.0369\n",
      "   3 1190 / 2728 loss = 0.0358\n",
      "   3 1200 / 2728 loss = 0.0383\n",
      "   3 1210 / 2728 loss = 0.0407\n",
      "   3 1220 / 2728 loss = 0.0438\n",
      "   3 1230 / 2728 loss = 0.0362\n",
      "   3 1240 / 2728 loss = 0.0372\n",
      "   3 1250 / 2728 loss = 0.0378\n",
      "   3 1260 / 2728 loss = 0.0430\n",
      "   3 1270 / 2728 loss = 0.0343\n",
      "   3 1280 / 2728 loss = 0.0349\n",
      "   3 1290 / 2728 loss = 0.0396\n",
      "   3 1300 / 2728 loss = 0.0377\n",
      "   3 1310 / 2728 loss = 0.0372\n",
      "   3 1320 / 2728 loss = 0.0386\n",
      "   3 1330 / 2728 loss = 0.0421\n",
      "   3 1340 / 2728 loss = 0.0348\n",
      "   3 1350 / 2728 loss = 0.0378\n",
      "   3 1360 / 2728 loss = 0.0420\n",
      "   3 1370 / 2728 loss = 0.0359\n",
      "   3 1380 / 2728 loss = 0.0320\n",
      "   3 1390 / 2728 loss = 0.0419\n",
      "   3 1400 / 2728 loss = 0.0351\n",
      "   3 1410 / 2728 loss = 0.0493\n",
      "   3 1420 / 2728 loss = 0.0375\n",
      "   3 1430 / 2728 loss = 0.0447\n",
      "   3 1440 / 2728 loss = 0.0449\n",
      "   3 1450 / 2728 loss = 0.0407\n",
      "   3 1460 / 2728 loss = 0.0326\n",
      "   3 1470 / 2728 loss = 0.0542\n",
      "   3 1480 / 2728 loss = 0.0378\n",
      "   3 1490 / 2728 loss = 0.0363\n",
      "   3 1500 / 2728 loss = 0.0445\n",
      "   3 1510 / 2728 loss = 0.0340\n",
      "   3 1520 / 2728 loss = 0.0371\n",
      "   3 1530 / 2728 loss = 0.0414\n",
      "   3 1540 / 2728 loss = 0.0350\n",
      "   3 1550 / 2728 loss = 0.0410\n",
      "   3 1560 / 2728 loss = 0.0376\n",
      "   3 1570 / 2728 loss = 0.0360\n",
      "   3 1580 / 2728 loss = 0.0459\n",
      "   3 1590 / 2728 loss = 0.0377\n",
      "   3 1600 / 2728 loss = 0.0410\n",
      "   3 1610 / 2728 loss = 0.0396\n",
      "   3 1620 / 2728 loss = 0.0356\n",
      "   3 1630 / 2728 loss = 0.0494\n",
      "   3 1640 / 2728 loss = 0.0434\n",
      "   3 1650 / 2728 loss = 0.0401\n",
      "   3 1660 / 2728 loss = 0.0355\n",
      "   3 1670 / 2728 loss = 0.0399\n",
      "   3 1680 / 2728 loss = 0.0602\n",
      "   3 1690 / 2728 loss = 0.0341\n",
      "   3 1700 / 2728 loss = 0.0359\n",
      "   3 1710 / 2728 loss = 0.0489\n",
      "   3 1720 / 2728 loss = 0.0373\n",
      "   3 1730 / 2728 loss = 0.0395\n",
      "   3 1740 / 2728 loss = 0.0362\n",
      "   3 1750 / 2728 loss = 0.0354\n",
      "   3 1760 / 2728 loss = 0.0422\n",
      "   3 1770 / 2728 loss = 0.0335\n",
      "   3 1780 / 2728 loss = 0.0324\n",
      "   3 1790 / 2728 loss = 0.0319\n",
      "   3 1800 / 2728 loss = 0.0361\n",
      "   3 1810 / 2728 loss = 0.0356\n",
      "   3 1820 / 2728 loss = 0.0384\n",
      "   3 1830 / 2728 loss = 0.0330\n",
      "   3 1840 / 2728 loss = 0.0374\n",
      "   3 1850 / 2728 loss = 0.0364\n",
      "   3 1860 / 2728 loss = 0.0333\n",
      "   3 1870 / 2728 loss = 0.0353\n",
      "   3 1880 / 2728 loss = 0.0368\n",
      "   3 1890 / 2728 loss = 0.0388\n",
      "   3 1900 / 2728 loss = 0.0379\n",
      "   3 1910 / 2728 loss = 0.0379\n",
      "   3 1920 / 2728 loss = 0.0424\n",
      "   3 1930 / 2728 loss = 0.0574\n",
      "   3 1940 / 2728 loss = 0.0654\n",
      "   3 1950 / 2728 loss = 0.0610\n",
      "   3 1960 / 2728 loss = 0.0332\n",
      "   3 1970 / 2728 loss = 0.0443\n",
      "   3 1980 / 2728 loss = 0.0571\n",
      "   3 1990 / 2728 loss = 0.0668\n",
      "   3 2000 / 2728 loss = 0.0451\n",
      "   3 2010 / 2728 loss = 0.0376\n",
      "   3 2020 / 2728 loss = 0.0382\n",
      "   3 2030 / 2728 loss = 0.0355\n",
      "   3 2040 / 2728 loss = 0.0381\n",
      "   3 2050 / 2728 loss = 0.0367\n",
      "   3 2060 / 2728 loss = 0.0417\n",
      "   3 2070 / 2728 loss = 0.0363\n",
      "   3 2080 / 2728 loss = 0.0355\n",
      "   3 2090 / 2728 loss = 0.0395\n",
      "   3 2100 / 2728 loss = 0.0357\n",
      "   3 2110 / 2728 loss = 0.0302\n",
      "   3 2120 / 2728 loss = 0.0345\n",
      "   3 2130 / 2728 loss = 0.0351\n",
      "   3 2140 / 2728 loss = 0.0315\n",
      "   3 2150 / 2728 loss = 0.0360\n",
      "   3 2160 / 2728 loss = 0.0360\n",
      "   3 2170 / 2728 loss = 0.0412\n",
      "   3 2180 / 2728 loss = 0.0320\n",
      "   3 2190 / 2728 loss = 0.0355\n",
      "   3 2200 / 2728 loss = 0.0359\n",
      "   3 2210 / 2728 loss = 0.0350\n",
      "   3 2220 / 2728 loss = 0.0401\n",
      "   3 2230 / 2728 loss = 0.0364\n",
      "   3 2240 / 2728 loss = 0.0359\n",
      "   3 2250 / 2728 loss = 0.0399\n",
      "   3 2260 / 2728 loss = 0.0537\n",
      "   3 2270 / 2728 loss = 0.0367\n",
      "   3 2280 / 2728 loss = 0.0343\n",
      "   3 2290 / 2728 loss = 0.0365\n",
      "   3 2300 / 2728 loss = 0.0371\n",
      "   3 2310 / 2728 loss = 0.0340\n",
      "   3 2320 / 2728 loss = 0.0442\n",
      "   3 2330 / 2728 loss = 0.0383\n",
      "   3 2340 / 2728 loss = 0.0360\n",
      "   3 2350 / 2728 loss = 0.0480\n",
      "   3 2360 / 2728 loss = 0.0316\n",
      "   3 2370 / 2728 loss = 0.0395\n",
      "   3 2380 / 2728 loss = 0.0459\n",
      "   3 2390 / 2728 loss = 0.0551\n",
      "   3 2400 / 2728 loss = 0.0405\n",
      "   3 2410 / 2728 loss = 0.0491\n",
      "   3 2420 / 2728 loss = 0.0400\n",
      "   3 2430 / 2728 loss = 0.0303\n",
      "   3 2440 / 2728 loss = 0.0384\n",
      "   3 2450 / 2728 loss = 0.0337\n",
      "   3 2460 / 2728 loss = 0.0982\n",
      "   3 2470 / 2728 loss = 0.0428\n",
      "   3 2480 / 2728 loss = 0.0387\n",
      "   3 2490 / 2728 loss = 0.0325\n",
      "   3 2500 / 2728 loss = 0.0407\n",
      "   3 2510 / 2728 loss = 0.0369\n",
      "   3 2520 / 2728 loss = 0.0402\n",
      "   3 2530 / 2728 loss = 0.0352\n",
      "   3 2540 / 2728 loss = 0.0329\n",
      "   3 2550 / 2728 loss = 0.0378\n",
      "   3 2560 / 2728 loss = 0.0351\n",
      "   3 2570 / 2728 loss = 0.0405\n",
      "   3 2580 / 2728 loss = 0.0359\n",
      "   3 2590 / 2728 loss = 0.0351\n",
      "   3 2600 / 2728 loss = 0.0386\n",
      "   3 2610 / 2728 loss = 0.0388\n",
      "   3 2620 / 2728 loss = 0.0379\n",
      "   3 2630 / 2728 loss = 0.0368\n",
      "   3 2640 / 2728 loss = 0.0339\n",
      "   3 2650 / 2728 loss = 0.0352\n",
      "   3 2660 / 2728 loss = 0.0389\n",
      "   3 2670 / 2728 loss = 0.0423\n",
      "   3 2680 / 2728 loss = 0.0361\n",
      "   3 2690 / 2728 loss = 0.0344\n",
      "   3 2700 / 2728 loss = 0.0336\n",
      "   3 2710 / 2728 loss = 0.0388\n",
      "   3 2720 / 2728 loss = 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:17<00:00, 225.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:57:58: epcoh =    3 , loss = 2.6099 , time = 223.74 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
