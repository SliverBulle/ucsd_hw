{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c44bf7-acb0-481c-88cf-03e9298a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '64', '--train_data', 'data/Train400', '--sigma', '4', '--epoch', '3', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=3, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "        \n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
    "        self.dropna = nn.Dropout2d(p=0.5)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_layers = []\n",
    "        for _ in range(10):\n",
    "            for sub in self.make_Residual():\n",
    "                output_layers.append(sub)\n",
    "        self.out = nn.Sequential(*output_layers)\n",
    "        self.res = nn.Conv2d(64, 1, kernel_size=7, padding=3, stride=1)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def make_Residual(self, in_channels=64, out_channels=64, kernel_size=3):\n",
    "        i = 0\n",
    "        layers = []\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=5, padding=2, stride=1, bias=True))\n",
    "            layers.append(nn.BatchNorm2d(64, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return layers\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.relu(self.BN(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.res(out)\n",
    "        return dn\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^-training data finished-^_^\n",
      "   1    0 / 2728 loss = 350.1694\n",
      "   1   10 / 2728 loss = 40.2601\n",
      "   1   20 / 2728 loss = 4.9260\n",
      "   1   30 / 2728 loss = 1.2478\n",
      "   1   40 / 2728 loss = 0.8458\n",
      "   1   50 / 2728 loss = 0.5263\n",
      "   1   60 / 2728 loss = 0.4496\n",
      "   1   70 / 2728 loss = 0.5002\n",
      "   1   80 / 2728 loss = 0.4050\n",
      "   1   90 / 2728 loss = 0.3695\n",
      "   1  100 / 2728 loss = 0.3643\n",
      "   1  110 / 2728 loss = 0.3241\n",
      "   1  120 / 2728 loss = 0.3474\n",
      "   1  130 / 2728 loss = 0.3283\n",
      "   1  140 / 2728 loss = 0.3129\n",
      "   1  150 / 2728 loss = 0.3229\n",
      "   1  160 / 2728 loss = 0.3307\n",
      "   1  170 / 2728 loss = 0.3008\n",
      "   1  180 / 2728 loss = 0.2749\n",
      "   1  190 / 2728 loss = 0.3096\n",
      "   1  200 / 2728 loss = 0.2803\n",
      "   1  210 / 2728 loss = 0.2702\n",
      "   1  220 / 2728 loss = 0.2681\n",
      "   1  230 / 2728 loss = 0.2549\n",
      "   1  240 / 2728 loss = 0.2710\n",
      "   1  250 / 2728 loss = 0.2963\n",
      "   1  260 / 2728 loss = 0.2618\n",
      "   1  270 / 2728 loss = 0.2555\n",
      "   1  280 / 2728 loss = 0.2768\n",
      "   1  290 / 2728 loss = 0.2444\n",
      "   1  300 / 2728 loss = 0.2501\n",
      "   1  310 / 2728 loss = 0.2520\n",
      "   1  320 / 2728 loss = 0.2464\n",
      "   1  330 / 2728 loss = 0.2590\n",
      "   1  340 / 2728 loss = 0.2591\n",
      "   1  350 / 2728 loss = 0.2623\n",
      "   1  360 / 2728 loss = 0.2351\n",
      "   1  370 / 2728 loss = 0.2369\n",
      "   1  380 / 2728 loss = 0.2307\n",
      "   1  390 / 2728 loss = 0.2385\n",
      "   1  400 / 2728 loss = 0.2308\n",
      "   1  410 / 2728 loss = 0.2318\n",
      "   1  420 / 2728 loss = 0.2346\n",
      "   1  430 / 2728 loss = 0.2448\n",
      "   1  440 / 2728 loss = 0.2335\n",
      "   1  450 / 2728 loss = 0.2306\n",
      "   1  460 / 2728 loss = 0.2523\n",
      "   1  470 / 2728 loss = 0.2507\n",
      "   1  480 / 2728 loss = 0.2334\n",
      "   1  490 / 2728 loss = 0.2255\n",
      "   1  500 / 2728 loss = 0.2229\n",
      "   1  510 / 2728 loss = 0.2377\n",
      "   1  520 / 2728 loss = 0.2381\n",
      "   1  530 / 2728 loss = 0.2213\n",
      "   1  540 / 2728 loss = 0.2347\n",
      "   1  550 / 2728 loss = 0.2426\n",
      "   1  560 / 2728 loss = 0.2190\n",
      "   1  570 / 2728 loss = 0.2158\n",
      "   1  580 / 2728 loss = 0.2318\n",
      "   1  590 / 2728 loss = 0.2206\n",
      "   1  600 / 2728 loss = 0.2189\n",
      "   1  610 / 2728 loss = 0.2174\n",
      "   1  620 / 2728 loss = 0.2213\n",
      "   1  630 / 2728 loss = 0.2176\n",
      "   1  640 / 2728 loss = 0.2274\n",
      "   1  650 / 2728 loss = 0.2237\n",
      "   1  660 / 2728 loss = 0.2133\n",
      "   1  670 / 2728 loss = 0.2169\n",
      "   1  680 / 2728 loss = 0.2348\n",
      "   1  690 / 2728 loss = 0.2166\n",
      "   1  700 / 2728 loss = 0.2179\n",
      "   1  710 / 2728 loss = 0.2207\n",
      "   1  720 / 2728 loss = 0.2161\n",
      "   1  730 / 2728 loss = 0.2185\n",
      "   1  740 / 2728 loss = 0.2147\n",
      "   1  750 / 2728 loss = 0.2166\n",
      "   1  760 / 2728 loss = 0.2154\n",
      "   1  770 / 2728 loss = 0.2260\n",
      "   1  780 / 2728 loss = 0.2135\n",
      "   1  790 / 2728 loss = 0.2192\n",
      "   1  800 / 2728 loss = 0.2157\n",
      "   1  810 / 2728 loss = 0.2167\n",
      "   1  820 / 2728 loss = 0.2089\n",
      "   1  830 / 2728 loss = 0.2110\n",
      "   1  840 / 2728 loss = 0.2111\n",
      "   1  850 / 2728 loss = 0.2158\n",
      "   1  860 / 2728 loss = 0.2101\n",
      "   1  870 / 2728 loss = 0.2191\n",
      "   1  880 / 2728 loss = 0.2103\n",
      "   1  890 / 2728 loss = 0.2213\n",
      "   1  900 / 2728 loss = 0.2102\n",
      "   1  910 / 2728 loss = 0.2119\n",
      "   1  920 / 2728 loss = 0.2220\n",
      "   1  930 / 2728 loss = 0.2156\n",
      "   1  940 / 2728 loss = 0.2375\n",
      "   1  950 / 2728 loss = 0.2127\n",
      "   1  960 / 2728 loss = 0.2154\n",
      "   1  970 / 2728 loss = 0.2101\n",
      "   1  980 / 2728 loss = 0.2099\n",
      "   1  990 / 2728 loss = 0.2168\n",
      "   1 1000 / 2728 loss = 0.2112\n",
      "   1 1010 / 2728 loss = 0.2077\n",
      "   1 1020 / 2728 loss = 0.2130\n",
      "   1 1030 / 2728 loss = 0.2147\n",
      "   1 1040 / 2728 loss = 0.2073\n",
      "   1 1050 / 2728 loss = 0.2113\n",
      "   1 1060 / 2728 loss = 0.2061\n",
      "   1 1070 / 2728 loss = 0.2141\n",
      "   1 1080 / 2728 loss = 0.2089\n",
      "   1 1090 / 2728 loss = 0.2114\n",
      "   1 1100 / 2728 loss = 0.2068\n",
      "   1 1110 / 2728 loss = 0.2068\n",
      "   1 1120 / 2728 loss = 0.2055\n",
      "   1 1130 / 2728 loss = 0.2056\n",
      "   1 1140 / 2728 loss = 0.2070\n",
      "   1 1150 / 2728 loss = 0.2072\n",
      "   1 1160 / 2728 loss = 0.2130\n",
      "   1 1170 / 2728 loss = 0.2087\n",
      "   1 1180 / 2728 loss = 0.2189\n",
      "   1 1190 / 2728 loss = 0.2094\n",
      "   1 1200 / 2728 loss = 0.2094\n",
      "   1 1210 / 2728 loss = 0.2195\n",
      "   1 1220 / 2728 loss = 0.2247\n",
      "   1 1230 / 2728 loss = 0.2108\n",
      "   1 1240 / 2728 loss = 0.2238\n",
      "   1 1250 / 2728 loss = 0.2169\n",
      "   1 1260 / 2728 loss = 0.2080\n",
      "   1 1270 / 2728 loss = 0.2161\n",
      "   1 1280 / 2728 loss = 0.2124\n",
      "   1 1290 / 2728 loss = 0.2061\n",
      "   1 1300 / 2728 loss = 0.2042\n",
      "   1 1310 / 2728 loss = 0.2041\n",
      "   1 1320 / 2728 loss = 0.2160\n",
      "   1 1330 / 2728 loss = 0.2087\n",
      "   1 1340 / 2728 loss = 0.2134\n",
      "   1 1350 / 2728 loss = 0.2049\n",
      "   1 1360 / 2728 loss = 0.2071\n",
      "   1 1370 / 2728 loss = 0.2049\n",
      "   1 1380 / 2728 loss = 0.2046\n",
      "   1 1390 / 2728 loss = 0.2059\n",
      "   1 1400 / 2728 loss = 0.2090\n",
      "   1 1410 / 2728 loss = 0.2052\n",
      "   1 1420 / 2728 loss = 0.2091\n",
      "   1 1430 / 2728 loss = 0.2072\n",
      "   1 1440 / 2728 loss = 0.2072\n",
      "   1 1450 / 2728 loss = 0.2293\n",
      "   1 1460 / 2728 loss = 0.2200\n",
      "   1 1470 / 2728 loss = 0.2133\n",
      "   1 1480 / 2728 loss = 0.2147\n",
      "   1 1490 / 2728 loss = 0.2207\n",
      "   1 1500 / 2728 loss = 0.2144\n",
      "   1 1510 / 2728 loss = 0.2160\n",
      "   1 1520 / 2728 loss = 0.2084\n",
      "   1 1530 / 2728 loss = 0.2057\n",
      "   1 1540 / 2728 loss = 0.2034\n",
      "   1 1550 / 2728 loss = 0.2043\n",
      "   1 1560 / 2728 loss = 0.2003\n",
      "   1 1570 / 2728 loss = 0.2034\n",
      "   1 1580 / 2728 loss = 0.2124\n",
      "   1 1590 / 2728 loss = 0.2118\n",
      "   1 1600 / 2728 loss = 0.2204\n",
      "   1 1610 / 2728 loss = 0.2065\n",
      "   1 1620 / 2728 loss = 0.3149\n",
      "   1 1630 / 2728 loss = 0.2282\n",
      "   1 1640 / 2728 loss = 0.2071\n",
      "   1 1650 / 2728 loss = 0.3084\n",
      "   1 1660 / 2728 loss = 0.2310\n",
      "   1 1670 / 2728 loss = 0.2660\n",
      "   1 1680 / 2728 loss = 0.4353\n",
      "   1 1690 / 2728 loss = 0.2255\n",
      "   1 1700 / 2728 loss = 0.2049\n",
      "   1 1710 / 2728 loss = 0.2056\n",
      "   1 1720 / 2728 loss = 0.2131\n",
      "   1 1730 / 2728 loss = 0.2055\n",
      "   1 1740 / 2728 loss = 0.2071\n",
      "   1 1750 / 2728 loss = 0.2285\n",
      "   1 1760 / 2728 loss = 0.2220\n",
      "   1 1770 / 2728 loss = 0.2006\n",
      "   1 1780 / 2728 loss = 0.2054\n",
      "   1 1790 / 2728 loss = 0.2087\n",
      "   1 1800 / 2728 loss = 0.2036\n",
      "   1 1810 / 2728 loss = 0.2070\n",
      "   1 1820 / 2728 loss = 0.2208\n",
      "   1 1830 / 2728 loss = 0.2816\n",
      "   1 1840 / 2728 loss = 0.2047\n",
      "   1 1850 / 2728 loss = 0.2114\n",
      "   1 1860 / 2728 loss = 0.4107\n",
      "   1 1870 / 2728 loss = 0.2339\n",
      "   1 1880 / 2728 loss = 0.4114\n",
      "   1 1890 / 2728 loss = 0.2040\n",
      "   1 1900 / 2728 loss = 0.2290\n",
      "   1 1910 / 2728 loss = 0.2059\n",
      "   1 1920 / 2728 loss = 0.2437\n",
      "   1 1930 / 2728 loss = 0.2746\n",
      "   1 1940 / 2728 loss = 0.2044\n",
      "   1 1950 / 2728 loss = 0.2489\n",
      "   1 1960 / 2728 loss = 0.2099\n",
      "   1 1970 / 2728 loss = 0.2581\n",
      "   1 1980 / 2728 loss = 0.2474\n",
      "   1 1990 / 2728 loss = 0.4760\n",
      "   1 2000 / 2728 loss = 0.2114\n",
      "   1 2010 / 2728 loss = 0.4904\n",
      "   1 2020 / 2728 loss = 0.2041\n",
      "   1 2030 / 2728 loss = 0.2171\n",
      "   1 2040 / 2728 loss = 0.2128\n",
      "   1 2050 / 2728 loss = 0.9255\n",
      "   1 2060 / 2728 loss = 0.5981\n",
      "   1 2070 / 2728 loss = 0.2896\n",
      "   1 2080 / 2728 loss = 0.3399\n",
      "   1 2090 / 2728 loss = 1.9697\n",
      "   1 2100 / 2728 loss = 0.5615\n",
      "   1 2110 / 2728 loss = 0.2066\n",
      "   1 2120 / 2728 loss = 0.2259\n",
      "   1 2130 / 2728 loss = 0.2099\n",
      "   1 2140 / 2728 loss = 0.2121\n",
      "   1 2150 / 2728 loss = 0.2555\n",
      "   1 2160 / 2728 loss = 0.2048\n",
      "   1 2170 / 2728 loss = 0.2505\n",
      "   1 2180 / 2728 loss = 0.2258\n",
      "   1 2190 / 2728 loss = 0.2045\n",
      "   1 2200 / 2728 loss = 0.2066\n",
      "   1 2210 / 2728 loss = 0.2049\n",
      "   1 2220 / 2728 loss = 0.2164\n",
      "   1 2230 / 2728 loss = 0.2789\n",
      "   1 2240 / 2728 loss = 0.2327\n",
      "   1 2250 / 2728 loss = 0.2032\n",
      "   1 2260 / 2728 loss = 0.2200\n",
      "   1 2270 / 2728 loss = 0.2129\n",
      "   1 2280 / 2728 loss = 0.2202\n",
      "   1 2290 / 2728 loss = 0.2827\n",
      "   1 2300 / 2728 loss = 0.2142\n",
      "   1 2310 / 2728 loss = 0.2018\n",
      "   1 2320 / 2728 loss = 0.2045\n",
      "   1 2330 / 2728 loss = 0.2021\n",
      "   1 2340 / 2728 loss = 0.2020\n",
      "   1 2350 / 2728 loss = 0.2035\n",
      "   1 2360 / 2728 loss = 0.2010\n",
      "   1 2370 / 2728 loss = 0.2085\n",
      "   1 2380 / 2728 loss = 0.2029\n",
      "   1 2390 / 2728 loss = 0.2028\n",
      "   1 2400 / 2728 loss = 0.2024\n",
      "   1 2410 / 2728 loss = 0.2051\n",
      "   1 2420 / 2728 loss = 0.2001\n",
      "   1 2430 / 2728 loss = 0.2025\n",
      "   1 2440 / 2728 loss = 0.2299\n",
      "   1 2450 / 2728 loss = 0.2397\n",
      "   1 2460 / 2728 loss = 1.0428\n",
      "   1 2470 / 2728 loss = 0.2265\n",
      "   1 2480 / 2728 loss = 1.8316\n",
      "   1 2490 / 2728 loss = 0.7601\n",
      "   1 2500 / 2728 loss = 0.2230\n",
      "   1 2510 / 2728 loss = 0.2163\n",
      "   1 2520 / 2728 loss = 0.2230\n",
      "   1 2530 / 2728 loss = 0.1994\n",
      "   1 2540 / 2728 loss = 0.2221\n",
      "   1 2550 / 2728 loss = 0.2126\n",
      "   1 2560 / 2728 loss = 0.2071\n",
      "   1 2570 / 2728 loss = 0.2083\n",
      "   1 2580 / 2728 loss = 0.2122\n",
      "   1 2590 / 2728 loss = 0.2025\n",
      "   1 2600 / 2728 loss = 0.2359\n",
      "   1 2610 / 2728 loss = 0.2377\n",
      "   1 2620 / 2728 loss = 0.2041\n",
      "   1 2630 / 2728 loss = 0.2639\n",
      "   1 2640 / 2728 loss = 0.2078\n",
      "   1 2650 / 2728 loss = 0.2385\n",
      "   1 2660 / 2728 loss = 0.4063\n",
      "   1 2670 / 2728 loss = 0.2467\n",
      "   1 2680 / 2728 loss = 0.2409\n",
      "   1 2690 / 2728 loss = 0.3373\n",
      "   1 2700 / 2728 loss = 0.2066\n",
      "   1 2710 / 2728 loss = 0.2557\n",
      "   1 2720 / 2728 loss = 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [06:09<12:19, 369.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 05:13:22: epcoh =    1 , loss = 121.4062 , time = 367.91 s\n",
      "^_^-training data finished-^_^\n",
      "   2    0 / 2728 loss = 0.2003\n",
      "   2   10 / 2728 loss = 0.3776\n",
      "   2   20 / 2728 loss = 0.4656\n",
      "   2   30 / 2728 loss = 0.2324\n",
      "   2   40 / 2728 loss = 0.2020\n",
      "   2   50 / 2728 loss = 0.3923\n",
      "   2   60 / 2728 loss = 0.2807\n",
      "   2   70 / 2728 loss = 0.2121\n",
      "   2   80 / 2728 loss = 0.1997\n",
      "   2   90 / 2728 loss = 0.2036\n",
      "   2  100 / 2728 loss = 0.1993\n",
      "   2  110 / 2728 loss = 0.2254\n",
      "   2  120 / 2728 loss = 0.2026\n",
      "   2  130 / 2728 loss = 0.2156\n",
      "   2  140 / 2728 loss = 0.4840\n",
      "   2  150 / 2728 loss = 0.3046\n",
      "   2  160 / 2728 loss = 0.2502\n",
      "   2  170 / 2728 loss = 2.3082\n",
      "   2  180 / 2728 loss = 0.2098\n",
      "   2  190 / 2728 loss = 0.2171\n",
      "   2  200 / 2728 loss = 0.2621\n",
      "   2  210 / 2728 loss = 0.2187\n",
      "   2  220 / 2728 loss = 0.3364\n",
      "   2  230 / 2728 loss = 0.2119\n",
      "   2  240 / 2728 loss = 0.2043\n",
      "   2  250 / 2728 loss = 0.2060\n",
      "   2  260 / 2728 loss = 0.2016\n",
      "   2  270 / 2728 loss = 0.2022\n",
      "   2  280 / 2728 loss = 0.1971\n",
      "   2  290 / 2728 loss = 0.1994\n",
      "   2  300 / 2728 loss = 0.2015\n",
      "   2  310 / 2728 loss = 0.2012\n",
      "   2  320 / 2728 loss = 0.1993\n",
      "   2  330 / 2728 loss = 0.2006\n",
      "   2  340 / 2728 loss = 0.2046\n",
      "   2  350 / 2728 loss = 0.2139\n",
      "   2  360 / 2728 loss = 0.2022\n",
      "   2  370 / 2728 loss = 0.2032\n",
      "   2  380 / 2728 loss = 0.2002\n",
      "   2  390 / 2728 loss = 0.2048\n",
      "   2  400 / 2728 loss = 0.1988\n",
      "   2  410 / 2728 loss = 0.2038\n",
      "   2  420 / 2728 loss = 0.2036\n",
      "   2  430 / 2728 loss = 0.2039\n",
      "   2  440 / 2728 loss = 0.2042\n",
      "   2  450 / 2728 loss = 0.2011\n",
      "   2  460 / 2728 loss = 0.1999\n",
      "   2  470 / 2728 loss = 0.2010\n",
      "   2  480 / 2728 loss = 0.2004\n",
      "   2  490 / 2728 loss = 0.2002\n",
      "   2  500 / 2728 loss = 0.2300\n",
      "   2  510 / 2728 loss = 0.2089\n",
      "   2  520 / 2728 loss = 0.2950\n",
      "   2  530 / 2728 loss = 0.2144\n",
      "   2  540 / 2728 loss = 0.2306\n",
      "   2  550 / 2728 loss = 0.6112\n",
      "   2  560 / 2728 loss = 0.2404\n",
      "   2  570 / 2728 loss = 0.5619\n",
      "   2  580 / 2728 loss = 0.8029\n",
      "   2  590 / 2728 loss = 0.6357\n",
      "   2  600 / 2728 loss = 0.2035\n",
      "   2  610 / 2728 loss = 0.2025\n",
      "   2  620 / 2728 loss = 0.3463\n",
      "   2  630 / 2728 loss = 0.3832\n",
      "   2  640 / 2728 loss = 0.2182\n",
      "   2  650 / 2728 loss = 0.3618\n",
      "   2  660 / 2728 loss = 0.3395\n",
      "   2  670 / 2728 loss = 0.3125\n",
      "   2  680 / 2728 loss = 0.2505\n",
      "   2  690 / 2728 loss = 0.2161\n",
      "   2  700 / 2728 loss = 0.2013\n",
      "   2  710 / 2728 loss = 0.2014\n",
      "   2  720 / 2728 loss = 0.2187\n",
      "   2  730 / 2728 loss = 0.2056\n",
      "   2  740 / 2728 loss = 0.2404\n",
      "   2  750 / 2728 loss = 0.2103\n",
      "   2  760 / 2728 loss = 0.2947\n",
      "   2  770 / 2728 loss = 0.2106\n",
      "   2  780 / 2728 loss = 0.2764\n",
      "   2  790 / 2728 loss = 0.2016\n",
      "   2  800 / 2728 loss = 0.2017\n",
      "   2  810 / 2728 loss = 0.4557\n",
      "   2  820 / 2728 loss = 0.2038\n",
      "   2  830 / 2728 loss = 0.2470\n",
      "   2  840 / 2728 loss = 0.2044\n",
      "   2  850 / 2728 loss = 0.2085\n",
      "   2  860 / 2728 loss = 0.2215\n",
      "   2  870 / 2728 loss = 0.2052\n",
      "   2  880 / 2728 loss = 0.2480\n",
      "   2  890 / 2728 loss = 0.5172\n",
      "   2  900 / 2728 loss = 0.2256\n",
      "   2  910 / 2728 loss = 0.2265\n",
      "   2  920 / 2728 loss = 0.2305\n",
      "   2  930 / 2728 loss = 0.2694\n",
      "   2  940 / 2728 loss = 0.7754\n",
      "   2  950 / 2728 loss = 0.2592\n",
      "   2  960 / 2728 loss = 0.2985\n",
      "   2  970 / 2728 loss = 0.2607\n",
      "   2  980 / 2728 loss = 0.3008\n",
      "   2  990 / 2728 loss = 0.6494\n",
      "   2 1000 / 2728 loss = 0.3177\n",
      "   2 1010 / 2728 loss = 0.2267\n",
      "   2 1020 / 2728 loss = 0.2187\n",
      "   2 1030 / 2728 loss = 0.3182\n",
      "   2 1040 / 2728 loss = 0.2161\n",
      "   2 1050 / 2728 loss = 0.2561\n",
      "   2 1060 / 2728 loss = 0.2984\n",
      "   2 1070 / 2728 loss = 0.2049\n",
      "   2 1080 / 2728 loss = 0.3487\n",
      "   2 1090 / 2728 loss = 0.2038\n",
      "   2 1100 / 2728 loss = 0.2483\n",
      "   2 1110 / 2728 loss = 0.2842\n",
      "   2 1120 / 2728 loss = 0.2306\n",
      "   2 1130 / 2728 loss = 0.1999\n",
      "   2 1140 / 2728 loss = 0.3264\n",
      "   2 1150 / 2728 loss = 0.7559\n",
      "   2 1160 / 2728 loss = 0.3371\n",
      "   2 1170 / 2728 loss = 0.4001\n",
      "   2 1180 / 2728 loss = 4.4440\n",
      "   2 1190 / 2728 loss = 0.6504\n",
      "   2 1200 / 2728 loss = 0.2665\n",
      "   2 1210 / 2728 loss = 0.3848\n",
      "   2 1220 / 2728 loss = 0.8044\n",
      "   2 1230 / 2728 loss = 0.2536\n",
      "   2 1240 / 2728 loss = 0.3990\n",
      "   2 1250 / 2728 loss = 0.2477\n",
      "   2 1260 / 2728 loss = 0.3293\n",
      "   2 1270 / 2728 loss = 0.3630\n",
      "   2 1280 / 2728 loss = 0.2962\n",
      "   2 1290 / 2728 loss = 0.3808\n",
      "   2 1300 / 2728 loss = 0.2044\n",
      "   2 1310 / 2728 loss = 0.2269\n",
      "   2 1320 / 2728 loss = 0.2421\n",
      "   2 1330 / 2728 loss = 0.2449\n",
      "   2 1340 / 2728 loss = 0.2087\n",
      "   2 1350 / 2728 loss = 0.3279\n",
      "   2 1360 / 2728 loss = 0.2937\n",
      "   2 1370 / 2728 loss = 0.2065\n",
      "   2 1380 / 2728 loss = 0.2156\n",
      "   2 1390 / 2728 loss = 0.2630\n",
      "   2 1400 / 2728 loss = 0.2597\n",
      "   2 1410 / 2728 loss = 0.4235\n",
      "   2 1420 / 2728 loss = 0.3099\n",
      "   2 1430 / 2728 loss = 0.3394\n",
      "   2 1440 / 2728 loss = 0.8092\n",
      "   2 1450 / 2728 loss = 0.2336\n",
      "   2 1460 / 2728 loss = 0.2166\n",
      "   2 1470 / 2728 loss = 0.7162\n",
      "   2 1480 / 2728 loss = 0.6872\n",
      "   2 1490 / 2728 loss = 0.6158\n",
      "   2 1500 / 2728 loss = 0.9434\n",
      "   2 1510 / 2728 loss = 1.3734\n",
      "   2 1520 / 2728 loss = 0.5067\n",
      "   2 1530 / 2728 loss = 0.2883\n",
      "   2 1540 / 2728 loss = 0.2104\n",
      "   2 1550 / 2728 loss = 0.2145\n",
      "   2 1560 / 2728 loss = 0.3112\n",
      "   2 1570 / 2728 loss = 0.2351\n",
      "   2 1580 / 2728 loss = 0.4841\n",
      "   2 1590 / 2728 loss = 0.3206\n",
      "   2 1600 / 2728 loss = 0.2547\n",
      "   2 1610 / 2728 loss = 0.4356\n",
      "   2 1620 / 2728 loss = 0.2108\n",
      "   2 1630 / 2728 loss = 0.2855\n",
      "   2 1640 / 2728 loss = 0.2458\n",
      "   2 1650 / 2728 loss = 0.2238\n",
      "   2 1660 / 2728 loss = 0.2099\n",
      "   2 1670 / 2728 loss = 0.2504\n",
      "   2 1680 / 2728 loss = 0.2010\n",
      "   2 1690 / 2728 loss = 0.2103\n",
      "   2 1700 / 2728 loss = 0.2025\n",
      "   2 1710 / 2728 loss = 0.2838\n",
      "   2 1720 / 2728 loss = 0.4533\n",
      "   2 1730 / 2728 loss = 0.2389\n",
      "   2 1740 / 2728 loss = 0.2036\n",
      "   2 1750 / 2728 loss = 0.2194\n",
      "   2 1760 / 2728 loss = 0.2055\n",
      "   2 1770 / 2728 loss = 0.2023\n",
      "   2 1780 / 2728 loss = 0.2301\n",
      "   2 1790 / 2728 loss = 0.2149\n",
      "   2 1800 / 2728 loss = 0.2259\n",
      "   2 1810 / 2728 loss = 0.2081\n",
      "   2 1820 / 2728 loss = 0.2023\n",
      "   2 1830 / 2728 loss = 0.2002\n",
      "   2 1840 / 2728 loss = 0.2055\n",
      "   2 1850 / 2728 loss = 0.2319\n",
      "   2 1860 / 2728 loss = 0.2627\n",
      "   2 1870 / 2728 loss = 0.3238\n",
      "   2 1880 / 2728 loss = 0.2723\n",
      "   2 1890 / 2728 loss = 0.2163\n",
      "   2 1900 / 2728 loss = 0.2058\n",
      "   2 1910 / 2728 loss = 0.2017\n",
      "   2 1920 / 2728 loss = 0.1996\n",
      "   2 1930 / 2728 loss = 0.2017\n",
      "   2 1940 / 2728 loss = 0.2011\n",
      "   2 1950 / 2728 loss = 0.2031\n",
      "   2 1960 / 2728 loss = 0.1991\n",
      "   2 1970 / 2728 loss = 0.2058\n",
      "   2 1980 / 2728 loss = 0.1997\n",
      "   2 1990 / 2728 loss = 0.1996\n",
      "   2 2000 / 2728 loss = 0.2056\n",
      "   2 2010 / 2728 loss = 0.2001\n",
      "   2 2020 / 2728 loss = 0.2009\n",
      "   2 2030 / 2728 loss = 0.2074\n",
      "   2 2040 / 2728 loss = 0.1995\n",
      "   2 2050 / 2728 loss = 0.2057\n",
      "   2 2060 / 2728 loss = 0.2002\n",
      "   2 2070 / 2728 loss = 0.2133\n",
      "   2 2080 / 2728 loss = 1.3512\n",
      "   2 2090 / 2728 loss = 0.4490\n",
      "   2 2100 / 2728 loss = 0.3740\n",
      "   2 2110 / 2728 loss = 0.2165\n",
      "   2 2120 / 2728 loss = 1.2848\n",
      "   2 2130 / 2728 loss = 0.4020\n",
      "   2 2140 / 2728 loss = 1.1611\n",
      "   2 2150 / 2728 loss = 0.2988\n",
      "   2 2160 / 2728 loss = 0.2577\n",
      "   2 2170 / 2728 loss = 0.2815\n",
      "   2 2180 / 2728 loss = 0.2441\n",
      "   2 2190 / 2728 loss = 0.3835\n",
      "   2 2200 / 2728 loss = 0.3625\n",
      "   2 2210 / 2728 loss = 0.2279\n",
      "   2 2220 / 2728 loss = 0.2225\n",
      "   2 2230 / 2728 loss = 0.2128\n",
      "   2 2240 / 2728 loss = 0.2444\n",
      "   2 2250 / 2728 loss = 0.3899\n",
      "   2 2260 / 2728 loss = 0.2811\n",
      "   2 2270 / 2728 loss = 0.2237\n",
      "   2 2280 / 2728 loss = 0.1989\n",
      "   2 2290 / 2728 loss = 0.1996\n",
      "   2 2300 / 2728 loss = 0.1996\n",
      "   2 2310 / 2728 loss = 0.2396\n",
      "   2 2320 / 2728 loss = 0.2170\n",
      "   2 2330 / 2728 loss = 0.2146\n",
      "   2 2340 / 2728 loss = 0.2030\n",
      "   2 2350 / 2728 loss = 0.2174\n",
      "   2 2360 / 2728 loss = 0.2240\n",
      "   2 2370 / 2728 loss = 0.1970\n",
      "   2 2380 / 2728 loss = 0.2243\n",
      "   2 2390 / 2728 loss = 0.2066\n",
      "   2 2400 / 2728 loss = 0.2426\n",
      "   2 2410 / 2728 loss = 0.2065\n",
      "   2 2420 / 2728 loss = 0.2136\n",
      "   2 2430 / 2728 loss = 0.3758\n",
      "   2 2440 / 2728 loss = 0.3242\n",
      "   2 2450 / 2728 loss = 0.2412\n",
      "   2 2460 / 2728 loss = 0.2529\n",
      "   2 2470 / 2728 loss = 1.3479\n",
      "   2 2480 / 2728 loss = 0.4592\n",
      "   2 2490 / 2728 loss = 0.5833\n",
      "   2 2500 / 2728 loss = 0.3521\n",
      "   2 2510 / 2728 loss = 0.5610\n",
      "   2 2520 / 2728 loss = 0.2340\n",
      "   2 2530 / 2728 loss = 0.2046\n",
      "   2 2540 / 2728 loss = 0.3282\n",
      "   2 2550 / 2728 loss = 0.2000\n",
      "   2 2560 / 2728 loss = 0.4214\n",
      "   2 2570 / 2728 loss = 0.2042\n",
      "   2 2580 / 2728 loss = 0.2051\n",
      "   2 2590 / 2728 loss = 0.2621\n",
      "   2 2600 / 2728 loss = 0.2306\n",
      "   2 2610 / 2728 loss = 0.2890\n",
      "   2 2620 / 2728 loss = 0.3462\n",
      "   2 2630 / 2728 loss = 0.7619\n",
      "   2 2640 / 2728 loss = 1.1731\n",
      "   2 2650 / 2728 loss = 0.4769\n",
      "   2 2660 / 2728 loss = 0.3499\n",
      "   2 2670 / 2728 loss = 0.4079\n",
      "   2 2680 / 2728 loss = 0.3552\n",
      "   2 2690 / 2728 loss = 0.4217\n",
      "   2 2700 / 2728 loss = 0.2610\n",
      "   2 2710 / 2728 loss = 0.2594\n",
      "   2 2720 / 2728 loss = 0.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [12:20<06:10, 370.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 05:19:32: epcoh =    2 , loss = 20.4893 , time = 368.35 s\n",
      "^_^-training data finished-^_^\n",
      "   3    0 / 2728 loss = 0.2113\n",
      "   3   10 / 2728 loss = 0.2625\n",
      "   3   20 / 2728 loss = 0.2191\n",
      "   3   30 / 2728 loss = 0.2528\n",
      "   3   40 / 2728 loss = 0.2298\n",
      "   3   50 / 2728 loss = 0.2049\n",
      "   3   60 / 2728 loss = 0.2041\n",
      "   3   70 / 2728 loss = 0.3952\n",
      "   3   80 / 2728 loss = 0.3450\n",
      "   3   90 / 2728 loss = 0.2194\n",
      "   3  100 / 2728 loss = 0.2511\n",
      "   3  110 / 2728 loss = 0.2326\n",
      "   3  120 / 2728 loss = 0.2523\n",
      "   3  130 / 2728 loss = 0.2462\n",
      "   3  140 / 2728 loss = 0.3188\n",
      "   3  150 / 2728 loss = 0.2698\n",
      "   3  160 / 2728 loss = 0.2019\n",
      "   3  170 / 2728 loss = 0.2046\n",
      "   3  180 / 2728 loss = 0.3136\n",
      "   3  190 / 2728 loss = 0.1997\n",
      "   3  200 / 2728 loss = 0.2051\n",
      "   3  210 / 2728 loss = 0.2118\n",
      "   3  220 / 2728 loss = 0.2650\n",
      "   3  230 / 2728 loss = 0.3586\n",
      "   3  240 / 2728 loss = 0.1995\n",
      "   3  250 / 2728 loss = 0.3965\n",
      "   3  260 / 2728 loss = 0.2621\n",
      "   3  270 / 2728 loss = 0.2065\n",
      "   3  280 / 2728 loss = 0.3266\n",
      "   3  290 / 2728 loss = 0.2067\n",
      "   3  300 / 2728 loss = 0.2363\n",
      "   3  310 / 2728 loss = 0.3023\n",
      "   3  320 / 2728 loss = 0.3086\n",
      "   3  330 / 2728 loss = 0.3779\n",
      "   3  340 / 2728 loss = 0.2104\n",
      "   3  350 / 2728 loss = 0.2138\n",
      "   3  360 / 2728 loss = 0.1995\n",
      "   3  370 / 2728 loss = 0.2160\n",
      "   3  380 / 2728 loss = 0.1969\n",
      "   3  390 / 2728 loss = 0.1982\n",
      "   3  400 / 2728 loss = 0.1979\n",
      "   3  410 / 2728 loss = 0.2281\n",
      "   3  420 / 2728 loss = 0.2260\n",
      "   3  430 / 2728 loss = 0.1975\n",
      "   3  440 / 2728 loss = 0.2017\n",
      "   3  450 / 2728 loss = 0.2167\n",
      "   3  460 / 2728 loss = 0.2821\n",
      "   3  470 / 2728 loss = 0.2267\n",
      "   3  480 / 2728 loss = 0.2152\n",
      "   3  490 / 2728 loss = 0.2090\n",
      "   3  500 / 2728 loss = 0.2282\n",
      "   3  510 / 2728 loss = 0.2005\n",
      "   3  520 / 2728 loss = 0.2022\n",
      "   3  530 / 2728 loss = 0.2050\n",
      "   3  540 / 2728 loss = 0.1984\n",
      "   3  550 / 2728 loss = 0.2584\n",
      "   3  560 / 2728 loss = 0.1986\n",
      "   3  570 / 2728 loss = 0.2001\n",
      "   3  580 / 2728 loss = 0.2949\n",
      "   3  590 / 2728 loss = 0.2231\n",
      "   3  600 / 2728 loss = 0.2352\n",
      "   3  610 / 2728 loss = 0.2604\n",
      "   3  620 / 2728 loss = 0.2104\n",
      "   3  630 / 2728 loss = 0.1980\n",
      "   3  640 / 2728 loss = 0.3019\n",
      "   3  650 / 2728 loss = 0.2063\n",
      "   3  660 / 2728 loss = 0.2001\n",
      "   3  670 / 2728 loss = 0.2349\n",
      "   3  680 / 2728 loss = 0.2746\n",
      "   3  690 / 2728 loss = 0.2300\n",
      "   3  700 / 2728 loss = 0.2395\n",
      "   3  710 / 2728 loss = 0.2039\n",
      "   3  720 / 2728 loss = 0.5826\n",
      "   3  730 / 2728 loss = 0.2975\n",
      "   3  740 / 2728 loss = 0.2817\n",
      "   3  750 / 2728 loss = 0.3272\n",
      "   3  760 / 2728 loss = 0.2815\n",
      "   3  770 / 2728 loss = 0.4020\n",
      "   3  780 / 2728 loss = 0.2994\n",
      "   3  790 / 2728 loss = 0.3358\n",
      "   3  800 / 2728 loss = 0.2266\n",
      "   3  810 / 2728 loss = 0.2009\n",
      "   3  820 / 2728 loss = 0.2078\n",
      "   3  830 / 2728 loss = 0.2623\n",
      "   3  840 / 2728 loss = 0.2222\n",
      "   3  850 / 2728 loss = 0.2147\n",
      "   3  860 / 2728 loss = 0.2244\n",
      "   3  870 / 2728 loss = 0.2550\n",
      "   3  880 / 2728 loss = 0.1984\n",
      "   3  890 / 2728 loss = 0.1988\n",
      "   3  900 / 2728 loss = 0.2204\n",
      "   3  910 / 2728 loss = 0.4222\n",
      "   3  920 / 2728 loss = 0.2238\n",
      "   3  930 / 2728 loss = 0.4434\n",
      "   3  940 / 2728 loss = 0.2753\n",
      "   3  950 / 2728 loss = 0.2385\n",
      "   3  960 / 2728 loss = 0.2109\n",
      "   3  970 / 2728 loss = 0.2695\n",
      "   3  980 / 2728 loss = 0.2391\n",
      "   3  990 / 2728 loss = 0.3129\n",
      "   3 1000 / 2728 loss = 0.2105\n",
      "   3 1010 / 2728 loss = 0.1991\n",
      "   3 1020 / 2728 loss = 0.2194\n",
      "   3 1030 / 2728 loss = 0.2008\n",
      "   3 1040 / 2728 loss = 0.2035\n",
      "   3 1050 / 2728 loss = 0.2010\n",
      "   3 1060 / 2728 loss = 0.2386\n",
      "   3 1070 / 2728 loss = 0.2216\n",
      "   3 1080 / 2728 loss = 0.2847\n",
      "   3 1090 / 2728 loss = 0.2107\n",
      "   3 1100 / 2728 loss = 0.2101\n",
      "   3 1110 / 2728 loss = 0.2273\n",
      "   3 1120 / 2728 loss = 0.2150\n",
      "   3 1130 / 2728 loss = 0.2011\n",
      "   3 1140 / 2728 loss = 0.2017\n",
      "   3 1150 / 2728 loss = 0.2052\n",
      "   3 1160 / 2728 loss = 0.2006\n",
      "   3 1170 / 2728 loss = 0.2174\n",
      "   3 1180 / 2728 loss = 0.2571\n",
      "   3 1190 / 2728 loss = 0.1982\n",
      "   3 1200 / 2728 loss = 0.2175\n",
      "   3 1210 / 2728 loss = 0.3073\n",
      "   3 1220 / 2728 loss = 0.2655\n",
      "   3 1230 / 2728 loss = 0.2408\n",
      "   3 1240 / 2728 loss = 0.2205\n",
      "   3 1250 / 2728 loss = 0.2279\n",
      "   3 1260 / 2728 loss = 0.2547\n",
      "   3 1270 / 2728 loss = 0.4957\n",
      "   3 1280 / 2728 loss = 2.7483\n",
      "   3 1290 / 2728 loss = 5.7677\n",
      "   3 1300 / 2728 loss = 2.6262\n",
      "   3 1310 / 2728 loss = 3.3730\n",
      "   3 1320 / 2728 loss = 1.8611\n",
      "   3 1330 / 2728 loss = 0.4943\n",
      "   3 1340 / 2728 loss = 0.3420\n",
      "   3 1350 / 2728 loss = 0.2396\n",
      "   3 1360 / 2728 loss = 0.2111\n",
      "   3 1370 / 2728 loss = 0.2004\n",
      "   3 1380 / 2728 loss = 0.2071\n",
      "   3 1390 / 2728 loss = 0.2035\n",
      "   3 1400 / 2728 loss = 0.2116\n",
      "   3 1410 / 2728 loss = 0.2018\n",
      "   3 1420 / 2728 loss = 0.2038\n",
      "   3 1430 / 2728 loss = 0.1986\n",
      "   3 1440 / 2728 loss = 0.2015\n",
      "   3 1450 / 2728 loss = 0.2031\n",
      "   3 1460 / 2728 loss = 0.2079\n",
      "   3 1470 / 2728 loss = 0.2000\n",
      "   3 1480 / 2728 loss = 0.2016\n",
      "   3 1490 / 2728 loss = 0.2072\n",
      "   3 1500 / 2728 loss = 0.2007\n",
      "   3 1510 / 2728 loss = 0.2022\n",
      "   3 1520 / 2728 loss = 0.1985\n",
      "   3 1530 / 2728 loss = 0.2015\n",
      "   3 1540 / 2728 loss = 0.1992\n",
      "   3 1550 / 2728 loss = 0.2048\n",
      "   3 1560 / 2728 loss = 0.1981\n",
      "   3 1570 / 2728 loss = 0.2036\n",
      "   3 1580 / 2728 loss = 0.2029\n",
      "   3 1590 / 2728 loss = 0.2011\n",
      "   3 1600 / 2728 loss = 0.2048\n",
      "   3 1610 / 2728 loss = 0.1991\n",
      "   3 1620 / 2728 loss = 0.1992\n",
      "   3 1630 / 2728 loss = 0.2023\n",
      "   3 1640 / 2728 loss = 0.1990\n",
      "   3 1650 / 2728 loss = 0.1985\n",
      "   3 1660 / 2728 loss = 0.2008\n",
      "   3 1670 / 2728 loss = 0.1998\n",
      "   3 1680 / 2728 loss = 0.1987\n",
      "   3 1690 / 2728 loss = 0.2065\n",
      "   3 1700 / 2728 loss = 0.2022\n",
      "   3 1710 / 2728 loss = 0.1987\n",
      "   3 1720 / 2728 loss = 0.1987\n",
      "   3 1730 / 2728 loss = 0.1983\n",
      "   3 1740 / 2728 loss = 0.2018\n",
      "   3 1750 / 2728 loss = 0.1967\n",
      "   3 1760 / 2728 loss = 0.1976\n",
      "   3 1770 / 2728 loss = 0.1979\n",
      "   3 1780 / 2728 loss = 0.1994\n",
      "   3 1790 / 2728 loss = 0.1977\n",
      "   3 1800 / 2728 loss = 0.1988\n",
      "   3 1810 / 2728 loss = 0.2014\n",
      "   3 1820 / 2728 loss = 0.1973\n",
      "   3 1830 / 2728 loss = 0.1982\n",
      "   3 1840 / 2728 loss = 0.1981\n",
      "   3 1850 / 2728 loss = 0.1980\n",
      "   3 1860 / 2728 loss = 0.2010\n",
      "   3 1870 / 2728 loss = 0.2006\n",
      "   3 1880 / 2728 loss = 0.2197\n",
      "   3 1890 / 2728 loss = 0.1995\n",
      "   3 1900 / 2728 loss = 0.1988\n",
      "   3 1910 / 2728 loss = 0.1980\n",
      "   3 1920 / 2728 loss = 0.2021\n",
      "   3 1930 / 2728 loss = 0.1984\n",
      "   3 1940 / 2728 loss = 0.2036\n",
      "   3 1950 / 2728 loss = 0.1977\n",
      "   3 1960 / 2728 loss = 0.2233\n",
      "   3 1970 / 2728 loss = 0.2149\n",
      "   3 1980 / 2728 loss = 0.1997\n",
      "   3 1990 / 2728 loss = 0.2186\n",
      "   3 2000 / 2728 loss = 0.2097\n",
      "   3 2010 / 2728 loss = 0.2077\n",
      "   3 2020 / 2728 loss = 0.2009\n",
      "   3 2030 / 2728 loss = 0.1957\n",
      "   3 2040 / 2728 loss = 0.2015\n",
      "   3 2050 / 2728 loss = 0.2065\n",
      "   3 2060 / 2728 loss = 0.2112\n",
      "   3 2070 / 2728 loss = 0.2059\n",
      "   3 2080 / 2728 loss = 0.3835\n",
      "   3 2090 / 2728 loss = 0.2440\n",
      "   3 2100 / 2728 loss = 0.1964\n",
      "   3 2110 / 2728 loss = 0.2161\n",
      "   3 2120 / 2728 loss = 0.2361\n",
      "   3 2130 / 2728 loss = 0.1984\n",
      "   3 2140 / 2728 loss = 0.2099\n",
      "   3 2150 / 2728 loss = 0.4332\n",
      "   3 2160 / 2728 loss = 0.2742\n",
      "   3 2170 / 2728 loss = 0.4303\n",
      "   3 2180 / 2728 loss = 0.2027\n",
      "   3 2190 / 2728 loss = 0.3641\n",
      "   3 2200 / 2728 loss = 0.1980\n",
      "   3 2210 / 2728 loss = 0.1982\n",
      "   3 2220 / 2728 loss = 0.1990\n",
      "   3 2230 / 2728 loss = 0.2011\n",
      "   3 2240 / 2728 loss = 0.1987\n",
      "   3 2250 / 2728 loss = 0.2442\n",
      "   3 2260 / 2728 loss = 0.2313\n",
      "   3 2270 / 2728 loss = 0.2092\n",
      "   3 2280 / 2728 loss = 0.4528\n",
      "   3 2290 / 2728 loss = 0.2210\n",
      "   3 2300 / 2728 loss = 0.4023\n",
      "   3 2310 / 2728 loss = 0.2173\n",
      "   3 2320 / 2728 loss = 0.3561\n",
      "   3 2330 / 2728 loss = 0.4030\n",
      "   3 2340 / 2728 loss = 0.2021\n",
      "   3 2350 / 2728 loss = 0.2986\n",
      "   3 2360 / 2728 loss = 0.2486\n",
      "   3 2370 / 2728 loss = 0.2004\n",
      "   3 2380 / 2728 loss = 0.2128\n",
      "   3 2390 / 2728 loss = 0.2062\n",
      "   3 2400 / 2728 loss = 0.2307\n",
      "   3 2410 / 2728 loss = 0.3333\n",
      "   3 2420 / 2728 loss = 0.2493\n",
      "   3 2430 / 2728 loss = 0.3615\n",
      "   3 2440 / 2728 loss = 0.3564\n",
      "   3 2450 / 2728 loss = 0.4199\n",
      "   3 2460 / 2728 loss = 0.4954\n",
      "   3 2470 / 2728 loss = 0.5244\n",
      "   3 2480 / 2728 loss = 0.4675\n",
      "   3 2490 / 2728 loss = 0.2037\n",
      "   3 2500 / 2728 loss = 0.2353\n",
      "   3 2510 / 2728 loss = 0.2833\n",
      "   3 2520 / 2728 loss = 0.2626\n",
      "   3 2530 / 2728 loss = 0.9756\n",
      "   3 2540 / 2728 loss = 0.2006\n",
      "   3 2550 / 2728 loss = 0.2112\n",
      "   3 2560 / 2728 loss = 0.2897\n",
      "   3 2570 / 2728 loss = 0.6880\n",
      "   3 2580 / 2728 loss = 0.3175\n",
      "   3 2590 / 2728 loss = 0.1981\n",
      "   3 2600 / 2728 loss = 0.2099\n",
      "   3 2610 / 2728 loss = 0.2174\n",
      "   3 2620 / 2728 loss = 0.2441\n",
      "   3 2630 / 2728 loss = 0.2524\n",
      "   3 2640 / 2728 loss = 0.2209\n",
      "   3 2650 / 2728 loss = 0.2376\n",
      "   3 2660 / 2728 loss = 0.2479\n",
      "   3 2670 / 2728 loss = 0.2020\n",
      "   3 2680 / 2728 loss = 0.2059\n",
      "   3 2690 / 2728 loss = 0.2836\n",
      "   3 2700 / 2728 loss = 0.2121\n",
      "   3 2710 / 2728 loss = 0.2108\n",
      "   3 2720 / 2728 loss = 0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [18:30<00:00, 370.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 05:25:42: epcoh =    3 , loss = 20.3572 , time = 368.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
