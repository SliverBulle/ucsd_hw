{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d9a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, time, datetime\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.io import imread, imsave\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0feb1e18-ee44-4d10-ae65-59b62815efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "223966b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--set_dir', default='data/Test', type=str, help='directory of test dataset')\n",
    "    parser.add_argument('--set_names', default=['Set68', 'Set12'], help='directory of test dataset')\n",
    "    parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "    parser.add_argument('--model_dir', default=os.path.join('models', 'DnCNN_sigma4'), help='directory of the model')\n",
    "    parser.add_argument('--model_name', default='model_003.pth', type=str, help='the model name')\n",
    "    parser.add_argument('--result_dir', default='results', type=str, help='directory of test dataset')\n",
    "    parser.add_argument('--save_result', default=0, type=int, help='save the denoised image, 1 or 0')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n",
    "\n",
    "\n",
    "def save_result(result, path):\n",
    "    path = path if path.find('.') != -1 else path+'.png'\n",
    "    ext = os.path.splitext(path)[-1]\n",
    "    if ext in ('.txt', '.dlm'):\n",
    "        np.savetxt(path, result, fmt='%2.4f')\n",
    "    else:\n",
    "        imsave(path, np.clip(result, 0, 1))\n",
    "\n",
    "\n",
    "def show(x, title=None, cbar=False, figsize=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(x, interpolation='nearest', cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if cbar:\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63e9925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Blocks(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, padding = 1):\n",
    "        super(Residual_Blocks, self).__init__()\n",
    "        self.convx_1 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.Leakyrelu = nn.LeakyReLU(inplace=True)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.convx_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.Leakyrelu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.BN(self.Leakyrelu(self.convx_1(x)))\n",
    "        out = self.BN(self.Leakyrelu(self.convx_2(x)))\n",
    "        return out\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, reduction=8):\n",
    "        super(Attention, self).__init__()\n",
    "        self.red = reduction\n",
    "        self.query = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.value = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.key = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channels=64//self.red, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        query = self.query(x).view(b, -1, h*w)\n",
    "        value = self.value(x).view(b, -1, h*w)\n",
    "        key = self.key(x).view(b, -1, h*w)\n",
    "        mul_1 = torch.bmm(query, value.transpose(1,2))\n",
    "        attention_weights = mul_1 / np.sqrt(64//self.red)\n",
    "        res_1 = nn.functional.softmax(attention_weights, dim=-1)\n",
    "        mul_2 = torch.bmm(res_1, key).view(b, -1, h, w)\n",
    "        out = self.out(mul_2)\n",
    "        return x + out\n",
    "\n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, image_channels=1):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(image_channels, n_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.attention = Attention()\n",
    "        self.act = nn.LeakyReLU(inplace=True)\n",
    "        self.out = nn.Sequential(*[Residual_Blocks() for _ in range(1)])\n",
    "        self.dn = nn.Conv2d(64, 1, kernel_size=3, padding=1, bias=True)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.act(self.attention(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.dn(out)\n",
    "        return dn\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28af0e9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/DnCNN_sigma4/model_003.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m args \u001b[38;5;241m=\u001b[39m parse_args([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--set_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Test\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--set_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet68\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet12\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--sigma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--model_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/DnCNN_sigma4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--model_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_003.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--result_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--save_result\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mmodel_dir, args\u001b[38;5;241m.\u001b[39mmodel_name)):\n\u001b[0;32m---> 18\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_003.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# load weights into new model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload trained model on Train400 dataset by kai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/DnCNN_sigma4/model_003.pth'"
     ]
    }
   ],
   "source": [
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--set_dir', default='data/Test', type=str, help='directory of test dataset')\n",
    "    parser.add_argument('--set_names', nargs='+', default=['Set68', 'Set12'], help='list of dataset names')\n",
    "    parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "    parser.add_argument('--model_dir', default='models/DnCNN_sigma4', type=str, help='directory of the model')\n",
    "    parser.add_argument('--model_name', default='model_003.pth', type=str, help='the model name')\n",
    "    parser.add_argument('--result_dir', default='results', type=str, help='directory for storing results')\n",
    "    parser.add_argument('--save_result', default=False, action='store_true', help='save the denoised image, true or false')\n",
    "\n",
    "    return parser.parse_args(args)\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    args = parse_args(['--set_dir', 'data/Test', '--set_names', 'Set68', 'Set12', '--sigma', '4', '--model_dir', 'models/DnCNN_sigma4', '--model_name', 'model_003.pth', '--result_dir', 'results', '--save_result'])\n",
    "\n",
    "    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):\n",
    "\n",
    "        model = torch.load(os.path.join(args.model_dir, 'model_003.pth'))\n",
    "        # load weights into new model\n",
    "        log('load trained model on Train400 dataset by kai')\n",
    "    else:\n",
    "        # model.load_state_dict(torch.load(os.path.join(args.model_dir, args.model_name)))\n",
    "        model = torch.load(os.path.join(args.model_dir, args.model_name))\n",
    "        log('load trained model')\n",
    "\n",
    "#    params = model.state_dict()\n",
    "#    print(params.values())\n",
    "#    print(params.keys())\n",
    "#\n",
    "#    for key, value in params.items():\n",
    "#        print(key)    # parameter name\n",
    "#    print(params['dncnn.12.running_mean'])\n",
    "#    print(model.state_dict())\n",
    "\n",
    "    model.eval()  # evaluation mode\n",
    "#    model.train()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.mkdir(args.result_dir)\n",
    "\n",
    "    for set_cur in args.set_names:\n",
    "\n",
    "        if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n",
    "            os.mkdir(os.path.join(args.result_dir, set_cur))\n",
    "        psnrs = []\n",
    "        ssims = []\n",
    "\n",
    "        for im in os.listdir(os.path.join(args.set_dir, set_cur)):\n",
    "            if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\n",
    "\n",
    "                x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32)/255.0\n",
    "                np.random.seed(seed=0)  # for reproducibility\n",
    "                y = x + np.random.normal(0, args.sigma/255.0, x.shape)  # Add Gaussian noise without clipping\n",
    "                y = y.astype(np.float32)\n",
    "                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                start_time = time.time()\n",
    "                y_ = y_.cuda()\n",
    "                x_ = model(y_)  # inference\n",
    "                x_ = x_.view(y.shape[0], y.shape[1])\n",
    "                x_ = x_.cpu()\n",
    "                x_ = x_.detach().numpy().astype(np.float32)\n",
    "                torch.cuda.synchronize()\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\n",
    "\n",
    "                im_x = np.array(x, dtype=np.float32)\n",
    "                im_x_ = np.array(x_, dtype=np.float32)\n",
    "                data_range = im_x.max() - im_x.min()\n",
    "\n",
    "                psnr_x_ = compare_psnr(x, x_)\n",
    "                ssim_x_ = compare_ssim(x, x_, data_range = data_range)\n",
    "                if args.save_result:\n",
    "                    name, ext = os.path.splitext(im)\n",
    "                    show(np.hstack((y, x_)))  # show the image\n",
    "                    res = np.array(x_)\n",
    "                    res_dn = np.clip(res, 0, 255).astype(np.uint8)\n",
    "                    im_dn = Image.fromarray(res_dn)\n",
    "                    save_result(im_dn, path=os.path.join(args.result_dir, set_cur, name+'_dncnn'+ext))  # save the denoised image\n",
    "                psnrs.append(psnr_x_)\n",
    "                ssims.append(ssim_x_)\n",
    "        psnr_avg = np.mean(psnrs)\n",
    "        ssim_avg = np.mean(ssims)\n",
    "        psnrs.append(psnr_avg)\n",
    "        ssims.append(ssim_avg)\n",
    "        if args.save_result:\n",
    "            save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\n",
    "        log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
