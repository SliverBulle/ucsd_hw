{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c44bf7-acb0-481c-88cf-03e9298a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '64', '--train_data', 'data/Train400', '--sigma', '4', '--epoch', '3', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=3, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "        \n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, out_channels=64, in_channels=1, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_layers = []\n",
    "        for _ in range(10):\n",
    "            for sub in self.make_Residual():\n",
    "                output_layers.append(sub)\n",
    "        self.out = nn.Sequential(*output_layers)\n",
    "        self.res = nn.Conv2d(64, 1, kernel_size=3, padding=1, stride=1)\n",
    "        \n",
    "    def make_Residual(self, in_channels=64, out_channels=64, kernel_size=3):\n",
    "        i = 0\n",
    "        layers = []\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, bias=True))\n",
    "            layers.append(nn.BatchNorm2d(64, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return layers\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.relu(self.BN(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.res(out)\n",
    "        return dn\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^-training data finished-^_^\n",
      "   1    0 / 2728 loss = 4456.5649\n",
      "   1   10 / 2728 loss = 1448.0883\n",
      "   1   20 / 2728 loss = 984.8729\n",
      "   1   30 / 2728 loss = 654.9639\n",
      "   1   40 / 2728 loss = 374.7516\n",
      "   1   50 / 2728 loss = 297.6810\n",
      "   1   60 / 2728 loss = 258.7581\n",
      "   1   70 / 2728 loss = 224.7777\n",
      "   1   80 / 2728 loss = 248.0746\n",
      "   1   90 / 2728 loss = 170.3078\n",
      "   1  100 / 2728 loss = 152.8036\n",
      "   1  110 / 2728 loss = 156.1373\n",
      "   1  120 / 2728 loss = 122.0618\n",
      "   1  130 / 2728 loss = 102.7961\n",
      "   1  140 / 2728 loss = 97.9845\n",
      "   1  150 / 2728 loss = 84.7896\n",
      "   1  160 / 2728 loss = 92.1766\n",
      "   1  170 / 2728 loss = 72.6370\n",
      "   1  180 / 2728 loss = 90.2166\n",
      "   1  190 / 2728 loss = 62.2101\n",
      "   1  200 / 2728 loss = 68.6387\n",
      "   1  210 / 2728 loss = 109.7892\n",
      "   1  220 / 2728 loss = 62.4841\n",
      "   1  230 / 2728 loss = 53.5848\n",
      "   1  240 / 2728 loss = 52.8305\n",
      "   1  250 / 2728 loss = 68.1986\n",
      "   1  260 / 2728 loss = 54.0270\n",
      "   1  270 / 2728 loss = 64.2407\n",
      "   1  280 / 2728 loss = 62.8281\n",
      "   1  290 / 2728 loss = 45.9484\n",
      "   1  300 / 2728 loss = 57.1243\n",
      "   1  310 / 2728 loss = 48.7329\n",
      "   1  320 / 2728 loss = 80.2071\n",
      "   1  330 / 2728 loss = 51.6420\n",
      "   1  340 / 2728 loss = 116.9011\n",
      "   1  350 / 2728 loss = 49.1866\n",
      "   1  360 / 2728 loss = 53.8095\n",
      "   1  370 / 2728 loss = 41.0427\n",
      "   1  380 / 2728 loss = 94.1701\n",
      "   1  390 / 2728 loss = 55.6177\n",
      "   1  400 / 2728 loss = 69.9562\n",
      "   1  410 / 2728 loss = 36.7095\n",
      "   1  420 / 2728 loss = 55.6598\n",
      "   1  430 / 2728 loss = 34.4110\n",
      "   1  440 / 2728 loss = 35.3071\n",
      "   1  450 / 2728 loss = 33.7169\n",
      "   1  460 / 2728 loss = 56.1734\n",
      "   1  470 / 2728 loss = 28.4668\n",
      "   1  480 / 2728 loss = 32.8332\n",
      "   1  490 / 2728 loss = 32.7844\n",
      "   1  500 / 2728 loss = 46.7765\n",
      "   1  510 / 2728 loss = 35.5067\n",
      "   1  520 / 2728 loss = 54.8175\n",
      "   1  530 / 2728 loss = 47.8340\n",
      "   1  540 / 2728 loss = 35.3746\n",
      "   1  550 / 2728 loss = 42.7473\n",
      "   1  560 / 2728 loss = 50.6489\n",
      "   1  570 / 2728 loss = 36.8904\n",
      "   1  580 / 2728 loss = 68.4428\n",
      "   1  590 / 2728 loss = 33.0559\n",
      "   1  600 / 2728 loss = 53.0840\n",
      "   1  610 / 2728 loss = 66.3870\n",
      "   1  620 / 2728 loss = 28.6973\n",
      "   1  630 / 2728 loss = 29.5685\n",
      "   1  640 / 2728 loss = 72.2495\n",
      "   1  650 / 2728 loss = 34.3142\n",
      "   1  660 / 2728 loss = 53.5139\n",
      "   1  670 / 2728 loss = 57.9833\n",
      "   1  680 / 2728 loss = 34.4368\n",
      "   1  690 / 2728 loss = 35.8778\n",
      "   1  700 / 2728 loss = 50.6953\n",
      "   1  710 / 2728 loss = 28.2769\n",
      "   1  720 / 2728 loss = 41.4635\n",
      "   1  730 / 2728 loss = 26.0105\n",
      "   1  740 / 2728 loss = 23.4518\n",
      "   1  750 / 2728 loss = 26.3889\n",
      "   1  760 / 2728 loss = 22.2626\n",
      "   1  770 / 2728 loss = 28.0723\n",
      "   1  780 / 2728 loss = 29.7535\n",
      "   1  790 / 2728 loss = 22.8661\n",
      "   1  800 / 2728 loss = 26.0214\n",
      "   1  810 / 2728 loss = 23.0712\n",
      "   1  820 / 2728 loss = 26.7950\n",
      "   1  830 / 2728 loss = 20.5025\n",
      "   1  840 / 2728 loss = 88.0297\n",
      "   1  850 / 2728 loss = 36.4512\n",
      "   1  860 / 2728 loss = 42.8942\n",
      "   1  870 / 2728 loss = 22.8556\n",
      "   1  880 / 2728 loss = 32.8983\n",
      "   1  890 / 2728 loss = 29.7310\n",
      "   1  900 / 2728 loss = 17.7779\n",
      "   1  910 / 2728 loss = 24.9007\n",
      "   1  920 / 2728 loss = 19.3773\n",
      "   1  930 / 2728 loss = 26.4980\n",
      "   1  940 / 2728 loss = 22.3149\n",
      "   1  950 / 2728 loss = 28.6100\n",
      "   1  960 / 2728 loss = 49.6199\n",
      "   1  970 / 2728 loss = 45.3421\n",
      "   1  980 / 2728 loss = 22.8216\n",
      "   1  990 / 2728 loss = 24.0337\n",
      "   1 1000 / 2728 loss = 61.4671\n",
      "   1 1010 / 2728 loss = 34.0067\n",
      "   1 1020 / 2728 loss = 19.3881\n",
      "   1 1030 / 2728 loss = 20.8490\n",
      "   1 1040 / 2728 loss = 18.6793\n",
      "   1 1050 / 2728 loss = 23.8265\n",
      "   1 1060 / 2728 loss = 28.2776\n",
      "   1 1070 / 2728 loss = 29.5156\n",
      "   1 1080 / 2728 loss = 31.6306\n",
      "   1 1090 / 2728 loss = 37.3790\n",
      "   1 1100 / 2728 loss = 35.4697\n",
      "   1 1110 / 2728 loss = 38.6761\n",
      "   1 1120 / 2728 loss = 26.1655\n",
      "   1 1130 / 2728 loss = 16.8962\n",
      "   1 1140 / 2728 loss = 19.9834\n",
      "   1 1150 / 2728 loss = 21.7383\n",
      "   1 1160 / 2728 loss = 23.8050\n",
      "   1 1170 / 2728 loss = 40.8931\n",
      "   1 1180 / 2728 loss = 80.3566\n",
      "   1 1190 / 2728 loss = 18.9766\n",
      "   1 1200 / 2728 loss = 37.3175\n",
      "   1 1210 / 2728 loss = 34.0997\n",
      "   1 1220 / 2728 loss = 20.9492\n",
      "   1 1230 / 2728 loss = 18.5194\n",
      "   1 1240 / 2728 loss = 17.3382\n",
      "   1 1250 / 2728 loss = 25.4698\n",
      "   1 1260 / 2728 loss = 23.8798\n",
      "   1 1270 / 2728 loss = 23.9103\n",
      "   1 1280 / 2728 loss = 73.9229\n",
      "   1 1290 / 2728 loss = 44.4253\n",
      "   1 1300 / 2728 loss = 25.0993\n",
      "   1 1310 / 2728 loss = 31.6614\n",
      "   1 1320 / 2728 loss = 32.0945\n",
      "   1 1330 / 2728 loss = 47.6367\n",
      "   1 1340 / 2728 loss = 39.0977\n",
      "   1 1350 / 2728 loss = 46.0064\n",
      "   1 1360 / 2728 loss = 27.8889\n",
      "   1 1370 / 2728 loss = 19.1803\n",
      "   1 1380 / 2728 loss = 14.9456\n",
      "   1 1390 / 2728 loss = 29.0000\n",
      "   1 1400 / 2728 loss = 30.0422\n",
      "   1 1410 / 2728 loss = 32.1779\n",
      "   1 1420 / 2728 loss = 17.2506\n",
      "   1 1430 / 2728 loss = 16.3981\n",
      "   1 1440 / 2728 loss = 31.0746\n",
      "   1 1450 / 2728 loss = 16.9082\n",
      "   1 1460 / 2728 loss = 22.3943\n",
      "   1 1470 / 2728 loss = 15.6747\n",
      "   1 1480 / 2728 loss = 15.0320\n",
      "   1 1490 / 2728 loss = 51.6955\n",
      "   1 1500 / 2728 loss = 88.4416\n",
      "   1 1510 / 2728 loss = 23.9280\n",
      "   1 1520 / 2728 loss = 21.8610\n",
      "   1 1530 / 2728 loss = 29.3582\n",
      "   1 1540 / 2728 loss = 29.7767\n",
      "   1 1550 / 2728 loss = 23.9044\n",
      "   1 1560 / 2728 loss = 18.4270\n",
      "   1 1570 / 2728 loss = 38.7962\n",
      "   1 1580 / 2728 loss = 39.2533\n",
      "   1 1590 / 2728 loss = 18.5040\n",
      "   1 1600 / 2728 loss = 40.3173\n",
      "   1 1610 / 2728 loss = 38.1635\n",
      "   1 1620 / 2728 loss = 33.7798\n",
      "   1 1630 / 2728 loss = 18.3311\n",
      "   1 1640 / 2728 loss = 20.9728\n",
      "   1 1650 / 2728 loss = 20.3006\n",
      "   1 1660 / 2728 loss = 22.6612\n",
      "   1 1670 / 2728 loss = 16.5399\n",
      "   1 1680 / 2728 loss = 28.8761\n",
      "   1 1690 / 2728 loss = 51.4405\n",
      "   1 1700 / 2728 loss = 76.1245\n",
      "   1 1710 / 2728 loss = 26.1206\n",
      "   1 1720 / 2728 loss = 12.5152\n",
      "   1 1730 / 2728 loss = 28.5250\n",
      "   1 1740 / 2728 loss = 14.7672\n",
      "   1 1750 / 2728 loss = 17.3044\n",
      "   1 1760 / 2728 loss = 15.6325\n",
      "   1 1770 / 2728 loss = 17.8417\n",
      "   1 1780 / 2728 loss = 13.8158\n",
      "   1 1790 / 2728 loss = 16.7718\n",
      "   1 1800 / 2728 loss = 16.8799\n",
      "   1 1810 / 2728 loss = 19.4868\n",
      "   1 1820 / 2728 loss = 16.1071\n",
      "   1 1830 / 2728 loss = 18.9647\n",
      "   1 1840 / 2728 loss = 32.4287\n",
      "   1 1850 / 2728 loss = 30.5364\n",
      "   1 1860 / 2728 loss = 30.7083\n",
      "   1 1870 / 2728 loss = 22.9838\n",
      "   1 1880 / 2728 loss = 13.4923\n",
      "   1 1890 / 2728 loss = 62.3527\n",
      "   1 1900 / 2728 loss = 11.7697\n",
      "   1 1910 / 2728 loss = 50.2696\n",
      "   1 1920 / 2728 loss = 21.9288\n",
      "   1 1930 / 2728 loss = 43.0963\n",
      "   1 1940 / 2728 loss = 27.6720\n",
      "   1 1950 / 2728 loss = 14.7155\n",
      "   1 1960 / 2728 loss = 15.0631\n",
      "   1 1970 / 2728 loss = 23.9997\n",
      "   1 1980 / 2728 loss = 51.5637\n",
      "   1 1990 / 2728 loss = 29.8106\n",
      "   1 2000 / 2728 loss = 19.7961\n",
      "   1 2010 / 2728 loss = 15.1638\n",
      "   1 2020 / 2728 loss = 17.8817\n",
      "   1 2030 / 2728 loss = 11.9786\n",
      "   1 2040 / 2728 loss = 29.3941\n",
      "   1 2050 / 2728 loss = 30.6414\n",
      "   1 2060 / 2728 loss = 31.0624\n",
      "   1 2070 / 2728 loss = 17.0316\n",
      "   1 2080 / 2728 loss = 13.3246\n",
      "   1 2090 / 2728 loss = 13.4733\n",
      "   1 2100 / 2728 loss = 15.4086\n",
      "   1 2110 / 2728 loss = 15.7721\n",
      "   1 2120 / 2728 loss = 27.4651\n",
      "   1 2130 / 2728 loss = 20.3244\n",
      "   1 2140 / 2728 loss = 19.5499\n",
      "   1 2150 / 2728 loss = 13.6643\n",
      "   1 2160 / 2728 loss = 30.0187\n",
      "   1 2170 / 2728 loss = 12.0700\n",
      "   1 2180 / 2728 loss = 11.1837\n",
      "   1 2190 / 2728 loss = 15.4171\n",
      "   1 2200 / 2728 loss = 35.9808\n",
      "   1 2210 / 2728 loss = 24.2606\n",
      "   1 2220 / 2728 loss = 16.7813\n",
      "   1 2230 / 2728 loss = 13.9829\n",
      "   1 2240 / 2728 loss = 18.2265\n",
      "   1 2250 / 2728 loss = 43.8188\n",
      "   1 2260 / 2728 loss = 15.8800\n",
      "   1 2270 / 2728 loss = 24.0047\n",
      "   1 2280 / 2728 loss = 86.9289\n",
      "   1 2290 / 2728 loss = 20.8460\n",
      "   1 2300 / 2728 loss = 28.9178\n",
      "   1 2310 / 2728 loss = 21.0470\n",
      "   1 2320 / 2728 loss = 21.4516\n",
      "   1 2330 / 2728 loss = 20.9093\n",
      "   1 2340 / 2728 loss = 18.1264\n",
      "   1 2350 / 2728 loss = 15.5217\n",
      "   1 2360 / 2728 loss = 26.0609\n",
      "   1 2370 / 2728 loss = 11.4317\n",
      "   1 2380 / 2728 loss = 28.5823\n",
      "   1 2390 / 2728 loss = 19.4544\n",
      "   1 2400 / 2728 loss = 59.4031\n",
      "   1 2410 / 2728 loss = 21.2930\n",
      "   1 2420 / 2728 loss = 12.6138\n",
      "   1 2430 / 2728 loss = 14.4514\n",
      "   1 2440 / 2728 loss = 24.3665\n",
      "   1 2450 / 2728 loss = 11.4836\n",
      "   1 2460 / 2728 loss = 25.1863\n",
      "   1 2470 / 2728 loss = 14.1846\n",
      "   1 2480 / 2728 loss = 10.8589\n",
      "   1 2490 / 2728 loss = 26.1699\n",
      "   1 2500 / 2728 loss = 21.7214\n",
      "   1 2510 / 2728 loss = 15.7935\n",
      "   1 2520 / 2728 loss = 23.1072\n",
      "   1 2530 / 2728 loss = 56.6654\n",
      "   1 2540 / 2728 loss = 24.7138\n",
      "   1 2550 / 2728 loss = 16.4703\n",
      "   1 2560 / 2728 loss = 10.7127\n",
      "   1 2570 / 2728 loss = 15.0552\n",
      "   1 2580 / 2728 loss = 11.2425\n",
      "   1 2590 / 2728 loss = 15.0861\n",
      "   1 2600 / 2728 loss = 14.8584\n",
      "   1 2610 / 2728 loss = 16.3177\n",
      "   1 2620 / 2728 loss = 13.1933\n",
      "   1 2630 / 2728 loss = 39.2661\n",
      "   1 2640 / 2728 loss = 13.5528\n",
      "   1 2650 / 2728 loss = 18.2314\n",
      "   1 2660 / 2728 loss = 29.8016\n",
      "   1 2670 / 2728 loss = 18.2865\n",
      "   1 2680 / 2728 loss = 31.7636\n",
      "   1 2690 / 2728 loss = 17.8431\n",
      "   1 2700 / 2728 loss = 26.4812\n",
      "   1 2710 / 2728 loss = 35.6517\n",
      "   1 2720 / 2728 loss = 23.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:52<07:44, 232.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 03:16:21: epcoh =    1 , loss = 3632.2472 , time = 230.02 s\n",
      "^_^-training data finished-^_^\n",
      "   2    0 / 2728 loss = 12.5466\n",
      "   2   10 / 2728 loss = 26.6247\n",
      "   2   20 / 2728 loss = 38.4835\n",
      "   2   30 / 2728 loss = 24.6686\n",
      "   2   40 / 2728 loss = 24.0222\n",
      "   2   50 / 2728 loss = 25.2037\n",
      "   2   60 / 2728 loss = 59.3731\n",
      "   2   70 / 2728 loss = 18.6037\n",
      "   2   80 / 2728 loss = 25.0113\n",
      "   2   90 / 2728 loss = 11.1854\n",
      "   2  100 / 2728 loss = 20.9979\n",
      "   2  110 / 2728 loss = 20.1346\n",
      "   2  120 / 2728 loss = 16.9313\n",
      "   2  130 / 2728 loss = 31.0983\n",
      "   2  140 / 2728 loss = 25.6598\n",
      "   2  150 / 2728 loss = 22.0393\n",
      "   2  160 / 2728 loss = 16.7425\n",
      "   2  170 / 2728 loss = 46.6616\n",
      "   2  180 / 2728 loss = 12.4737\n",
      "   2  190 / 2728 loss = 19.2847\n",
      "   2  200 / 2728 loss = 12.4561\n",
      "   2  210 / 2728 loss = 20.7970\n",
      "   2  220 / 2728 loss = 15.7941\n",
      "   2  230 / 2728 loss = 13.9002\n",
      "   2  240 / 2728 loss = 29.9998\n",
      "   2  250 / 2728 loss = 15.8242\n",
      "   2  260 / 2728 loss = 23.9696\n",
      "   2  270 / 2728 loss = 20.4426\n",
      "   2  280 / 2728 loss = 16.6376\n",
      "   2  290 / 2728 loss = 83.1613\n",
      "   2  300 / 2728 loss = 33.8572\n",
      "   2  310 / 2728 loss = 32.6653\n",
      "   2  320 / 2728 loss = 15.0572\n",
      "   2  330 / 2728 loss = 22.5756\n",
      "   2  340 / 2728 loss = 22.7751\n",
      "   2  350 / 2728 loss = 17.6980\n",
      "   2  360 / 2728 loss = 30.6497\n",
      "   2  370 / 2728 loss = 16.4395\n",
      "   2  380 / 2728 loss = 20.7016\n",
      "   2  390 / 2728 loss = 11.8116\n",
      "   2  400 / 2728 loss = 20.3905\n",
      "   2  410 / 2728 loss = 17.7357\n",
      "   2  420 / 2728 loss = 9.3214\n",
      "   2  430 / 2728 loss = 24.3025\n",
      "   2  440 / 2728 loss = 10.1611\n",
      "   2  450 / 2728 loss = 9.2261\n",
      "   2  460 / 2728 loss = 14.6774\n",
      "   2  470 / 2728 loss = 11.6937\n",
      "   2  480 / 2728 loss = 10.1515\n",
      "   2  490 / 2728 loss = 43.4327\n",
      "   2  500 / 2728 loss = 9.5852\n",
      "   2  510 / 2728 loss = 16.5924\n",
      "   2  520 / 2728 loss = 9.4163\n",
      "   2  530 / 2728 loss = 8.3417\n",
      "   2  540 / 2728 loss = 16.8841\n",
      "   2  550 / 2728 loss = 28.2461\n",
      "   2  560 / 2728 loss = 109.2793\n",
      "   2  570 / 2728 loss = 69.0514\n",
      "   2  580 / 2728 loss = 62.3632\n",
      "   2  590 / 2728 loss = 44.0456\n",
      "   2  600 / 2728 loss = 22.6510\n",
      "   2  610 / 2728 loss = 51.1887\n",
      "   2  620 / 2728 loss = 27.7796\n",
      "   2  630 / 2728 loss = 81.1656\n",
      "   2  640 / 2728 loss = 57.9359\n",
      "   2  650 / 2728 loss = 14.4718\n",
      "   2  660 / 2728 loss = 21.4026\n",
      "   2  670 / 2728 loss = 11.4517\n",
      "   2  680 / 2728 loss = 16.4900\n",
      "   2  690 / 2728 loss = 21.3304\n",
      "   2  700 / 2728 loss = 12.7033\n",
      "   2  710 / 2728 loss = 50.9505\n",
      "   2  720 / 2728 loss = 19.0392\n",
      "   2  730 / 2728 loss = 31.9812\n",
      "   2  740 / 2728 loss = 10.6273\n",
      "   2  750 / 2728 loss = 10.1618\n",
      "   2  760 / 2728 loss = 11.7129\n",
      "   2  770 / 2728 loss = 11.9051\n",
      "   2  780 / 2728 loss = 11.8308\n",
      "   2  790 / 2728 loss = 8.6132\n",
      "   2  800 / 2728 loss = 10.7529\n",
      "   2  810 / 2728 loss = 26.3705\n",
      "   2  820 / 2728 loss = 11.8578\n",
      "   2  830 / 2728 loss = 14.4058\n",
      "   2  840 / 2728 loss = 9.6266\n",
      "   2  850 / 2728 loss = 8.5033\n",
      "   2  860 / 2728 loss = 22.1305\n",
      "   2  870 / 2728 loss = 13.7880\n",
      "   2  880 / 2728 loss = 13.8006\n",
      "   2  890 / 2728 loss = 53.0616\n",
      "   2  900 / 2728 loss = 16.3715\n",
      "   2  910 / 2728 loss = 11.2565\n",
      "   2  920 / 2728 loss = 10.2268\n",
      "   2  930 / 2728 loss = 12.3449\n",
      "   2  940 / 2728 loss = 8.7602\n",
      "   2  950 / 2728 loss = 11.7746\n",
      "   2  960 / 2728 loss = 14.1258\n",
      "   2  970 / 2728 loss = 35.3105\n",
      "   2  980 / 2728 loss = 14.0439\n",
      "   2  990 / 2728 loss = 49.7056\n",
      "   2 1000 / 2728 loss = 36.0479\n",
      "   2 1010 / 2728 loss = 20.7222\n",
      "   2 1020 / 2728 loss = 10.2801\n",
      "   2 1030 / 2728 loss = 17.9647\n",
      "   2 1040 / 2728 loss = 7.4322\n",
      "   2 1050 / 2728 loss = 6.4421\n",
      "   2 1060 / 2728 loss = 16.3811\n",
      "   2 1070 / 2728 loss = 17.6843\n",
      "   2 1080 / 2728 loss = 30.4205\n",
      "   2 1090 / 2728 loss = 12.1175\n",
      "   2 1100 / 2728 loss = 8.3483\n",
      "   2 1110 / 2728 loss = 13.8680\n",
      "   2 1120 / 2728 loss = 39.0690\n",
      "   2 1130 / 2728 loss = 19.6241\n",
      "   2 1140 / 2728 loss = 20.5470\n",
      "   2 1150 / 2728 loss = 14.0283\n",
      "   2 1160 / 2728 loss = 41.8886\n",
      "   2 1170 / 2728 loss = 17.4351\n",
      "   2 1180 / 2728 loss = 29.1175\n",
      "   2 1190 / 2728 loss = 11.1724\n",
      "   2 1200 / 2728 loss = 12.9716\n",
      "   2 1210 / 2728 loss = 9.3812\n",
      "   2 1220 / 2728 loss = 10.2037\n",
      "   2 1230 / 2728 loss = 12.5739\n",
      "   2 1240 / 2728 loss = 6.0781\n",
      "   2 1250 / 2728 loss = 14.4877\n",
      "   2 1260 / 2728 loss = 16.2229\n",
      "   2 1270 / 2728 loss = 8.2919\n",
      "   2 1280 / 2728 loss = 19.9573\n",
      "   2 1290 / 2728 loss = 17.6861\n",
      "   2 1300 / 2728 loss = 8.0064\n",
      "   2 1310 / 2728 loss = 11.6893\n",
      "   2 1320 / 2728 loss = 9.1480\n",
      "   2 1330 / 2728 loss = 10.4520\n",
      "   2 1340 / 2728 loss = 10.4677\n",
      "   2 1350 / 2728 loss = 22.3889\n",
      "   2 1360 / 2728 loss = 29.1840\n",
      "   2 1370 / 2728 loss = 12.8879\n",
      "   2 1380 / 2728 loss = 7.9937\n",
      "   2 1390 / 2728 loss = 30.2080\n",
      "   2 1400 / 2728 loss = 18.9392\n",
      "   2 1410 / 2728 loss = 12.1164\n",
      "   2 1420 / 2728 loss = 9.2123\n",
      "   2 1430 / 2728 loss = 8.1142\n",
      "   2 1440 / 2728 loss = 14.5785\n",
      "   2 1450 / 2728 loss = 11.2314\n",
      "   2 1460 / 2728 loss = 24.5676\n",
      "   2 1470 / 2728 loss = 53.3816\n",
      "   2 1480 / 2728 loss = 9.2568\n",
      "   2 1490 / 2728 loss = 16.7207\n",
      "   2 1500 / 2728 loss = 18.3956\n",
      "   2 1510 / 2728 loss = 36.4586\n",
      "   2 1520 / 2728 loss = 28.2803\n",
      "   2 1530 / 2728 loss = 8.3772\n",
      "   2 1540 / 2728 loss = 11.6033\n",
      "   2 1550 / 2728 loss = 55.7599\n",
      "   2 1560 / 2728 loss = 18.8348\n",
      "   2 1570 / 2728 loss = 8.3934\n",
      "   2 1580 / 2728 loss = 86.3775\n",
      "   2 1590 / 2728 loss = 12.0900\n",
      "   2 1600 / 2728 loss = 8.4910\n",
      "   2 1610 / 2728 loss = 38.3484\n",
      "   2 1620 / 2728 loss = 6.5181\n",
      "   2 1630 / 2728 loss = 37.1671\n",
      "   2 1640 / 2728 loss = 12.2561\n",
      "   2 1650 / 2728 loss = 18.4895\n",
      "   2 1660 / 2728 loss = 12.9971\n",
      "   2 1670 / 2728 loss = 12.4456\n",
      "   2 1680 / 2728 loss = 16.6496\n",
      "   2 1690 / 2728 loss = 9.4593\n",
      "   2 1700 / 2728 loss = 41.7889\n",
      "   2 1710 / 2728 loss = 14.8955\n",
      "   2 1720 / 2728 loss = 14.0527\n",
      "   2 1730 / 2728 loss = 13.7144\n",
      "   2 1740 / 2728 loss = 14.5754\n",
      "   2 1750 / 2728 loss = 19.9145\n",
      "   2 1760 / 2728 loss = 13.1874\n",
      "   2 1770 / 2728 loss = 18.8173\n",
      "   2 1780 / 2728 loss = 8.0815\n",
      "   2 1790 / 2728 loss = 70.4289\n",
      "   2 1800 / 2728 loss = 12.0404\n",
      "   2 1810 / 2728 loss = 19.6238\n",
      "   2 1820 / 2728 loss = 33.9236\n",
      "   2 1830 / 2728 loss = 22.5835\n",
      "   2 1840 / 2728 loss = 10.5207\n",
      "   2 1850 / 2728 loss = 29.0080\n",
      "   2 1860 / 2728 loss = 16.1550\n",
      "   2 1870 / 2728 loss = 15.0311\n",
      "   2 1880 / 2728 loss = 12.0848\n",
      "   2 1890 / 2728 loss = 16.8660\n",
      "   2 1900 / 2728 loss = 15.7385\n",
      "   2 1910 / 2728 loss = 12.8548\n",
      "   2 1920 / 2728 loss = 12.2273\n",
      "   2 1930 / 2728 loss = 36.0980\n",
      "   2 1940 / 2728 loss = 36.8938\n",
      "   2 1950 / 2728 loss = 6.0035\n",
      "   2 1960 / 2728 loss = 34.6639\n",
      "   2 1970 / 2728 loss = 10.7631\n",
      "   2 1980 / 2728 loss = 11.8834\n",
      "   2 1990 / 2728 loss = 17.9727\n",
      "   2 2000 / 2728 loss = 7.8564\n",
      "   2 2010 / 2728 loss = 8.2969\n",
      "   2 2020 / 2728 loss = 26.7995\n",
      "   2 2030 / 2728 loss = 23.0757\n",
      "   2 2040 / 2728 loss = 13.6532\n",
      "   2 2050 / 2728 loss = 10.3349\n",
      "   2 2060 / 2728 loss = 8.6733\n",
      "   2 2070 / 2728 loss = 16.7106\n",
      "   2 2080 / 2728 loss = 20.4522\n",
      "   2 2090 / 2728 loss = 9.8586\n",
      "   2 2100 / 2728 loss = 6.6946\n",
      "   2 2110 / 2728 loss = 11.2523\n",
      "   2 2120 / 2728 loss = 7.2558\n",
      "   2 2130 / 2728 loss = 35.3041\n",
      "   2 2140 / 2728 loss = 29.2516\n",
      "   2 2150 / 2728 loss = 15.3330\n",
      "   2 2160 / 2728 loss = 40.4375\n",
      "   2 2170 / 2728 loss = 74.0672\n",
      "   2 2180 / 2728 loss = 16.2902\n",
      "   2 2190 / 2728 loss = 10.6702\n",
      "   2 2200 / 2728 loss = 6.9380\n",
      "   2 2210 / 2728 loss = 32.3412\n",
      "   2 2220 / 2728 loss = 22.8230\n",
      "   2 2230 / 2728 loss = 14.4065\n",
      "   2 2240 / 2728 loss = 48.0209\n",
      "   2 2250 / 2728 loss = 8.4192\n",
      "   2 2260 / 2728 loss = 10.0517\n",
      "   2 2270 / 2728 loss = 7.1128\n",
      "   2 2280 / 2728 loss = 14.9467\n",
      "   2 2290 / 2728 loss = 12.9646\n",
      "   2 2300 / 2728 loss = 10.9240\n",
      "   2 2310 / 2728 loss = 12.2049\n",
      "   2 2320 / 2728 loss = 10.8456\n",
      "   2 2330 / 2728 loss = 34.1749\n",
      "   2 2340 / 2728 loss = 10.1588\n",
      "   2 2350 / 2728 loss = 6.6501\n",
      "   2 2360 / 2728 loss = 19.8355\n",
      "   2 2370 / 2728 loss = 23.9498\n",
      "   2 2380 / 2728 loss = 17.3563\n",
      "   2 2390 / 2728 loss = 6.9638\n",
      "   2 2400 / 2728 loss = 8.7883\n",
      "   2 2410 / 2728 loss = 10.1101\n",
      "   2 2420 / 2728 loss = 20.3541\n",
      "   2 2430 / 2728 loss = 10.4372\n",
      "   2 2440 / 2728 loss = 10.5032\n",
      "   2 2450 / 2728 loss = 11.3901\n",
      "   2 2460 / 2728 loss = 6.8181\n",
      "   2 2470 / 2728 loss = 14.3147\n",
      "   2 2480 / 2728 loss = 14.1679\n",
      "   2 2490 / 2728 loss = 18.3242\n",
      "   2 2500 / 2728 loss = 11.3234\n",
      "   2 2510 / 2728 loss = 16.3045\n",
      "   2 2520 / 2728 loss = 47.0344\n",
      "   2 2530 / 2728 loss = 13.5870\n",
      "   2 2540 / 2728 loss = 29.5918\n",
      "   2 2550 / 2728 loss = 17.2318\n",
      "   2 2560 / 2728 loss = 6.9724\n",
      "   2 2570 / 2728 loss = 6.4700\n",
      "   2 2580 / 2728 loss = 12.6230\n",
      "   2 2590 / 2728 loss = 10.1954\n",
      "   2 2600 / 2728 loss = 10.5373\n",
      "   2 2610 / 2728 loss = 15.7357\n",
      "   2 2620 / 2728 loss = 6.2182\n",
      "   2 2630 / 2728 loss = 13.5607\n",
      "   2 2640 / 2728 loss = 40.8524\n",
      "   2 2650 / 2728 loss = 23.2383\n",
      "   2 2660 / 2728 loss = 14.8191\n",
      "   2 2670 / 2728 loss = 23.1124\n",
      "   2 2680 / 2728 loss = 8.5345\n",
      "   2 2690 / 2728 loss = 10.4619\n",
      "   2 2700 / 2728 loss = 7.2189\n",
      "   2 2710 / 2728 loss = 7.7902\n",
      "   2 2720 / 2728 loss = 20.8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [07:44<03:52, 232.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 03:20:14: epcoh =    2 , loss = 1201.3587 , time = 230.24 s\n",
      "^_^-training data finished-^_^\n",
      "   3    0 / 2728 loss = 7.0562\n",
      "   3   10 / 2728 loss = 6.7474\n",
      "   3   20 / 2728 loss = 24.2776\n",
      "   3   30 / 2728 loss = 7.0304\n",
      "   3   40 / 2728 loss = 30.9595\n",
      "   3   50 / 2728 loss = 7.0629\n",
      "   3   60 / 2728 loss = 18.1968\n",
      "   3   70 / 2728 loss = 20.9187\n",
      "   3   80 / 2728 loss = 16.8881\n",
      "   3   90 / 2728 loss = 12.8894\n",
      "   3  100 / 2728 loss = 7.5952\n",
      "   3  110 / 2728 loss = 26.7025\n",
      "   3  120 / 2728 loss = 14.4435\n",
      "   3  130 / 2728 loss = 5.9817\n",
      "   3  140 / 2728 loss = 45.7971\n",
      "   3  150 / 2728 loss = 10.6404\n",
      "   3  160 / 2728 loss = 10.6670\n",
      "   3  170 / 2728 loss = 19.6354\n",
      "   3  180 / 2728 loss = 11.8884\n",
      "   3  190 / 2728 loss = 6.1379\n",
      "   3  200 / 2728 loss = 12.7986\n",
      "   3  210 / 2728 loss = 5.9122\n",
      "   3  220 / 2728 loss = 12.5729\n",
      "   3  230 / 2728 loss = 30.5421\n",
      "   3  240 / 2728 loss = 5.7372\n",
      "   3  250 / 2728 loss = 11.4766\n",
      "   3  260 / 2728 loss = 5.1758\n",
      "   3  270 / 2728 loss = 5.0418\n",
      "   3  280 / 2728 loss = 27.4466\n",
      "   3  290 / 2728 loss = 16.4656\n",
      "   3  300 / 2728 loss = 7.8113\n",
      "   3  310 / 2728 loss = 6.9855\n",
      "   3  320 / 2728 loss = 18.0849\n",
      "   3  330 / 2728 loss = 15.4462\n",
      "   3  340 / 2728 loss = 7.1125\n",
      "   3  350 / 2728 loss = 6.8570\n",
      "   3  360 / 2728 loss = 7.2388\n",
      "   3  370 / 2728 loss = 40.6292\n",
      "   3  380 / 2728 loss = 20.8260\n",
      "   3  390 / 2728 loss = 8.9272\n",
      "   3  400 / 2728 loss = 4.6515\n",
      "   3  410 / 2728 loss = 32.4754\n",
      "   3  420 / 2728 loss = 12.7902\n",
      "   3  430 / 2728 loss = 9.5718\n",
      "   3  440 / 2728 loss = 20.5013\n",
      "   3  450 / 2728 loss = 49.9170\n",
      "   3  460 / 2728 loss = 6.7166\n",
      "   3  470 / 2728 loss = 56.3718\n",
      "   3  480 / 2728 loss = 9.4706\n",
      "   3  490 / 2728 loss = 21.6280\n",
      "   3  500 / 2728 loss = 18.3067\n",
      "   3  510 / 2728 loss = 29.8675\n",
      "   3  520 / 2728 loss = 15.0113\n",
      "   3  530 / 2728 loss = 20.0817\n",
      "   3  540 / 2728 loss = 8.4231\n",
      "   3  550 / 2728 loss = 20.7225\n",
      "   3  560 / 2728 loss = 6.0727\n",
      "   3  570 / 2728 loss = 4.2045\n",
      "   3  580 / 2728 loss = 8.1068\n",
      "   3  590 / 2728 loss = 18.1698\n",
      "   3  600 / 2728 loss = 29.1121\n",
      "   3  610 / 2728 loss = 5.2917\n",
      "   3  620 / 2728 loss = 6.2320\n",
      "   3  630 / 2728 loss = 14.6307\n",
      "   3  640 / 2728 loss = 16.3749\n",
      "   3  650 / 2728 loss = 13.7054\n",
      "   3  660 / 2728 loss = 5.5460\n",
      "   3  670 / 2728 loss = 33.5799\n",
      "   3  680 / 2728 loss = 23.8106\n",
      "   3  690 / 2728 loss = 16.0251\n",
      "   3  700 / 2728 loss = 52.9616\n",
      "   3  710 / 2728 loss = 32.6495\n",
      "   3  720 / 2728 loss = 6.3477\n",
      "   3  730 / 2728 loss = 10.0224\n",
      "   3  740 / 2728 loss = 19.1362\n",
      "   3  750 / 2728 loss = 19.0681\n",
      "   3  760 / 2728 loss = 14.4074\n",
      "   3  770 / 2728 loss = 16.0937\n",
      "   3  780 / 2728 loss = 25.4804\n",
      "   3  790 / 2728 loss = 6.7288\n",
      "   3  800 / 2728 loss = 32.7206\n",
      "   3  810 / 2728 loss = 11.0960\n",
      "   3  820 / 2728 loss = 5.9384\n",
      "   3  830 / 2728 loss = 5.8988\n",
      "   3  840 / 2728 loss = 9.9564\n",
      "   3  850 / 2728 loss = 63.6797\n",
      "   3  860 / 2728 loss = 7.1709\n",
      "   3  870 / 2728 loss = 7.9405\n",
      "   3  880 / 2728 loss = 10.0103\n",
      "   3  890 / 2728 loss = 14.8605\n",
      "   3  900 / 2728 loss = 12.0494\n",
      "   3  910 / 2728 loss = 42.4994\n",
      "   3  920 / 2728 loss = 15.0086\n",
      "   3  930 / 2728 loss = 25.8637\n",
      "   3  940 / 2728 loss = 13.0394\n",
      "   3  950 / 2728 loss = 7.4792\n",
      "   3  960 / 2728 loss = 16.4930\n",
      "   3  970 / 2728 loss = 11.1911\n",
      "   3  980 / 2728 loss = 8.8813\n",
      "   3  990 / 2728 loss = 15.5927\n",
      "   3 1000 / 2728 loss = 12.1281\n",
      "   3 1010 / 2728 loss = 11.4985\n",
      "   3 1020 / 2728 loss = 21.5480\n",
      "   3 1030 / 2728 loss = 7.8026\n",
      "   3 1040 / 2728 loss = 4.9539\n",
      "   3 1050 / 2728 loss = 5.4168\n",
      "   3 1060 / 2728 loss = 7.8610\n",
      "   3 1070 / 2728 loss = 13.2803\n",
      "   3 1080 / 2728 loss = 12.6543\n",
      "   3 1090 / 2728 loss = 15.0538\n",
      "   3 1100 / 2728 loss = 4.5801\n",
      "   3 1110 / 2728 loss = 16.7063\n",
      "   3 1120 / 2728 loss = 7.3916\n",
      "   3 1130 / 2728 loss = 7.3348\n",
      "   3 1140 / 2728 loss = 35.3518\n",
      "   3 1150 / 2728 loss = 14.9569\n",
      "   3 1160 / 2728 loss = 13.6761\n",
      "   3 1170 / 2728 loss = 10.4861\n",
      "   3 1180 / 2728 loss = 6.6600\n",
      "   3 1190 / 2728 loss = 7.3824\n",
      "   3 1200 / 2728 loss = 10.3512\n",
      "   3 1210 / 2728 loss = 5.0284\n",
      "   3 1220 / 2728 loss = 18.3918\n",
      "   3 1230 / 2728 loss = 10.0094\n",
      "   3 1240 / 2728 loss = 10.5937\n",
      "   3 1250 / 2728 loss = 7.4269\n",
      "   3 1260 / 2728 loss = 5.6542\n",
      "   3 1270 / 2728 loss = 10.3314\n",
      "   3 1280 / 2728 loss = 6.8644\n",
      "   3 1290 / 2728 loss = 8.9365\n",
      "   3 1300 / 2728 loss = 8.0261\n",
      "   3 1310 / 2728 loss = 10.9707\n",
      "   3 1320 / 2728 loss = 7.1946\n",
      "   3 1330 / 2728 loss = 13.5570\n",
      "   3 1340 / 2728 loss = 16.8152\n",
      "   3 1350 / 2728 loss = 11.6118\n",
      "   3 1360 / 2728 loss = 13.0599\n",
      "   3 1370 / 2728 loss = 24.6008\n",
      "   3 1380 / 2728 loss = 19.4177\n",
      "   3 1390 / 2728 loss = 11.1223\n",
      "   3 1400 / 2728 loss = 11.1884\n",
      "   3 1410 / 2728 loss = 5.8437\n",
      "   3 1420 / 2728 loss = 8.2773\n",
      "   3 1430 / 2728 loss = 30.6604\n",
      "   3 1440 / 2728 loss = 18.4516\n",
      "   3 1450 / 2728 loss = 14.0177\n",
      "   3 1460 / 2728 loss = 5.6819\n",
      "   3 1470 / 2728 loss = 13.7980\n",
      "   3 1480 / 2728 loss = 6.8778\n",
      "   3 1490 / 2728 loss = 11.9479\n",
      "   3 1500 / 2728 loss = 9.0375\n",
      "   3 1510 / 2728 loss = 10.8101\n",
      "   3 1520 / 2728 loss = 9.4705\n",
      "   3 1530 / 2728 loss = 10.4433\n",
      "   3 1540 / 2728 loss = 5.7136\n",
      "   3 1550 / 2728 loss = 5.1017\n",
      "   3 1560 / 2728 loss = 23.2941\n",
      "   3 1570 / 2728 loss = 11.4403\n",
      "   3 1580 / 2728 loss = 8.3998\n",
      "   3 1590 / 2728 loss = 10.5396\n",
      "   3 1600 / 2728 loss = 16.9824\n",
      "   3 1610 / 2728 loss = 9.2390\n",
      "   3 1620 / 2728 loss = 9.3356\n",
      "   3 1630 / 2728 loss = 16.0743\n",
      "   3 1640 / 2728 loss = 10.1548\n",
      "   3 1650 / 2728 loss = 5.2729\n",
      "   3 1660 / 2728 loss = 5.9639\n",
      "   3 1670 / 2728 loss = 6.6629\n",
      "   3 1680 / 2728 loss = 12.0321\n",
      "   3 1690 / 2728 loss = 25.8422\n",
      "   3 1700 / 2728 loss = 7.0019\n",
      "   3 1710 / 2728 loss = 56.0418\n",
      "   3 1720 / 2728 loss = 33.4690\n",
      "   3 1730 / 2728 loss = 9.8549\n",
      "   3 1740 / 2728 loss = 8.8192\n",
      "   3 1750 / 2728 loss = 16.0112\n",
      "   3 1760 / 2728 loss = 11.8790\n",
      "   3 1770 / 2728 loss = 20.5868\n",
      "   3 1780 / 2728 loss = 8.3959\n",
      "   3 1790 / 2728 loss = 12.2676\n",
      "   3 1800 / 2728 loss = 19.4113\n",
      "   3 1810 / 2728 loss = 25.0385\n",
      "   3 1820 / 2728 loss = 6.7867\n",
      "   3 1830 / 2728 loss = 16.3799\n",
      "   3 1840 / 2728 loss = 15.8993\n",
      "   3 1850 / 2728 loss = 5.1851\n",
      "   3 1860 / 2728 loss = 7.3711\n",
      "   3 1870 / 2728 loss = 14.5465\n",
      "   3 1880 / 2728 loss = 28.2193\n",
      "   3 1890 / 2728 loss = 23.6988\n",
      "   3 1900 / 2728 loss = 10.7571\n",
      "   3 1910 / 2728 loss = 12.6492\n",
      "   3 1920 / 2728 loss = 8.4699\n",
      "   3 1930 / 2728 loss = 11.5478\n",
      "   3 1940 / 2728 loss = 27.9927\n",
      "   3 1950 / 2728 loss = 5.4555\n",
      "   3 1960 / 2728 loss = 8.1472\n",
      "   3 1970 / 2728 loss = 37.4019\n",
      "   3 1980 / 2728 loss = 9.2299\n",
      "   3 1990 / 2728 loss = 13.5826\n",
      "   3 2000 / 2728 loss = 6.4500\n",
      "   3 2010 / 2728 loss = 5.1638\n",
      "   3 2020 / 2728 loss = 6.6633\n",
      "   3 2030 / 2728 loss = 7.5023\n",
      "   3 2040 / 2728 loss = 13.0631\n",
      "   3 2050 / 2728 loss = 7.3030\n",
      "   3 2060 / 2728 loss = 10.6997\n",
      "   3 2070 / 2728 loss = 11.7216\n",
      "   3 2080 / 2728 loss = 8.2677\n",
      "   3 2090 / 2728 loss = 8.7795\n",
      "   3 2100 / 2728 loss = 8.3837\n",
      "   3 2110 / 2728 loss = 83.4568\n",
      "   3 2120 / 2728 loss = 16.6826\n",
      "   3 2130 / 2728 loss = 20.9117\n",
      "   3 2140 / 2728 loss = 24.4348\n",
      "   3 2150 / 2728 loss = 10.9803\n",
      "   3 2160 / 2728 loss = 11.5586\n",
      "   3 2170 / 2728 loss = 20.2874\n",
      "   3 2180 / 2728 loss = 25.0296\n",
      "   3 2190 / 2728 loss = 9.0800\n",
      "   3 2200 / 2728 loss = 7.4005\n",
      "   3 2210 / 2728 loss = 8.3414\n",
      "   3 2220 / 2728 loss = 12.5721\n",
      "   3 2230 / 2728 loss = 10.7530\n",
      "   3 2240 / 2728 loss = 6.5783\n",
      "   3 2250 / 2728 loss = 15.0095\n",
      "   3 2260 / 2728 loss = 15.4392\n",
      "   3 2270 / 2728 loss = 5.6290\n",
      "   3 2280 / 2728 loss = 6.0556\n",
      "   3 2290 / 2728 loss = 10.5185\n",
      "   3 2300 / 2728 loss = 9.1230\n",
      "   3 2310 / 2728 loss = 10.0464\n",
      "   3 2320 / 2728 loss = 5.3114\n",
      "   3 2330 / 2728 loss = 10.3493\n",
      "   3 2340 / 2728 loss = 14.1698\n",
      "   3 2350 / 2728 loss = 7.3726\n",
      "   3 2360 / 2728 loss = 7.6523\n",
      "   3 2370 / 2728 loss = 7.5275\n",
      "   3 2380 / 2728 loss = 6.4244\n",
      "   3 2390 / 2728 loss = 6.0499\n",
      "   3 2400 / 2728 loss = 7.2073\n",
      "   3 2410 / 2728 loss = 5.2285\n",
      "   3 2420 / 2728 loss = 5.1840\n",
      "   3 2430 / 2728 loss = 4.0437\n",
      "   3 2440 / 2728 loss = 5.6416\n",
      "   3 2450 / 2728 loss = 8.3875\n",
      "   3 2460 / 2728 loss = 13.4039\n",
      "   3 2470 / 2728 loss = 15.8880\n",
      "   3 2480 / 2728 loss = 6.4377\n",
      "   3 2490 / 2728 loss = 4.4887\n",
      "   3 2500 / 2728 loss = 9.6076\n",
      "   3 2510 / 2728 loss = 4.5604\n",
      "   3 2520 / 2728 loss = 3.9456\n",
      "   3 2530 / 2728 loss = 6.2574\n",
      "   3 2540 / 2728 loss = 13.4693\n",
      "   3 2550 / 2728 loss = 18.4285\n",
      "   3 2560 / 2728 loss = 5.2539\n",
      "   3 2570 / 2728 loss = 4.9084\n",
      "   3 2580 / 2728 loss = 25.3283\n",
      "   3 2590 / 2728 loss = 15.8482\n",
      "   3 2600 / 2728 loss = 21.9746\n",
      "   3 2610 / 2728 loss = 10.0429\n",
      "   3 2620 / 2728 loss = 25.5663\n",
      "   3 2630 / 2728 loss = 8.7473\n",
      "   3 2640 / 2728 loss = 7.7542\n",
      "   3 2650 / 2728 loss = 26.1626\n",
      "   3 2660 / 2728 loss = 25.5650\n",
      "   3 2670 / 2728 loss = 10.8759\n",
      "   3 2680 / 2728 loss = 6.5850\n",
      "   3 2690 / 2728 loss = 8.3384\n",
      "   3 2700 / 2728 loss = 7.8210\n",
      "   3 2710 / 2728 loss = 6.0215\n",
      "   3 2720 / 2728 loss = 14.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:36<00:00, 232.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 03:24:06: epcoh =    3 , loss = 891.0544 , time = 230.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
