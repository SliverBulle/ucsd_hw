{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c44bf7-acb0-481c-88cf-03e9298a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '64', '--train_data', 'data/Train400', '--sigma', '4', '--epoch', '3', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=3, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "        \n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, out_channels=64, in_channels=1, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_layers = []\n",
    "        for _ in range(10):\n",
    "            for sub in self.make_Residual():\n",
    "                output_layers.append(sub)\n",
    "        self.out = nn.Sequential(*output_layers)\n",
    "        self.res = nn.Conv2d(64, 1, kernel_size=3, padding=1, stride=1)\n",
    "        \n",
    "    def make_Residual(self, in_channels=64, out_channels=64, kernel_size=3):\n",
    "        i = 0\n",
    "        layers = []\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, bias=True))\n",
    "            layers.append(nn.BatchNorm2d(64, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return layers\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.relu(self.BN(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.res(out)\n",
    "        return dn\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^-training data finished-^_^\n",
      "   1    0 / 2728 loss = 3662.9446\n",
      "   1   10 / 2728 loss = 1309.7716\n",
      "   1   20 / 2728 loss = 946.0906\n",
      "   1   30 / 2728 loss = 547.5883\n",
      "   1   40 / 2728 loss = 360.2235\n",
      "   1   50 / 2728 loss = 284.0804\n",
      "   1   60 / 2728 loss = 246.4255\n",
      "   1   70 / 2728 loss = 209.9993\n",
      "   1   80 / 2728 loss = 215.2713\n",
      "   1   90 / 2728 loss = 166.1460\n",
      "   1  100 / 2728 loss = 177.8282\n",
      "   1  110 / 2728 loss = 127.0031\n",
      "   1  120 / 2728 loss = 177.3469\n",
      "   1  130 / 2728 loss = 102.6135\n",
      "   1  140 / 2728 loss = 90.2536\n",
      "   1  150 / 2728 loss = 117.1431\n",
      "   1  160 / 2728 loss = 100.8194\n",
      "   1  170 / 2728 loss = 71.7937\n",
      "   1  180 / 2728 loss = 65.3173\n",
      "   1  190 / 2728 loss = 79.4943\n",
      "   1  200 / 2728 loss = 71.9804\n",
      "   1  210 / 2728 loss = 71.8738\n",
      "   1  220 / 2728 loss = 56.3057\n",
      "   1  230 / 2728 loss = 68.4615\n",
      "   1  240 / 2728 loss = 52.0838\n",
      "   1  250 / 2728 loss = 57.5822\n",
      "   1  260 / 2728 loss = 50.1758\n",
      "   1  270 / 2728 loss = 64.8028\n",
      "   1  280 / 2728 loss = 50.7798\n",
      "   1  290 / 2728 loss = 82.9947\n",
      "   1  300 / 2728 loss = 56.8066\n",
      "   1  310 / 2728 loss = 66.7605\n",
      "   1  320 / 2728 loss = 68.5646\n",
      "   1  330 / 2728 loss = 53.4444\n",
      "   1  340 / 2728 loss = 71.8261\n",
      "   1  350 / 2728 loss = 117.1746\n",
      "   1  360 / 2728 loss = 76.4153\n",
      "   1  370 / 2728 loss = 46.0477\n",
      "   1  380 / 2728 loss = 38.8794\n",
      "   1  390 / 2728 loss = 56.0292\n",
      "   1  400 / 2728 loss = 46.9210\n",
      "   1  410 / 2728 loss = 36.0437\n",
      "   1  420 / 2728 loss = 31.8117\n",
      "   1  430 / 2728 loss = 36.3449\n",
      "   1  440 / 2728 loss = 40.4025\n",
      "   1  450 / 2728 loss = 41.8333\n",
      "   1  460 / 2728 loss = 64.8860\n",
      "   1  470 / 2728 loss = 48.7212\n",
      "   1  480 / 2728 loss = 29.2457\n",
      "   1  490 / 2728 loss = 45.0742\n",
      "   1  500 / 2728 loss = 28.5906\n",
      "   1  510 / 2728 loss = 40.7567\n",
      "   1  520 / 2728 loss = 29.0165\n",
      "   1  530 / 2728 loss = 30.0757\n",
      "   1  540 / 2728 loss = 54.2073\n",
      "   1  550 / 2728 loss = 29.8926\n",
      "   1  560 / 2728 loss = 41.2625\n",
      "   1  570 / 2728 loss = 80.7896\n",
      "   1  580 / 2728 loss = 29.6494\n",
      "   1  590 / 2728 loss = 27.8124\n",
      "   1  600 / 2728 loss = 31.9037\n",
      "   1  610 / 2728 loss = 44.3022\n",
      "   1  620 / 2728 loss = 25.8540\n",
      "   1  630 / 2728 loss = 35.6023\n",
      "   1  640 / 2728 loss = 38.9889\n",
      "   1  650 / 2728 loss = 39.1940\n",
      "   1  660 / 2728 loss = 29.5219\n",
      "   1  670 / 2728 loss = 31.4331\n",
      "   1  680 / 2728 loss = 98.7394\n",
      "   1  690 / 2728 loss = 33.7712\n",
      "   1  700 / 2728 loss = 29.0261\n",
      "   1  710 / 2728 loss = 28.7148\n",
      "   1  720 / 2728 loss = 22.9636\n",
      "   1  730 / 2728 loss = 24.9105\n",
      "   1  740 / 2728 loss = 34.8549\n",
      "   1  750 / 2728 loss = 24.8296\n",
      "   1  760 / 2728 loss = 35.3968\n",
      "   1  770 / 2728 loss = 27.9083\n",
      "   1  780 / 2728 loss = 25.1127\n",
      "   1  790 / 2728 loss = 36.9147\n",
      "   1  800 / 2728 loss = 64.0222\n",
      "   1  810 / 2728 loss = 27.0427\n",
      "   1  820 / 2728 loss = 37.2058\n",
      "   1  830 / 2728 loss = 23.0979\n",
      "   1  840 / 2728 loss = 25.9384\n",
      "   1  850 / 2728 loss = 24.2924\n",
      "   1  860 / 2728 loss = 22.3768\n",
      "   1  870 / 2728 loss = 17.9998\n",
      "   1  880 / 2728 loss = 22.9470\n",
      "   1  890 / 2728 loss = 21.6411\n",
      "   1  900 / 2728 loss = 38.7321\n",
      "   1  910 / 2728 loss = 27.2259\n",
      "   1  920 / 2728 loss = 21.1873\n",
      "   1  930 / 2728 loss = 32.9454\n",
      "   1  940 / 2728 loss = 20.5989\n",
      "   1  950 / 2728 loss = 20.9628\n",
      "   1  960 / 2728 loss = 17.2900\n",
      "   1  970 / 2728 loss = 19.0640\n",
      "   1  980 / 2728 loss = 22.7888\n",
      "   1  990 / 2728 loss = 21.5626\n",
      "   1 1000 / 2728 loss = 37.9285\n",
      "   1 1010 / 2728 loss = 62.5417\n",
      "   1 1020 / 2728 loss = 29.3824\n",
      "   1 1030 / 2728 loss = 27.2219\n",
      "   1 1040 / 2728 loss = 21.1442\n",
      "   1 1050 / 2728 loss = 58.3204\n",
      "   1 1060 / 2728 loss = 23.4426\n",
      "   1 1070 / 2728 loss = 26.9357\n",
      "   1 1080 / 2728 loss = 38.2885\n",
      "   1 1090 / 2728 loss = 27.5715\n",
      "   1 1100 / 2728 loss = 61.6023\n",
      "   1 1110 / 2728 loss = 27.6178\n",
      "   1 1120 / 2728 loss = 51.6106\n",
      "   1 1130 / 2728 loss = 16.8833\n",
      "   1 1140 / 2728 loss = 19.5512\n",
      "   1 1150 / 2728 loss = 20.9284\n",
      "   1 1160 / 2728 loss = 21.1112\n",
      "   1 1170 / 2728 loss = 33.3488\n",
      "   1 1180 / 2728 loss = 22.8240\n",
      "   1 1190 / 2728 loss = 21.8301\n",
      "   1 1200 / 2728 loss = 19.3843\n",
      "   1 1210 / 2728 loss = 20.8484\n",
      "   1 1220 / 2728 loss = 16.7154\n",
      "   1 1230 / 2728 loss = 37.2436\n",
      "   1 1240 / 2728 loss = 29.1360\n",
      "   1 1250 / 2728 loss = 18.8629\n",
      "   1 1260 / 2728 loss = 37.2761\n",
      "   1 1270 / 2728 loss = 18.8093\n",
      "   1 1280 / 2728 loss = 94.8201\n",
      "   1 1290 / 2728 loss = 36.0737\n",
      "   1 1300 / 2728 loss = 18.2768\n",
      "   1 1310 / 2728 loss = 15.8345\n",
      "   1 1320 / 2728 loss = 26.4287\n",
      "   1 1330 / 2728 loss = 21.0653\n",
      "   1 1340 / 2728 loss = 30.7187\n",
      "   1 1350 / 2728 loss = 23.2316\n",
      "   1 1360 / 2728 loss = 32.1588\n",
      "   1 1370 / 2728 loss = 40.4881\n",
      "   1 1380 / 2728 loss = 35.6408\n",
      "   1 1390 / 2728 loss = 71.9979\n",
      "   1 1400 / 2728 loss = 18.7098\n",
      "   1 1410 / 2728 loss = 22.8917\n",
      "   1 1420 / 2728 loss = 45.3325\n",
      "   1 1430 / 2728 loss = 49.4771\n",
      "   1 1440 / 2728 loss = 21.1513\n",
      "   1 1450 / 2728 loss = 26.7352\n",
      "   1 1460 / 2728 loss = 22.6310\n",
      "   1 1470 / 2728 loss = 18.7737\n",
      "   1 1480 / 2728 loss = 14.1556\n",
      "   1 1490 / 2728 loss = 15.3210\n",
      "   1 1500 / 2728 loss = 16.2290\n",
      "   1 1510 / 2728 loss = 16.6817\n",
      "   1 1520 / 2728 loss = 23.0968\n",
      "   1 1530 / 2728 loss = 69.2519\n",
      "   1 1540 / 2728 loss = 14.6786\n",
      "   1 1550 / 2728 loss = 20.2160\n",
      "   1 1560 / 2728 loss = 19.0312\n",
      "   1 1570 / 2728 loss = 19.8900\n",
      "   1 1580 / 2728 loss = 20.8005\n",
      "   1 1590 / 2728 loss = 33.1758\n",
      "   1 1600 / 2728 loss = 13.9163\n",
      "   1 1610 / 2728 loss = 17.2973\n",
      "   1 1620 / 2728 loss = 16.8914\n",
      "   1 1630 / 2728 loss = 47.6771\n",
      "   1 1640 / 2728 loss = 29.4299\n",
      "   1 1650 / 2728 loss = 45.0230\n",
      "   1 1660 / 2728 loss = 26.1736\n",
      "   1 1670 / 2728 loss = 31.6827\n",
      "   1 1680 / 2728 loss = 33.3865\n",
      "   1 1690 / 2728 loss = 26.0697\n",
      "   1 1700 / 2728 loss = 22.7180\n",
      "   1 1710 / 2728 loss = 36.4638\n",
      "   1 1720 / 2728 loss = 22.7202\n",
      "   1 1730 / 2728 loss = 26.1137\n",
      "   1 1740 / 2728 loss = 15.3397\n",
      "   1 1750 / 2728 loss = 19.5985\n",
      "   1 1760 / 2728 loss = 13.3072\n",
      "   1 1770 / 2728 loss = 15.8940\n",
      "   1 1780 / 2728 loss = 14.4544\n",
      "   1 1790 / 2728 loss = 12.5814\n",
      "   1 1800 / 2728 loss = 15.2390\n",
      "   1 1810 / 2728 loss = 24.5890\n",
      "   1 1820 / 2728 loss = 16.8169\n",
      "   1 1830 / 2728 loss = 14.8802\n",
      "   1 1840 / 2728 loss = 16.6149\n",
      "   1 1850 / 2728 loss = 16.9779\n",
      "   1 1860 / 2728 loss = 67.3428\n",
      "   1 1870 / 2728 loss = 24.0834\n",
      "   1 1880 / 2728 loss = 35.6974\n",
      "   1 1890 / 2728 loss = 28.7603\n",
      "   1 1900 / 2728 loss = 13.1808\n",
      "   1 1910 / 2728 loss = 28.2898\n",
      "   1 1920 / 2728 loss = 36.9602\n",
      "   1 1930 / 2728 loss = 35.8441\n",
      "   1 1940 / 2728 loss = 16.3124\n",
      "   1 1950 / 2728 loss = 14.1110\n",
      "   1 1960 / 2728 loss = 11.9516\n",
      "   1 1970 / 2728 loss = 22.9320\n",
      "   1 1980 / 2728 loss = 47.5820\n",
      "   1 1990 / 2728 loss = 24.1807\n",
      "   1 2000 / 2728 loss = 19.1638\n",
      "   1 2010 / 2728 loss = 17.9383\n",
      "   1 2020 / 2728 loss = 15.1871\n",
      "   1 2030 / 2728 loss = 41.5746\n",
      "   1 2040 / 2728 loss = 68.2294\n",
      "   1 2050 / 2728 loss = 11.2967\n",
      "   1 2060 / 2728 loss = 11.0181\n",
      "   1 2070 / 2728 loss = 15.8776\n",
      "   1 2080 / 2728 loss = 30.6713\n",
      "   1 2090 / 2728 loss = 26.2945\n",
      "   1 2100 / 2728 loss = 10.9150\n",
      "   1 2110 / 2728 loss = 24.1384\n",
      "   1 2120 / 2728 loss = 39.0474\n",
      "   1 2130 / 2728 loss = 21.0429\n",
      "   1 2140 / 2728 loss = 20.0085\n",
      "   1 2150 / 2728 loss = 15.7427\n",
      "   1 2160 / 2728 loss = 34.6986\n",
      "   1 2170 / 2728 loss = 14.7441\n",
      "   1 2180 / 2728 loss = 18.4304\n",
      "   1 2190 / 2728 loss = 22.5799\n",
      "   1 2200 / 2728 loss = 16.6419\n",
      "   1 2210 / 2728 loss = 12.9399\n",
      "   1 2220 / 2728 loss = 14.9534\n",
      "   1 2230 / 2728 loss = 10.7410\n",
      "   1 2240 / 2728 loss = 26.9560\n",
      "   1 2250 / 2728 loss = 25.8945\n",
      "   1 2260 / 2728 loss = 32.9002\n",
      "   1 2270 / 2728 loss = 13.4639\n",
      "   1 2280 / 2728 loss = 27.4317\n",
      "   1 2290 / 2728 loss = 15.1366\n",
      "   1 2300 / 2728 loss = 20.8336\n",
      "   1 2310 / 2728 loss = 54.2466\n",
      "   1 2320 / 2728 loss = 11.9955\n",
      "   1 2330 / 2728 loss = 34.5884\n",
      "   1 2340 / 2728 loss = 11.8079\n",
      "   1 2350 / 2728 loss = 24.4983\n",
      "   1 2360 / 2728 loss = 22.6157\n",
      "   1 2370 / 2728 loss = 14.1554\n",
      "   1 2380 / 2728 loss = 13.9476\n",
      "   1 2390 / 2728 loss = 23.1243\n",
      "   1 2400 / 2728 loss = 21.7839\n",
      "   1 2410 / 2728 loss = 17.5902\n",
      "   1 2420 / 2728 loss = 14.1500\n",
      "   1 2430 / 2728 loss = 25.8591\n",
      "   1 2440 / 2728 loss = 15.8691\n",
      "   1 2450 / 2728 loss = 43.4243\n",
      "   1 2460 / 2728 loss = 9.7733\n",
      "   1 2470 / 2728 loss = 20.5012\n",
      "   1 2480 / 2728 loss = 55.1501\n",
      "   1 2490 / 2728 loss = 15.3090\n",
      "   1 2500 / 2728 loss = 16.6515\n",
      "   1 2510 / 2728 loss = 16.5214\n",
      "   1 2520 / 2728 loss = 21.7103\n",
      "   1 2530 / 2728 loss = 15.4808\n",
      "   1 2540 / 2728 loss = 61.5683\n",
      "   1 2550 / 2728 loss = 17.3015\n",
      "   1 2560 / 2728 loss = 10.8957\n",
      "   1 2570 / 2728 loss = 41.7110\n",
      "   1 2580 / 2728 loss = 12.6231\n",
      "   1 2590 / 2728 loss = 28.8990\n",
      "   1 2600 / 2728 loss = 23.3507\n",
      "   1 2610 / 2728 loss = 19.5626\n",
      "   1 2620 / 2728 loss = 20.5538\n",
      "   1 2630 / 2728 loss = 13.4673\n",
      "   1 2640 / 2728 loss = 23.5939\n",
      "   1 2650 / 2728 loss = 18.8039\n",
      "   1 2660 / 2728 loss = 24.4068\n",
      "   1 2670 / 2728 loss = 31.8682\n",
      "   1 2680 / 2728 loss = 25.7670\n",
      "   1 2690 / 2728 loss = 13.7769\n",
      "   1 2700 / 2728 loss = 9.9257\n",
      "   1 2710 / 2728 loss = 10.4606\n",
      "   1 2720 / 2728 loss = 28.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [03:52<07:45, 232.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:30:24: epcoh =    1 , loss = 3548.9169 , time = 230.53 s\n",
      "^_^-training data finished-^_^\n",
      "   2    0 / 2728 loss = 17.1914\n",
      "   2   10 / 2728 loss = 16.1395\n",
      "   2   20 / 2728 loss = 10.9203\n",
      "   2   30 / 2728 loss = 19.1820\n",
      "   2   40 / 2728 loss = 38.5931\n",
      "   2   50 / 2728 loss = 12.7421\n",
      "   2   60 / 2728 loss = 24.0554\n",
      "   2   70 / 2728 loss = 23.9911\n",
      "   2   80 / 2728 loss = 8.3231\n",
      "   2   90 / 2728 loss = 11.0193\n",
      "   2  100 / 2728 loss = 12.4186\n",
      "   2  110 / 2728 loss = 11.8963\n",
      "   2  120 / 2728 loss = 9.0626\n",
      "   2  130 / 2728 loss = 10.4495\n",
      "   2  140 / 2728 loss = 25.0496\n",
      "   2  150 / 2728 loss = 13.2314\n",
      "   2  160 / 2728 loss = 11.9627\n",
      "   2  170 / 2728 loss = 10.2880\n",
      "   2  180 / 2728 loss = 12.3104\n",
      "   2  190 / 2728 loss = 13.9772\n",
      "   2  200 / 2728 loss = 26.4489\n",
      "   2  210 / 2728 loss = 26.8817\n",
      "   2  220 / 2728 loss = 35.2934\n",
      "   2  230 / 2728 loss = 30.3697\n",
      "   2  240 / 2728 loss = 11.0570\n",
      "   2  250 / 2728 loss = 12.4976\n",
      "   2  260 / 2728 loss = 13.2533\n",
      "   2  270 / 2728 loss = 30.1403\n",
      "   2  280 / 2728 loss = 13.9572\n",
      "   2  290 / 2728 loss = 53.4912\n",
      "   2  300 / 2728 loss = 11.2431\n",
      "   2  310 / 2728 loss = 22.2907\n",
      "   2  320 / 2728 loss = 38.0505\n",
      "   2  330 / 2728 loss = 10.8973\n",
      "   2  340 / 2728 loss = 22.3071\n",
      "   2  350 / 2728 loss = 16.8496\n",
      "   2  360 / 2728 loss = 42.0460\n",
      "   2  370 / 2728 loss = 37.4686\n",
      "   2  380 / 2728 loss = 13.2558\n",
      "   2  390 / 2728 loss = 18.2620\n",
      "   2  400 / 2728 loss = 10.2327\n",
      "   2  410 / 2728 loss = 8.2548\n",
      "   2  420 / 2728 loss = 9.3504\n",
      "   2  430 / 2728 loss = 10.0173\n",
      "   2  440 / 2728 loss = 27.9279\n",
      "   2  450 / 2728 loss = 15.6009\n",
      "   2  460 / 2728 loss = 32.7570\n",
      "   2  470 / 2728 loss = 11.8896\n",
      "   2  480 / 2728 loss = 8.3815\n",
      "   2  490 / 2728 loss = 32.9536\n",
      "   2  500 / 2728 loss = 8.9611\n",
      "   2  510 / 2728 loss = 12.8946\n",
      "   2  520 / 2728 loss = 18.7953\n",
      "   2  530 / 2728 loss = 18.9327\n",
      "   2  540 / 2728 loss = 11.0523\n",
      "   2  550 / 2728 loss = 62.5256\n",
      "   2  560 / 2728 loss = 20.9047\n",
      "   2  570 / 2728 loss = 11.3344\n",
      "   2  580 / 2728 loss = 12.4414\n",
      "   2  590 / 2728 loss = 15.2363\n",
      "   2  600 / 2728 loss = 14.8584\n",
      "   2  610 / 2728 loss = 8.5351\n",
      "   2  620 / 2728 loss = 45.4975\n",
      "   2  630 / 2728 loss = 7.8890\n",
      "   2  640 / 2728 loss = 32.2546\n",
      "   2  650 / 2728 loss = 38.0060\n",
      "   2  660 / 2728 loss = 24.2148\n",
      "   2  670 / 2728 loss = 43.9454\n",
      "   2  680 / 2728 loss = 16.3976\n",
      "   2  690 / 2728 loss = 7.5939\n",
      "   2  700 / 2728 loss = 31.0385\n",
      "   2  710 / 2728 loss = 23.1335\n",
      "   2  720 / 2728 loss = 77.8735\n",
      "   2  730 / 2728 loss = 19.6503\n",
      "   2  740 / 2728 loss = 54.7422\n",
      "   2  750 / 2728 loss = 21.7973\n",
      "   2  760 / 2728 loss = 16.0678\n",
      "   2  770 / 2728 loss = 9.7042\n",
      "   2  780 / 2728 loss = 6.3095\n",
      "   2  790 / 2728 loss = 16.0015\n",
      "   2  800 / 2728 loss = 14.5302\n",
      "   2  810 / 2728 loss = 16.3029\n",
      "   2  820 / 2728 loss = 16.1272\n",
      "   2  830 / 2728 loss = 40.6368\n",
      "   2  840 / 2728 loss = 11.5079\n",
      "   2  850 / 2728 loss = 36.9720\n",
      "   2  860 / 2728 loss = 18.7851\n",
      "   2  870 / 2728 loss = 11.5485\n",
      "   2  880 / 2728 loss = 17.6364\n",
      "   2  890 / 2728 loss = 17.2726\n",
      "   2  900 / 2728 loss = 8.9365\n",
      "   2  910 / 2728 loss = 11.4101\n",
      "   2  920 / 2728 loss = 49.0686\n",
      "   2  930 / 2728 loss = 12.8148\n",
      "   2  940 / 2728 loss = 9.7152\n",
      "   2  950 / 2728 loss = 10.0114\n",
      "   2  960 / 2728 loss = 15.6593\n",
      "   2  970 / 2728 loss = 9.4088\n",
      "   2  980 / 2728 loss = 10.5288\n",
      "   2  990 / 2728 loss = 53.4919\n",
      "   2 1000 / 2728 loss = 76.8382\n",
      "   2 1010 / 2728 loss = 26.4306\n",
      "   2 1020 / 2728 loss = 33.6507\n",
      "   2 1030 / 2728 loss = 8.8199\n",
      "   2 1040 / 2728 loss = 7.9138\n",
      "   2 1050 / 2728 loss = 9.8105\n",
      "   2 1060 / 2728 loss = 33.7396\n",
      "   2 1070 / 2728 loss = 7.2803\n",
      "   2 1080 / 2728 loss = 10.3432\n",
      "   2 1090 / 2728 loss = 9.6788\n",
      "   2 1100 / 2728 loss = 18.6719\n",
      "   2 1110 / 2728 loss = 14.5140\n",
      "   2 1120 / 2728 loss = 11.0307\n",
      "   2 1130 / 2728 loss = 35.1941\n",
      "   2 1140 / 2728 loss = 9.0015\n",
      "   2 1150 / 2728 loss = 17.8225\n",
      "   2 1160 / 2728 loss = 14.2993\n",
      "   2 1170 / 2728 loss = 65.2900\n",
      "   2 1180 / 2728 loss = 11.6218\n",
      "   2 1190 / 2728 loss = 12.3073\n",
      "   2 1200 / 2728 loss = 30.9114\n",
      "   2 1210 / 2728 loss = 32.6948\n",
      "   2 1220 / 2728 loss = 7.8824\n",
      "   2 1230 / 2728 loss = 12.2996\n",
      "   2 1240 / 2728 loss = 24.5666\n",
      "   2 1250 / 2728 loss = 14.5179\n",
      "   2 1260 / 2728 loss = 37.9458\n",
      "   2 1270 / 2728 loss = 9.5613\n",
      "   2 1280 / 2728 loss = 9.0974\n",
      "   2 1290 / 2728 loss = 29.9478\n",
      "   2 1300 / 2728 loss = 22.4831\n",
      "   2 1310 / 2728 loss = 21.2796\n",
      "   2 1320 / 2728 loss = 44.1284\n",
      "   2 1330 / 2728 loss = 55.8378\n",
      "   2 1340 / 2728 loss = 7.9875\n",
      "   2 1350 / 2728 loss = 21.7754\n",
      "   2 1360 / 2728 loss = 9.0317\n",
      "   2 1370 / 2728 loss = 13.5755\n",
      "   2 1380 / 2728 loss = 7.0373\n",
      "   2 1390 / 2728 loss = 6.9367\n",
      "   2 1400 / 2728 loss = 8.7944\n",
      "   2 1410 / 2728 loss = 8.3978\n",
      "   2 1420 / 2728 loss = 22.6529\n",
      "   2 1430 / 2728 loss = 6.5541\n",
      "   2 1440 / 2728 loss = 8.0641\n",
      "   2 1450 / 2728 loss = 13.7993\n",
      "   2 1460 / 2728 loss = 20.4682\n",
      "   2 1470 / 2728 loss = 28.5107\n",
      "   2 1480 / 2728 loss = 12.9175\n",
      "   2 1490 / 2728 loss = 8.3319\n",
      "   2 1500 / 2728 loss = 32.4962\n",
      "   2 1510 / 2728 loss = 7.9198\n",
      "   2 1520 / 2728 loss = 9.5957\n",
      "   2 1530 / 2728 loss = 25.6853\n",
      "   2 1540 / 2728 loss = 12.7102\n",
      "   2 1550 / 2728 loss = 25.2596\n",
      "   2 1560 / 2728 loss = 7.6255\n",
      "   2 1570 / 2728 loss = 23.0887\n",
      "   2 1580 / 2728 loss = 7.7110\n",
      "   2 1590 / 2728 loss = 7.3647\n",
      "   2 1600 / 2728 loss = 10.2024\n",
      "   2 1610 / 2728 loss = 19.4262\n",
      "   2 1620 / 2728 loss = 11.0027\n",
      "   2 1630 / 2728 loss = 40.2008\n",
      "   2 1640 / 2728 loss = 38.0937\n",
      "   2 1650 / 2728 loss = 24.8614\n",
      "   2 1660 / 2728 loss = 10.4814\n",
      "   2 1670 / 2728 loss = 11.0330\n",
      "   2 1680 / 2728 loss = 17.2008\n",
      "   2 1690 / 2728 loss = 12.2858\n",
      "   2 1700 / 2728 loss = 31.2435\n",
      "   2 1710 / 2728 loss = 16.7915\n",
      "   2 1720 / 2728 loss = 6.5949\n",
      "   2 1730 / 2728 loss = 16.9690\n",
      "   2 1740 / 2728 loss = 38.8923\n",
      "   2 1750 / 2728 loss = 11.4579\n",
      "   2 1760 / 2728 loss = 44.1083\n",
      "   2 1770 / 2728 loss = 14.5089\n",
      "   2 1780 / 2728 loss = 12.8914\n",
      "   2 1790 / 2728 loss = 20.6609\n",
      "   2 1800 / 2728 loss = 15.7375\n",
      "   2 1810 / 2728 loss = 6.3771\n",
      "   2 1820 / 2728 loss = 11.0031\n",
      "   2 1830 / 2728 loss = 15.2026\n",
      "   2 1840 / 2728 loss = 6.6057\n",
      "   2 1850 / 2728 loss = 6.4524\n",
      "   2 1860 / 2728 loss = 22.9967\n",
      "   2 1870 / 2728 loss = 11.1869\n",
      "   2 1880 / 2728 loss = 11.3220\n",
      "   2 1890 / 2728 loss = 25.9777\n",
      "   2 1900 / 2728 loss = 12.5125\n",
      "   2 1910 / 2728 loss = 49.1427\n",
      "   2 1920 / 2728 loss = 24.0976\n",
      "   2 1930 / 2728 loss = 6.0137\n",
      "   2 1940 / 2728 loss = 7.2290\n",
      "   2 1950 / 2728 loss = 16.6003\n",
      "   2 1960 / 2728 loss = 13.4639\n",
      "   2 1970 / 2728 loss = 7.0378\n",
      "   2 1980 / 2728 loss = 7.5859\n",
      "   2 1990 / 2728 loss = 27.1403\n",
      "   2 2000 / 2728 loss = 8.7827\n",
      "   2 2010 / 2728 loss = 21.1283\n",
      "   2 2020 / 2728 loss = 29.3274\n",
      "   2 2030 / 2728 loss = 9.9637\n",
      "   2 2040 / 2728 loss = 10.8252\n",
      "   2 2050 / 2728 loss = 10.5105\n",
      "   2 2060 / 2728 loss = 18.1710\n",
      "   2 2070 / 2728 loss = 17.3793\n",
      "   2 2080 / 2728 loss = 7.3447\n",
      "   2 2090 / 2728 loss = 32.4551\n",
      "   2 2100 / 2728 loss = 16.0214\n",
      "   2 2110 / 2728 loss = 25.6158\n",
      "   2 2120 / 2728 loss = 6.7703\n",
      "   2 2130 / 2728 loss = 5.0333\n",
      "   2 2140 / 2728 loss = 21.4657\n",
      "   2 2150 / 2728 loss = 14.0140\n",
      "   2 2160 / 2728 loss = 7.5226\n",
      "   2 2170 / 2728 loss = 9.4564\n",
      "   2 2180 / 2728 loss = 17.3288\n",
      "   2 2190 / 2728 loss = 58.5971\n",
      "   2 2200 / 2728 loss = 13.4128\n",
      "   2 2210 / 2728 loss = 7.5800\n",
      "   2 2220 / 2728 loss = 6.8566\n",
      "   2 2230 / 2728 loss = 18.8757\n",
      "   2 2240 / 2728 loss = 5.1841\n",
      "   2 2250 / 2728 loss = 35.7850\n",
      "   2 2260 / 2728 loss = 28.4304\n",
      "   2 2270 / 2728 loss = 6.2672\n",
      "   2 2280 / 2728 loss = 17.8457\n",
      "   2 2290 / 2728 loss = 16.5931\n",
      "   2 2300 / 2728 loss = 11.8618\n",
      "   2 2310 / 2728 loss = 11.5399\n",
      "   2 2320 / 2728 loss = 4.7003\n",
      "   2 2330 / 2728 loss = 18.0038\n",
      "   2 2340 / 2728 loss = 13.8403\n",
      "   2 2350 / 2728 loss = 6.6143\n",
      "   2 2360 / 2728 loss = 19.5371\n",
      "   2 2370 / 2728 loss = 9.3596\n",
      "   2 2380 / 2728 loss = 22.0032\n",
      "   2 2390 / 2728 loss = 50.7817\n",
      "   2 2400 / 2728 loss = 8.9473\n",
      "   2 2410 / 2728 loss = 27.9072\n",
      "   2 2420 / 2728 loss = 8.7585\n",
      "   2 2430 / 2728 loss = 11.9800\n",
      "   2 2440 / 2728 loss = 15.1755\n",
      "   2 2450 / 2728 loss = 25.1466\n",
      "   2 2460 / 2728 loss = 5.5297\n",
      "   2 2470 / 2728 loss = 24.7153\n",
      "   2 2480 / 2728 loss = 9.3977\n",
      "   2 2490 / 2728 loss = 16.1606\n",
      "   2 2500 / 2728 loss = 8.4676\n",
      "   2 2510 / 2728 loss = 29.3916\n",
      "   2 2520 / 2728 loss = 7.5492\n",
      "   2 2530 / 2728 loss = 31.1432\n",
      "   2 2540 / 2728 loss = 34.8146\n",
      "   2 2550 / 2728 loss = 12.3315\n",
      "   2 2560 / 2728 loss = 13.5441\n",
      "   2 2570 / 2728 loss = 14.8352\n",
      "   2 2580 / 2728 loss = 11.7952\n",
      "   2 2590 / 2728 loss = 9.1450\n",
      "   2 2600 / 2728 loss = 8.0929\n",
      "   2 2610 / 2728 loss = 10.2578\n",
      "   2 2620 / 2728 loss = 10.2267\n",
      "   2 2630 / 2728 loss = 32.4806\n",
      "   2 2640 / 2728 loss = 6.6487\n",
      "   2 2650 / 2728 loss = 5.0952\n",
      "   2 2660 / 2728 loss = 8.3797\n",
      "   2 2670 / 2728 loss = 9.8046\n",
      "   2 2680 / 2728 loss = 8.5770\n",
      "   2 2690 / 2728 loss = 38.7158\n",
      "   2 2700 / 2728 loss = 16.5418\n",
      "   2 2710 / 2728 loss = 5.8625\n",
      "   2 2720 / 2728 loss = 26.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [07:45<03:52, 232.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:34:17: epcoh =    2 , loss = 1172.7178 , time = 230.71 s\n",
      "^_^-training data finished-^_^\n",
      "   3    0 / 2728 loss = 8.9296\n",
      "   3   10 / 2728 loss = 15.9136\n",
      "   3   20 / 2728 loss = 7.1544\n",
      "   3   30 / 2728 loss = 5.5564\n",
      "   3   40 / 2728 loss = 20.4171\n",
      "   3   50 / 2728 loss = 6.8679\n",
      "   3   60 / 2728 loss = 43.5309\n",
      "   3   70 / 2728 loss = 22.3931\n",
      "   3   80 / 2728 loss = 32.0310\n",
      "   3   90 / 2728 loss = 10.8197\n",
      "   3  100 / 2728 loss = 26.5948\n",
      "   3  110 / 2728 loss = 21.4885\n",
      "   3  120 / 2728 loss = 16.5310\n",
      "   3  130 / 2728 loss = 7.2722\n",
      "   3  140 / 2728 loss = 12.1117\n",
      "   3  150 / 2728 loss = 11.6148\n",
      "   3  160 / 2728 loss = 13.6156\n",
      "   3  170 / 2728 loss = 28.6625\n",
      "   3  180 / 2728 loss = 8.1206\n",
      "   3  190 / 2728 loss = 11.8085\n",
      "   3  200 / 2728 loss = 9.8870\n",
      "   3  210 / 2728 loss = 9.4762\n",
      "   3  220 / 2728 loss = 5.4618\n",
      "   3  230 / 2728 loss = 8.6192\n",
      "   3  240 / 2728 loss = 15.2850\n",
      "   3  250 / 2728 loss = 7.9141\n",
      "   3  260 / 2728 loss = 18.2620\n",
      "   3  270 / 2728 loss = 18.9702\n",
      "   3  280 / 2728 loss = 27.8783\n",
      "   3  290 / 2728 loss = 7.7289\n",
      "   3  300 / 2728 loss = 16.8100\n",
      "   3  310 / 2728 loss = 11.3636\n",
      "   3  320 / 2728 loss = 13.8528\n",
      "   3  330 / 2728 loss = 12.3856\n",
      "   3  340 / 2728 loss = 6.9629\n",
      "   3  350 / 2728 loss = 28.8051\n",
      "   3  360 / 2728 loss = 14.3389\n",
      "   3  370 / 2728 loss = 23.6631\n",
      "   3  380 / 2728 loss = 21.1566\n",
      "   3  390 / 2728 loss = 27.1390\n",
      "   3  400 / 2728 loss = 8.4086\n",
      "   3  410 / 2728 loss = 10.2919\n",
      "   3  420 / 2728 loss = 12.3227\n",
      "   3  430 / 2728 loss = 37.4990\n",
      "   3  440 / 2728 loss = 32.2119\n",
      "   3  450 / 2728 loss = 23.9608\n",
      "   3  460 / 2728 loss = 14.3718\n",
      "   3  470 / 2728 loss = 19.0821\n",
      "   3  480 / 2728 loss = 14.7592\n",
      "   3  490 / 2728 loss = 9.8847\n",
      "   3  500 / 2728 loss = 10.8427\n",
      "   3  510 / 2728 loss = 18.1079\n",
      "   3  520 / 2728 loss = 12.8290\n",
      "   3  530 / 2728 loss = 91.2269\n",
      "   3  540 / 2728 loss = 14.3087\n",
      "   3  550 / 2728 loss = 46.4985\n",
      "   3  560 / 2728 loss = 5.4385\n",
      "   3  570 / 2728 loss = 5.9067\n",
      "   3  580 / 2728 loss = 25.1188\n",
      "   3  590 / 2728 loss = 26.5523\n",
      "   3  600 / 2728 loss = 44.7448\n",
      "   3  610 / 2728 loss = 7.8382\n",
      "   3  620 / 2728 loss = 6.1455\n",
      "   3  630 / 2728 loss = 11.2526\n",
      "   3  640 / 2728 loss = 22.2990\n",
      "   3  650 / 2728 loss = 10.0826\n",
      "   3  660 / 2728 loss = 24.1714\n",
      "   3  670 / 2728 loss = 8.8593\n",
      "   3  680 / 2728 loss = 32.1289\n",
      "   3  690 / 2728 loss = 14.3134\n",
      "   3  700 / 2728 loss = 7.5740\n",
      "   3  710 / 2728 loss = 8.2829\n",
      "   3  720 / 2728 loss = 21.8331\n",
      "   3  730 / 2728 loss = 3.9957\n",
      "   3  740 / 2728 loss = 5.0543\n",
      "   3  750 / 2728 loss = 8.2273\n",
      "   3  760 / 2728 loss = 10.1564\n",
      "   3  770 / 2728 loss = 3.6016\n",
      "   3  780 / 2728 loss = 4.4701\n",
      "   3  790 / 2728 loss = 13.2188\n",
      "   3  800 / 2728 loss = 4.2737\n",
      "   3  810 / 2728 loss = 17.5225\n",
      "   3  820 / 2728 loss = 20.3057\n",
      "   3  830 / 2728 loss = 10.2085\n",
      "   3  840 / 2728 loss = 14.5941\n",
      "   3  850 / 2728 loss = 11.2215\n",
      "   3  860 / 2728 loss = 11.3350\n",
      "   3  870 / 2728 loss = 14.1120\n",
      "   3  880 / 2728 loss = 6.3366\n",
      "   3  890 / 2728 loss = 17.0271\n",
      "   3  900 / 2728 loss = 5.3917\n",
      "   3  910 / 2728 loss = 5.4841\n",
      "   3  920 / 2728 loss = 4.9995\n",
      "   3  930 / 2728 loss = 8.8358\n",
      "   3  940 / 2728 loss = 22.1941\n",
      "   3  950 / 2728 loss = 34.4637\n",
      "   3  960 / 2728 loss = 4.5985\n",
      "   3  970 / 2728 loss = 7.4710\n",
      "   3  980 / 2728 loss = 26.8160\n",
      "   3  990 / 2728 loss = 18.3404\n",
      "   3 1000 / 2728 loss = 8.8388\n",
      "   3 1010 / 2728 loss = 19.3884\n",
      "   3 1020 / 2728 loss = 22.4447\n",
      "   3 1030 / 2728 loss = 12.8571\n",
      "   3 1040 / 2728 loss = 44.6764\n",
      "   3 1050 / 2728 loss = 12.8185\n",
      "   3 1060 / 2728 loss = 10.8946\n",
      "   3 1070 / 2728 loss = 14.0616\n",
      "   3 1080 / 2728 loss = 11.0870\n",
      "   3 1090 / 2728 loss = 9.7926\n",
      "   3 1100 / 2728 loss = 6.2042\n",
      "   3 1110 / 2728 loss = 12.9147\n",
      "   3 1120 / 2728 loss = 15.1625\n",
      "   3 1130 / 2728 loss = 14.6273\n",
      "   3 1140 / 2728 loss = 7.0828\n",
      "   3 1150 / 2728 loss = 4.0638\n",
      "   3 1160 / 2728 loss = 23.3495\n",
      "   3 1170 / 2728 loss = 4.1839\n",
      "   3 1180 / 2728 loss = 8.0719\n",
      "   3 1190 / 2728 loss = 21.3674\n",
      "   3 1200 / 2728 loss = 11.0423\n",
      "   3 1210 / 2728 loss = 4.6842\n",
      "   3 1220 / 2728 loss = 11.3284\n",
      "   3 1230 / 2728 loss = 5.3693\n",
      "   3 1240 / 2728 loss = 57.8975\n",
      "   3 1250 / 2728 loss = 49.1543\n",
      "   3 1260 / 2728 loss = 44.6611\n",
      "   3 1270 / 2728 loss = 35.5285\n",
      "   3 1280 / 2728 loss = 12.6708\n",
      "   3 1290 / 2728 loss = 14.9335\n",
      "   3 1300 / 2728 loss = 24.4425\n",
      "   3 1310 / 2728 loss = 6.5528\n",
      "   3 1320 / 2728 loss = 10.0055\n",
      "   3 1330 / 2728 loss = 4.9368\n",
      "   3 1340 / 2728 loss = 15.1148\n",
      "   3 1350 / 2728 loss = 36.1813\n",
      "   3 1360 / 2728 loss = 14.3616\n",
      "   3 1370 / 2728 loss = 4.8522\n",
      "   3 1380 / 2728 loss = 4.8324\n",
      "   3 1390 / 2728 loss = 6.6460\n",
      "   3 1400 / 2728 loss = 8.1514\n",
      "   3 1410 / 2728 loss = 4.8171\n",
      "   3 1420 / 2728 loss = 17.8233\n",
      "   3 1430 / 2728 loss = 13.4466\n",
      "   3 1440 / 2728 loss = 10.4027\n",
      "   3 1450 / 2728 loss = 12.2193\n",
      "   3 1460 / 2728 loss = 5.1195\n",
      "   3 1470 / 2728 loss = 8.6285\n",
      "   3 1480 / 2728 loss = 8.8070\n",
      "   3 1490 / 2728 loss = 8.1917\n",
      "   3 1500 / 2728 loss = 4.3904\n",
      "   3 1510 / 2728 loss = 5.9662\n",
      "   3 1520 / 2728 loss = 10.0597\n",
      "   3 1530 / 2728 loss = 14.2184\n",
      "   3 1540 / 2728 loss = 45.0627\n",
      "   3 1550 / 2728 loss = 5.3976\n",
      "   3 1560 / 2728 loss = 16.0333\n",
      "   3 1570 / 2728 loss = 17.1759\n",
      "   3 1580 / 2728 loss = 7.8080\n",
      "   3 1590 / 2728 loss = 8.2680\n",
      "   3 1600 / 2728 loss = 10.9563\n",
      "   3 1610 / 2728 loss = 31.0928\n",
      "   3 1620 / 2728 loss = 9.0104\n",
      "   3 1630 / 2728 loss = 7.1790\n",
      "   3 1640 / 2728 loss = 3.2505\n",
      "   3 1650 / 2728 loss = 7.0073\n",
      "   3 1660 / 2728 loss = 13.1847\n",
      "   3 1670 / 2728 loss = 8.5246\n",
      "   3 1680 / 2728 loss = 8.7944\n",
      "   3 1690 / 2728 loss = 11.8248\n",
      "   3 1700 / 2728 loss = 13.8623\n",
      "   3 1710 / 2728 loss = 9.4960\n",
      "   3 1720 / 2728 loss = 6.0197\n",
      "   3 1730 / 2728 loss = 8.8904\n",
      "   3 1740 / 2728 loss = 59.5179\n",
      "   3 1750 / 2728 loss = 23.5097\n",
      "   3 1760 / 2728 loss = 8.5124\n",
      "   3 1770 / 2728 loss = 45.6528\n",
      "   3 1780 / 2728 loss = 22.2578\n",
      "   3 1790 / 2728 loss = 26.9656\n",
      "   3 1800 / 2728 loss = 6.6096\n",
      "   3 1810 / 2728 loss = 5.6697\n",
      "   3 1820 / 2728 loss = 7.7089\n",
      "   3 1830 / 2728 loss = 10.2687\n",
      "   3 1840 / 2728 loss = 22.4147\n",
      "   3 1850 / 2728 loss = 10.3029\n",
      "   3 1860 / 2728 loss = 7.2011\n",
      "   3 1870 / 2728 loss = 5.7211\n",
      "   3 1880 / 2728 loss = 6.5739\n",
      "   3 1890 / 2728 loss = 5.7963\n",
      "   3 1900 / 2728 loss = 19.7411\n",
      "   3 1910 / 2728 loss = 6.4445\n",
      "   3 1920 / 2728 loss = 7.2568\n",
      "   3 1930 / 2728 loss = 8.7555\n",
      "   3 1940 / 2728 loss = 12.9596\n",
      "   3 1950 / 2728 loss = 6.8827\n",
      "   3 1960 / 2728 loss = 49.4302\n",
      "   3 1970 / 2728 loss = 12.1077\n",
      "   3 1980 / 2728 loss = 5.1634\n",
      "   3 1990 / 2728 loss = 4.7960\n",
      "   3 2000 / 2728 loss = 9.0555\n",
      "   3 2010 / 2728 loss = 9.6222\n",
      "   3 2020 / 2728 loss = 6.4545\n",
      "   3 2030 / 2728 loss = 5.5369\n",
      "   3 2040 / 2728 loss = 4.8006\n",
      "   3 2050 / 2728 loss = 23.4171\n",
      "   3 2060 / 2728 loss = 5.7159\n",
      "   3 2070 / 2728 loss = 29.1064\n",
      "   3 2080 / 2728 loss = 6.0381\n",
      "   3 2090 / 2728 loss = 6.3010\n",
      "   3 2100 / 2728 loss = 43.8121\n",
      "   3 2110 / 2728 loss = 4.6677\n",
      "   3 2120 / 2728 loss = 7.9992\n",
      "   3 2130 / 2728 loss = 14.3466\n",
      "   3 2140 / 2728 loss = 8.2027\n",
      "   3 2150 / 2728 loss = 12.5865\n",
      "   3 2160 / 2728 loss = 12.8520\n",
      "   3 2170 / 2728 loss = 22.0156\n",
      "   3 2180 / 2728 loss = 6.9371\n",
      "   3 2190 / 2728 loss = 5.2259\n",
      "   3 2200 / 2728 loss = 14.6530\n",
      "   3 2210 / 2728 loss = 4.2918\n",
      "   3 2220 / 2728 loss = 4.7327\n",
      "   3 2230 / 2728 loss = 5.8400\n",
      "   3 2240 / 2728 loss = 10.0821\n",
      "   3 2250 / 2728 loss = 17.7824\n",
      "   3 2260 / 2728 loss = 18.0686\n",
      "   3 2270 / 2728 loss = 7.9720\n",
      "   3 2280 / 2728 loss = 14.0872\n",
      "   3 2290 / 2728 loss = 6.3563\n",
      "   3 2300 / 2728 loss = 6.2513\n",
      "   3 2310 / 2728 loss = 3.6873\n",
      "   3 2320 / 2728 loss = 5.7027\n",
      "   3 2330 / 2728 loss = 15.3602\n",
      "   3 2340 / 2728 loss = 7.5571\n",
      "   3 2350 / 2728 loss = 11.4522\n",
      "   3 2360 / 2728 loss = 7.0232\n",
      "   3 2370 / 2728 loss = 7.3664\n",
      "   3 2380 / 2728 loss = 8.9680\n",
      "   3 2390 / 2728 loss = 4.3369\n",
      "   3 2400 / 2728 loss = 10.4807\n",
      "   3 2410 / 2728 loss = 20.9782\n",
      "   3 2420 / 2728 loss = 5.8097\n",
      "   3 2430 / 2728 loss = 27.9527\n",
      "   3 2440 / 2728 loss = 5.1607\n",
      "   3 2450 / 2728 loss = 18.6455\n",
      "   3 2460 / 2728 loss = 13.9857\n",
      "   3 2470 / 2728 loss = 11.7649\n",
      "   3 2480 / 2728 loss = 4.4686\n",
      "   3 2490 / 2728 loss = 5.6722\n",
      "   3 2500 / 2728 loss = 4.3131\n",
      "   3 2510 / 2728 loss = 13.4332\n",
      "   3 2520 / 2728 loss = 11.6113\n",
      "   3 2530 / 2728 loss = 14.0156\n",
      "   3 2540 / 2728 loss = 9.5628\n",
      "   3 2550 / 2728 loss = 5.3430\n",
      "   3 2560 / 2728 loss = 4.8621\n",
      "   3 2570 / 2728 loss = 22.3803\n",
      "   3 2580 / 2728 loss = 4.4093\n",
      "   3 2590 / 2728 loss = 9.9515\n",
      "   3 2600 / 2728 loss = 9.1541\n",
      "   3 2610 / 2728 loss = 7.5676\n",
      "   3 2620 / 2728 loss = 5.1743\n",
      "   3 2630 / 2728 loss = 7.3818\n",
      "   3 2640 / 2728 loss = 5.7787\n",
      "   3 2650 / 2728 loss = 4.2017\n",
      "   3 2660 / 2728 loss = 3.9939\n",
      "   3 2670 / 2728 loss = 4.1403\n",
      "   3 2680 / 2728 loss = 4.7493\n",
      "   3 2690 / 2728 loss = 9.6533\n",
      "   3 2700 / 2728 loss = 5.9361\n",
      "   3 2710 / 2728 loss = 12.4753\n",
      "   3 2720 / 2728 loss = 5.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:38<00:00, 232.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:38:09: epcoh =    3 , loss = 885.4382 , time = 230.83 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
