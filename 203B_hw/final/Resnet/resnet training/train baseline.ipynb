{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c44bf7-acb0-481c-88cf-03e9298a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '64', '--train_data', 'data/Train400', '--sigma', '4', '--epoch', '3', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=3, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "        \n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, out_channels=64, in_channels=1, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1, stride=1)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_layers = []\n",
    "        for _ in range(10):\n",
    "            for sub in self.make_Residual():\n",
    "                output_layers.append(sub)\n",
    "        self.out = nn.Sequential(*output_layers)\n",
    "        self.res = nn.Conv2d(64, 1, kernel_size=3, padding=1, stride=1)\n",
    "        \n",
    "    def make_Residual(self, in_channels=64, out_channels=64, kernel_size=3):\n",
    "        i = 0\n",
    "        layers = []\n",
    "        for i in range(2):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, bias=True))\n",
    "            layers.append(nn.BatchNorm2d(64, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        return layers\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.relu(self.BN(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.res(out)\n",
    "        return dn\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^_^-training data finished-^_^\n",
      "   1    0 / 2728 loss = 74.5793\n",
      "   1   10 / 2728 loss = 1.9732\n",
      "   1   20 / 2728 loss = 0.6997\n",
      "   1   30 / 2728 loss = 0.3605\n",
      "   1   40 / 2728 loss = 0.3070\n",
      "   1   50 / 2728 loss = 0.2544\n",
      "   1   60 / 2728 loss = 0.2318\n",
      "   1   70 / 2728 loss = 0.2427\n",
      "   1   80 / 2728 loss = 0.2478\n",
      "   1   90 / 2728 loss = 0.2374\n",
      "   1  100 / 2728 loss = 0.2324\n",
      "   1  110 / 2728 loss = 0.2304\n",
      "   1  120 / 2728 loss = 0.2278\n",
      "   1  130 / 2728 loss = 0.2258\n",
      "   1  140 / 2728 loss = 0.2255\n",
      "   1  150 / 2728 loss = 0.2160\n",
      "   1  160 / 2728 loss = 0.2117\n",
      "   1  170 / 2728 loss = 0.2230\n",
      "   1  180 / 2728 loss = 0.2067\n",
      "   1  190 / 2728 loss = 0.2268\n",
      "   1  200 / 2728 loss = 0.2130\n",
      "   1  210 / 2728 loss = 0.2591\n",
      "   1  220 / 2728 loss = 0.2136\n",
      "   1  230 / 2728 loss = 0.2114\n",
      "   1  240 / 2728 loss = 0.2137\n",
      "   1  250 / 2728 loss = 0.2098\n",
      "   1  260 / 2728 loss = 0.2109\n",
      "   1  270 / 2728 loss = 0.2019\n",
      "   1  280 / 2728 loss = 0.2141\n",
      "   1  290 / 2728 loss = 0.2111\n",
      "   1  300 / 2728 loss = 0.2072\n",
      "   1  310 / 2728 loss = 0.2184\n",
      "   1  320 / 2728 loss = 0.2061\n",
      "   1  330 / 2728 loss = 0.2041\n",
      "   1  340 / 2728 loss = 0.2291\n",
      "   1  350 / 2728 loss = 0.2075\n",
      "   1  360 / 2728 loss = 0.2106\n",
      "   1  370 / 2728 loss = 0.2157\n",
      "   1  380 / 2728 loss = 0.2095\n",
      "   1  390 / 2728 loss = 0.2044\n",
      "   1  400 / 2728 loss = 0.2007\n",
      "   1  410 / 2728 loss = 0.2016\n",
      "   1  420 / 2728 loss = 0.2111\n",
      "   1  430 / 2728 loss = 0.2042\n",
      "   1  440 / 2728 loss = 0.2022\n",
      "   1  450 / 2728 loss = 0.2042\n",
      "   1  460 / 2728 loss = 0.2037\n",
      "   1  470 / 2728 loss = 0.1983\n",
      "   1  480 / 2728 loss = 0.2033\n",
      "   1  490 / 2728 loss = 0.2022\n",
      "   1  500 / 2728 loss = 0.2043\n",
      "   1  510 / 2728 loss = 0.2096\n",
      "   1  520 / 2728 loss = 0.1987\n",
      "   1  530 / 2728 loss = 0.2068\n",
      "   1  540 / 2728 loss = 0.2055\n",
      "   1  550 / 2728 loss = 0.2044\n",
      "   1  560 / 2728 loss = 0.2054\n",
      "   1  570 / 2728 loss = 0.2020\n",
      "   1  580 / 2728 loss = 0.2008\n",
      "   1  590 / 2728 loss = 0.2030\n",
      "   1  600 / 2728 loss = 0.2004\n",
      "   1  610 / 2728 loss = 0.2061\n",
      "   1  620 / 2728 loss = 0.2049\n",
      "   1  630 / 2728 loss = 0.2029\n",
      "   1  640 / 2728 loss = 0.2005\n",
      "   1  650 / 2728 loss = 0.2063\n",
      "   1  660 / 2728 loss = 0.2099\n",
      "   1  670 / 2728 loss = 0.2031\n",
      "   1  680 / 2728 loss = 0.1990\n",
      "   1  690 / 2728 loss = 0.1985\n",
      "   1  700 / 2728 loss = 0.1988\n",
      "   1  710 / 2728 loss = 0.1969\n",
      "   1  720 / 2728 loss = 0.2006\n",
      "   1  730 / 2728 loss = 0.2002\n",
      "   1  740 / 2728 loss = 0.1985\n",
      "   1  750 / 2728 loss = 0.2064\n",
      "   1  760 / 2728 loss = 0.1991\n",
      "   1  770 / 2728 loss = 0.1982\n",
      "   1  780 / 2728 loss = 0.1992\n",
      "   1  790 / 2728 loss = 0.1972\n",
      "   1  800 / 2728 loss = 0.2002\n",
      "   1  810 / 2728 loss = 0.2033\n",
      "   1  820 / 2728 loss = 0.1971\n",
      "   1  830 / 2728 loss = 0.1993\n",
      "   1  840 / 2728 loss = 0.1984\n",
      "   1  850 / 2728 loss = 0.1987\n",
      "   1  860 / 2728 loss = 0.1981\n",
      "   1  870 / 2728 loss = 0.1971\n",
      "   1  880 / 2728 loss = 0.2000\n",
      "   1  890 / 2728 loss = 0.1980\n",
      "   1  900 / 2728 loss = 0.2011\n",
      "   1  910 / 2728 loss = 0.1981\n",
      "   1  920 / 2728 loss = 0.1995\n",
      "   1  930 / 2728 loss = 0.1990\n",
      "   1  940 / 2728 loss = 0.1999\n",
      "   1  950 / 2728 loss = 0.2019\n",
      "   1  960 / 2728 loss = 0.1999\n",
      "   1  970 / 2728 loss = 0.1986\n",
      "   1  980 / 2728 loss = 0.1980\n",
      "   1  990 / 2728 loss = 0.1960\n",
      "   1 1000 / 2728 loss = 0.1975\n",
      "   1 1010 / 2728 loss = 0.2020\n",
      "   1 1020 / 2728 loss = 0.1971\n",
      "   1 1030 / 2728 loss = 0.1969\n",
      "   1 1040 / 2728 loss = 0.1970\n",
      "   1 1050 / 2728 loss = 0.1980\n",
      "   1 1060 / 2728 loss = 0.1981\n",
      "   1 1070 / 2728 loss = 0.1997\n",
      "   1 1080 / 2728 loss = 0.1975\n",
      "   1 1090 / 2728 loss = 0.1954\n",
      "   1 1100 / 2728 loss = 0.1973\n",
      "   1 1110 / 2728 loss = 0.1974\n",
      "   1 1120 / 2728 loss = 0.1966\n",
      "   1 1130 / 2728 loss = 0.1986\n",
      "   1 1140 / 2728 loss = 0.1946\n",
      "   1 1150 / 2728 loss = 0.1967\n",
      "   1 1160 / 2728 loss = 0.1943\n",
      "   1 1170 / 2728 loss = 0.1973\n",
      "   1 1180 / 2728 loss = 0.1940\n",
      "   1 1190 / 2728 loss = 0.1926\n",
      "   1 1200 / 2728 loss = 0.1945\n",
      "   1 1210 / 2728 loss = 0.1914\n",
      "   1 1220 / 2728 loss = 0.1923\n",
      "   1 1230 / 2728 loss = 0.1948\n",
      "   1 1240 / 2728 loss = 0.1933\n",
      "   1 1250 / 2728 loss = 0.1923\n",
      "   1 1260 / 2728 loss = 0.1903\n",
      "   1 1270 / 2728 loss = 0.1910\n",
      "   1 1280 / 2728 loss = 0.1897\n",
      "   1 1290 / 2728 loss = 0.1890\n",
      "   1 1300 / 2728 loss = 0.1906\n",
      "   1 1310 / 2728 loss = 0.1899\n",
      "   1 1320 / 2728 loss = 0.1903\n",
      "   1 1330 / 2728 loss = 0.1864\n",
      "   1 1340 / 2728 loss = 0.1884\n",
      "   1 1350 / 2728 loss = 0.1856\n",
      "   1 1360 / 2728 loss = 0.1880\n",
      "   1 1370 / 2728 loss = 0.1872\n",
      "   1 1380 / 2728 loss = 0.1873\n",
      "   1 1390 / 2728 loss = 0.1855\n",
      "   1 1400 / 2728 loss = 0.1820\n",
      "   1 1410 / 2728 loss = 0.1880\n",
      "   1 1420 / 2728 loss = 0.1817\n",
      "   1 1430 / 2728 loss = 0.1815\n",
      "   1 1440 / 2728 loss = 0.1838\n",
      "   1 1450 / 2728 loss = 0.1796\n",
      "   1 1460 / 2728 loss = 0.1823\n",
      "   1 1470 / 2728 loss = 0.1818\n",
      "   1 1480 / 2728 loss = 0.1782\n",
      "   1 1490 / 2728 loss = 0.1757\n",
      "   1 1500 / 2728 loss = 0.1780\n",
      "   1 1510 / 2728 loss = 0.1766\n",
      "   1 1520 / 2728 loss = 0.1742\n",
      "   1 1530 / 2728 loss = 0.1778\n",
      "   1 1540 / 2728 loss = 0.1728\n",
      "   1 1550 / 2728 loss = 0.1725\n",
      "   1 1560 / 2728 loss = 0.1758\n",
      "   1 1570 / 2728 loss = 0.1791\n",
      "   1 1580 / 2728 loss = 0.1760\n",
      "   1 1590 / 2728 loss = 0.1747\n",
      "   1 1600 / 2728 loss = 0.1662\n",
      "   1 1610 / 2728 loss = 0.1708\n",
      "   1 1620 / 2728 loss = 0.1723\n",
      "   1 1630 / 2728 loss = 0.1657\n",
      "   1 1640 / 2728 loss = 0.1695\n",
      "   1 1650 / 2728 loss = 0.1637\n",
      "   1 1660 / 2728 loss = 0.1604\n",
      "   1 1670 / 2728 loss = 0.1689\n",
      "   1 1680 / 2728 loss = 0.1690\n",
      "   1 1690 / 2728 loss = 0.1635\n",
      "   1 1700 / 2728 loss = 0.1583\n",
      "   1 1710 / 2728 loss = 0.1610\n",
      "   1 1720 / 2728 loss = 0.1599\n",
      "   1 1730 / 2728 loss = 0.1582\n",
      "   1 1740 / 2728 loss = 0.1609\n",
      "   1 1750 / 2728 loss = 0.1699\n",
      "   1 1760 / 2728 loss = 0.1593\n",
      "   1 1770 / 2728 loss = 0.1655\n",
      "   1 1780 / 2728 loss = 0.1606\n",
      "   1 1790 / 2728 loss = 0.1736\n",
      "   1 1800 / 2728 loss = 0.1574\n",
      "   1 1810 / 2728 loss = 0.1582\n",
      "   1 1820 / 2728 loss = 0.1544\n",
      "   1 1830 / 2728 loss = 0.1630\n",
      "   1 1840 / 2728 loss = 0.1551\n",
      "   1 1850 / 2728 loss = 0.1539\n",
      "   1 1860 / 2728 loss = 0.1624\n",
      "   1 1870 / 2728 loss = 0.1532\n",
      "   1 1880 / 2728 loss = 0.1609\n",
      "   1 1890 / 2728 loss = 0.1537\n",
      "   1 1900 / 2728 loss = 0.1579\n",
      "   1 1910 / 2728 loss = 0.1497\n",
      "   1 1920 / 2728 loss = 0.1573\n",
      "   1 1930 / 2728 loss = 0.1541\n",
      "   1 1940 / 2728 loss = 0.1539\n",
      "   1 1950 / 2728 loss = 0.1515\n",
      "   1 1960 / 2728 loss = 0.1623\n",
      "   1 1970 / 2728 loss = 0.1579\n",
      "   1 1980 / 2728 loss = 0.1539\n",
      "   1 1990 / 2728 loss = 0.1508\n",
      "   1 2000 / 2728 loss = 0.1571\n",
      "   1 2010 / 2728 loss = 0.1484\n",
      "   1 2020 / 2728 loss = 0.1647\n",
      "   1 2030 / 2728 loss = 0.1548\n",
      "   1 2040 / 2728 loss = 0.1555\n",
      "   1 2050 / 2728 loss = 0.1541\n",
      "   1 2060 / 2728 loss = 0.1548\n",
      "   1 2070 / 2728 loss = 0.1491\n",
      "   1 2080 / 2728 loss = 0.1519\n",
      "   1 2090 / 2728 loss = 0.1515\n",
      "   1 2100 / 2728 loss = 0.1506\n",
      "   1 2110 / 2728 loss = 0.1482\n",
      "   1 2120 / 2728 loss = 0.1504\n",
      "   1 2130 / 2728 loss = 0.1542\n",
      "   1 2140 / 2728 loss = 0.1569\n",
      "   1 2150 / 2728 loss = 0.1581\n",
      "   1 2160 / 2728 loss = 0.1511\n",
      "   1 2170 / 2728 loss = 0.1471\n",
      "   1 2180 / 2728 loss = 0.1459\n",
      "   1 2190 / 2728 loss = 0.1521\n",
      "   1 2200 / 2728 loss = 0.1536\n",
      "   1 2210 / 2728 loss = 0.1572\n",
      "   1 2220 / 2728 loss = 0.1538\n",
      "   1 2230 / 2728 loss = 0.1518\n",
      "   1 2240 / 2728 loss = 0.1449\n",
      "   1 2250 / 2728 loss = 0.1402\n",
      "   1 2260 / 2728 loss = 0.1460\n",
      "   1 2270 / 2728 loss = 0.1410\n",
      "   1 2280 / 2728 loss = 0.1466\n",
      "   1 2290 / 2728 loss = 0.1538\n",
      "   1 2300 / 2728 loss = 0.1543\n",
      "   1 2310 / 2728 loss = 0.1400\n",
      "   1 2320 / 2728 loss = 0.1493\n",
      "   1 2330 / 2728 loss = 0.1490\n",
      "   1 2340 / 2728 loss = 0.1456\n",
      "   1 2350 / 2728 loss = 0.1415\n",
      "   1 2360 / 2728 loss = 0.1423\n",
      "   1 2370 / 2728 loss = 0.1615\n",
      "   1 2380 / 2728 loss = 0.1618\n",
      "   1 2390 / 2728 loss = 0.1520\n",
      "   1 2400 / 2728 loss = 0.1384\n",
      "   1 2410 / 2728 loss = 0.1374\n",
      "   1 2420 / 2728 loss = 0.1463\n",
      "   1 2430 / 2728 loss = 0.1483\n",
      "   1 2440 / 2728 loss = 0.1463\n",
      "   1 2450 / 2728 loss = 0.1569\n",
      "   1 2460 / 2728 loss = 0.1410\n",
      "   1 2470 / 2728 loss = 0.1348\n",
      "   1 2480 / 2728 loss = 0.1482\n",
      "   1 2490 / 2728 loss = 0.1588\n",
      "   1 2500 / 2728 loss = 0.1472\n",
      "   1 2510 / 2728 loss = 0.1442\n",
      "   1 2520 / 2728 loss = 0.1560\n",
      "   1 2530 / 2728 loss = 0.1468\n",
      "   1 2540 / 2728 loss = 0.1544\n",
      "   1 2550 / 2728 loss = 0.1536\n",
      "   1 2560 / 2728 loss = 0.1336\n",
      "   1 2570 / 2728 loss = 0.1501\n",
      "   1 2580 / 2728 loss = 0.1549\n",
      "   1 2590 / 2728 loss = 0.2045\n",
      "   1 2600 / 2728 loss = 0.1898\n",
      "   1 2610 / 2728 loss = 0.1501\n",
      "   1 2620 / 2728 loss = 0.1507\n",
      "   1 2630 / 2728 loss = 0.1498\n",
      "   1 2640 / 2728 loss = 0.1621\n",
      "   1 2650 / 2728 loss = 0.1500\n",
      "   1 2660 / 2728 loss = 0.1403\n",
      "   1 2670 / 2728 loss = 0.1386\n",
      "   1 2680 / 2728 loss = 0.1374\n",
      "   1 2690 / 2728 loss = 0.1388\n",
      "   1 2700 / 2728 loss = 0.1393\n",
      "   1 2710 / 2728 loss = 0.1381\n",
      "   1 2720 / 2728 loss = 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:50<05:41, 170.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-22 05:30:45: epcoh =    1 , loss = 20.1438 , time = 167.67 s\n",
      "^_^-training data finished-^_^\n",
      "   2    0 / 2728 loss = 0.1363\n",
      "   2   10 / 2728 loss = 0.1408\n",
      "   2   20 / 2728 loss = 0.1503\n",
      "   2   30 / 2728 loss = 0.1477\n",
      "   2   40 / 2728 loss = 0.1470\n",
      "   2   50 / 2728 loss = 0.1379\n",
      "   2   60 / 2728 loss = 0.1486\n",
      "   2   70 / 2728 loss = 0.1421\n",
      "   2   80 / 2728 loss = 0.1565\n",
      "   2   90 / 2728 loss = 0.1583\n",
      "   2  100 / 2728 loss = 0.1507\n",
      "   2  110 / 2728 loss = 0.1543\n",
      "   2  120 / 2728 loss = 0.1396\n",
      "   2  130 / 2728 loss = 0.1387\n",
      "   2  140 / 2728 loss = 0.1513\n",
      "   2  150 / 2728 loss = 0.1439\n",
      "   2  160 / 2728 loss = 0.1414\n",
      "   2  170 / 2728 loss = 0.1535\n",
      "   2  180 / 2728 loss = 0.1446\n",
      "   2  190 / 2728 loss = 0.1373\n",
      "   2  200 / 2728 loss = 0.1417\n",
      "   2  210 / 2728 loss = 0.1522\n",
      "   2  220 / 2728 loss = 0.1427\n",
      "   2  230 / 2728 loss = 0.2112\n",
      "   2  240 / 2728 loss = 0.1562\n",
      "   2  250 / 2728 loss = 0.1395\n",
      "   2  260 / 2728 loss = 0.1416\n",
      "   2  270 / 2728 loss = 0.1420\n",
      "   2  280 / 2728 loss = 0.1362\n",
      "   2  290 / 2728 loss = 0.1409\n",
      "   2  300 / 2728 loss = 0.1371\n",
      "   2  310 / 2728 loss = 0.1357\n",
      "   2  320 / 2728 loss = 0.1351\n",
      "   2  330 / 2728 loss = 0.1365\n",
      "   2  340 / 2728 loss = 0.1419\n",
      "   2  350 / 2728 loss = 0.1353\n",
      "   2  360 / 2728 loss = 0.1411\n",
      "   2  370 / 2728 loss = 0.1530\n",
      "   2  380 / 2728 loss = 0.1856\n",
      "   2  390 / 2728 loss = 0.1428\n",
      "   2  400 / 2728 loss = 0.1613\n",
      "   2  410 / 2728 loss = 0.1544\n",
      "   2  420 / 2728 loss = 0.1396\n",
      "   2  430 / 2728 loss = 0.1395\n",
      "   2  440 / 2728 loss = 0.1337\n",
      "   2  450 / 2728 loss = 0.1340\n",
      "   2  460 / 2728 loss = 0.1324\n",
      "   2  470 / 2728 loss = 0.1475\n",
      "   2  480 / 2728 loss = 0.1356\n",
      "   2  490 / 2728 loss = 0.1400\n",
      "   2  500 / 2728 loss = 0.1353\n",
      "   2  510 / 2728 loss = 0.1410\n",
      "   2  520 / 2728 loss = 0.1318\n",
      "   2  530 / 2728 loss = 0.1502\n",
      "   2  540 / 2728 loss = 0.1506\n",
      "   2  550 / 2728 loss = 0.1377\n",
      "   2  560 / 2728 loss = 0.1418\n",
      "   2  570 / 2728 loss = 0.1414\n",
      "   2  580 / 2728 loss = 0.1593\n",
      "   2  590 / 2728 loss = 0.1295\n",
      "   2  600 / 2728 loss = 0.1378\n",
      "   2  610 / 2728 loss = 0.1453\n",
      "   2  620 / 2728 loss = 0.1354\n",
      "   2  630 / 2728 loss = 0.1861\n",
      "   2  640 / 2728 loss = 0.1688\n",
      "   2  650 / 2728 loss = 0.1584\n",
      "   2  660 / 2728 loss = 0.1375\n",
      "   2  670 / 2728 loss = 0.1435\n",
      "   2  680 / 2728 loss = 0.1472\n",
      "   2  690 / 2728 loss = 0.1389\n",
      "   2  700 / 2728 loss = 0.1246\n",
      "   2  710 / 2728 loss = 0.1395\n",
      "   2  720 / 2728 loss = 0.1676\n",
      "   2  730 / 2728 loss = 0.1785\n",
      "   2  740 / 2728 loss = 0.1328\n",
      "   2  750 / 2728 loss = 0.1396\n",
      "   2  760 / 2728 loss = 0.2032\n",
      "   2  770 / 2728 loss = 0.1615\n",
      "   2  780 / 2728 loss = 0.1422\n",
      "   2  790 / 2728 loss = 0.1361\n",
      "   2  800 / 2728 loss = 0.1530\n",
      "   2  810 / 2728 loss = 0.1520\n",
      "   2  820 / 2728 loss = 0.1467\n",
      "   2  830 / 2728 loss = 0.1471\n",
      "   2  840 / 2728 loss = 0.1311\n",
      "   2  850 / 2728 loss = 0.1304\n",
      "   2  860 / 2728 loss = 0.1297\n",
      "   2  870 / 2728 loss = 0.1373\n",
      "   2  880 / 2728 loss = 0.1436\n",
      "   2  890 / 2728 loss = 0.1348\n",
      "   2  900 / 2728 loss = 0.1465\n",
      "   2  910 / 2728 loss = 0.1356\n",
      "   2  920 / 2728 loss = 0.1316\n",
      "   2  930 / 2728 loss = 0.1642\n",
      "   2  940 / 2728 loss = 0.1364\n",
      "   2  950 / 2728 loss = 0.1746\n",
      "   2  960 / 2728 loss = 0.1480\n",
      "   2  970 / 2728 loss = 0.1388\n",
      "   2  980 / 2728 loss = 0.1333\n",
      "   2  990 / 2728 loss = 0.1363\n",
      "   2 1000 / 2728 loss = 0.1320\n",
      "   2 1010 / 2728 loss = 0.1482\n",
      "   2 1020 / 2728 loss = 0.1406\n",
      "   2 1030 / 2728 loss = 0.1378\n",
      "   2 1040 / 2728 loss = 0.1297\n",
      "   2 1050 / 2728 loss = 0.1347\n",
      "   2 1060 / 2728 loss = 0.1364\n",
      "   2 1070 / 2728 loss = 0.1380\n",
      "   2 1080 / 2728 loss = 0.1493\n",
      "   2 1090 / 2728 loss = 0.1451\n",
      "   2 1100 / 2728 loss = 0.1460\n",
      "   2 1110 / 2728 loss = 0.1330\n",
      "   2 1120 / 2728 loss = 0.1283\n",
      "   2 1130 / 2728 loss = 0.1445\n",
      "   2 1140 / 2728 loss = 0.1443\n",
      "   2 1150 / 2728 loss = 0.2291\n",
      "   2 1160 / 2728 loss = 0.1305\n",
      "   2 1170 / 2728 loss = 0.1318\n",
      "   2 1180 / 2728 loss = 0.1432\n",
      "   2 1190 / 2728 loss = 0.1302\n",
      "   2 1200 / 2728 loss = 0.1410\n",
      "   2 1210 / 2728 loss = 0.1347\n",
      "   2 1220 / 2728 loss = 0.1346\n",
      "   2 1230 / 2728 loss = 0.1492\n",
      "   2 1240 / 2728 loss = 0.1393\n",
      "   2 1250 / 2728 loss = 0.1305\n",
      "   2 1260 / 2728 loss = 0.1317\n",
      "   2 1270 / 2728 loss = 0.1302\n",
      "   2 1280 / 2728 loss = 0.1471\n",
      "   2 1290 / 2728 loss = 0.1269\n",
      "   2 1300 / 2728 loss = 0.1429\n",
      "   2 1310 / 2728 loss = 0.1429\n",
      "   2 1320 / 2728 loss = 0.1313\n",
      "   2 1330 / 2728 loss = 0.1338\n",
      "   2 1340 / 2728 loss = 0.1424\n",
      "   2 1350 / 2728 loss = 0.1427\n",
      "   2 1360 / 2728 loss = 0.1267\n",
      "   2 1370 / 2728 loss = 0.1397\n",
      "   2 1380 / 2728 loss = 0.1274\n",
      "   2 1390 / 2728 loss = 0.1422\n",
      "   2 1400 / 2728 loss = 0.1513\n",
      "   2 1410 / 2728 loss = 0.1352\n",
      "   2 1420 / 2728 loss = 0.1408\n",
      "   2 1430 / 2728 loss = 0.1417\n",
      "   2 1440 / 2728 loss = 0.1393\n",
      "   2 1450 / 2728 loss = 0.1360\n",
      "   2 1460 / 2728 loss = 0.1371\n",
      "   2 1470 / 2728 loss = 0.1269\n",
      "   2 1480 / 2728 loss = 0.1279\n",
      "   2 1490 / 2728 loss = 0.1363\n",
      "   2 1500 / 2728 loss = 0.1460\n",
      "   2 1510 / 2728 loss = 0.1343\n",
      "   2 1520 / 2728 loss = 0.1330\n",
      "   2 1530 / 2728 loss = 0.1258\n",
      "   2 1540 / 2728 loss = 0.1257\n",
      "   2 1550 / 2728 loss = 0.1348\n",
      "   2 1560 / 2728 loss = 0.1277\n",
      "   2 1570 / 2728 loss = 0.1268\n",
      "   2 1580 / 2728 loss = 0.1262\n",
      "   2 1590 / 2728 loss = 0.1407\n",
      "   2 1600 / 2728 loss = 0.1363\n",
      "   2 1610 / 2728 loss = 0.1292\n",
      "   2 1620 / 2728 loss = 0.1258\n",
      "   2 1630 / 2728 loss = 0.1451\n",
      "   2 1640 / 2728 loss = 0.1287\n",
      "   2 1650 / 2728 loss = 0.1378\n",
      "   2 1660 / 2728 loss = 0.1304\n",
      "   2 1670 / 2728 loss = 0.1281\n",
      "   2 1680 / 2728 loss = 0.1298\n",
      "   2 1690 / 2728 loss = 0.1320\n",
      "   2 1700 / 2728 loss = 0.1276\n",
      "   2 1710 / 2728 loss = 0.1288\n",
      "   2 1720 / 2728 loss = 0.1296\n",
      "   2 1730 / 2728 loss = 0.1312\n",
      "   2 1740 / 2728 loss = 0.1494\n",
      "   2 1750 / 2728 loss = 0.1738\n",
      "   2 1760 / 2728 loss = 0.1330\n",
      "   2 1770 / 2728 loss = 0.1400\n",
      "   2 1780 / 2728 loss = 0.1425\n",
      "   2 1790 / 2728 loss = 0.2328\n",
      "   2 1800 / 2728 loss = 0.1313\n",
      "   2 1810 / 2728 loss = 0.1394\n",
      "   2 1820 / 2728 loss = 0.1265\n",
      "   2 1830 / 2728 loss = 0.2228\n",
      "   2 1840 / 2728 loss = 0.1397\n",
      "   2 1850 / 2728 loss = 0.1341\n",
      "   2 1860 / 2728 loss = 0.1426\n",
      "   2 1870 / 2728 loss = 0.1273\n",
      "   2 1880 / 2728 loss = 0.1275\n",
      "   2 1890 / 2728 loss = 0.1320\n",
      "   2 1900 / 2728 loss = 0.1331\n",
      "   2 1910 / 2728 loss = 0.1284\n",
      "   2 1920 / 2728 loss = 0.1286\n",
      "   2 1930 / 2728 loss = 0.1263\n",
      "   2 1940 / 2728 loss = 0.1373\n",
      "   2 1950 / 2728 loss = 0.1461\n",
      "   2 1960 / 2728 loss = 0.1471\n",
      "   2 1970 / 2728 loss = 0.1468\n",
      "   2 1980 / 2728 loss = 0.1302\n",
      "   2 1990 / 2728 loss = 0.1210\n",
      "   2 2000 / 2728 loss = 0.1287\n",
      "   2 2010 / 2728 loss = 0.1282\n",
      "   2 2020 / 2728 loss = 0.1288\n",
      "   2 2030 / 2728 loss = 0.1327\n",
      "   2 2040 / 2728 loss = 0.1312\n",
      "   2 2050 / 2728 loss = 0.1938\n",
      "   2 2060 / 2728 loss = 0.1734\n",
      "   2 2070 / 2728 loss = 0.1372\n",
      "   2 2080 / 2728 loss = 0.1331\n",
      "   2 2090 / 2728 loss = 0.1332\n",
      "   2 2100 / 2728 loss = 0.1331\n",
      "   2 2110 / 2728 loss = 0.1320\n",
      "   2 2120 / 2728 loss = 0.1334\n",
      "   2 2130 / 2728 loss = 0.1253\n",
      "   2 2140 / 2728 loss = 0.1352\n",
      "   2 2150 / 2728 loss = 0.1275\n",
      "   2 2160 / 2728 loss = 0.1307\n",
      "   2 2170 / 2728 loss = 0.1267\n",
      "   2 2180 / 2728 loss = 0.1349\n",
      "   2 2190 / 2728 loss = 0.1304\n",
      "   2 2200 / 2728 loss = 0.1396\n",
      "   2 2210 / 2728 loss = 0.1325\n",
      "   2 2220 / 2728 loss = 0.1410\n",
      "   2 2230 / 2728 loss = 0.1332\n",
      "   2 2240 / 2728 loss = 0.1467\n",
      "   2 2250 / 2728 loss = 0.1290\n",
      "   2 2260 / 2728 loss = 0.1150\n",
      "   2 2270 / 2728 loss = 0.1265\n",
      "   2 2280 / 2728 loss = 0.1199\n",
      "   2 2290 / 2728 loss = 0.1276\n",
      "   2 2300 / 2728 loss = 0.1227\n",
      "   2 2310 / 2728 loss = 0.1288\n",
      "   2 2320 / 2728 loss = 0.1283\n",
      "   2 2330 / 2728 loss = 0.1352\n",
      "   2 2340 / 2728 loss = 0.1345\n",
      "   2 2350 / 2728 loss = 0.1287\n",
      "   2 2360 / 2728 loss = 0.1487\n",
      "   2 2370 / 2728 loss = 0.1281\n",
      "   2 2380 / 2728 loss = 0.1281\n",
      "   2 2390 / 2728 loss = 0.1194\n",
      "   2 2400 / 2728 loss = 0.1263\n",
      "   2 2410 / 2728 loss = 0.1212\n",
      "   2 2420 / 2728 loss = 0.1310\n",
      "   2 2430 / 2728 loss = 0.1235\n",
      "   2 2440 / 2728 loss = 0.1285\n",
      "   2 2450 / 2728 loss = 0.1284\n",
      "   2 2460 / 2728 loss = 0.1216\n",
      "   2 2470 / 2728 loss = 0.1283\n",
      "   2 2480 / 2728 loss = 0.1289\n",
      "   2 2490 / 2728 loss = 0.1229\n",
      "   2 2500 / 2728 loss = 0.1185\n",
      "   2 2510 / 2728 loss = 0.1318\n",
      "   2 2520 / 2728 loss = 0.1252\n",
      "   2 2530 / 2728 loss = 0.1472\n",
      "   2 2540 / 2728 loss = 0.1254\n",
      "   2 2550 / 2728 loss = 0.1526\n",
      "   2 2560 / 2728 loss = 0.1268\n",
      "   2 2570 / 2728 loss = 0.1280\n",
      "   2 2580 / 2728 loss = 0.1240\n",
      "   2 2590 / 2728 loss = 0.1194\n",
      "   2 2600 / 2728 loss = 0.1222\n",
      "   2 2610 / 2728 loss = 0.1286\n",
      "   2 2620 / 2728 loss = 0.1205\n",
      "   2 2630 / 2728 loss = 0.1231\n",
      "   2 2640 / 2728 loss = 0.1291\n",
      "   2 2650 / 2728 loss = 0.1177\n",
      "   2 2660 / 2728 loss = 0.1226\n",
      "   2 2670 / 2728 loss = 0.1306\n",
      "   2 2680 / 2728 loss = 0.1274\n",
      "   2 2690 / 2728 loss = 0.1271\n",
      "   2 2700 / 2728 loss = 0.1189\n",
      "   2 2710 / 2728 loss = 0.1289\n",
      "   2 2720 / 2728 loss = 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [05:43<02:51, 171.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-22 05:33:37: epcoh =    2 , loss = 8.8900 , time = 169.31 s\n",
      "^_^-training data finished-^_^\n",
      "   3    0 / 2728 loss = 0.1288\n",
      "   3   10 / 2728 loss = 0.1159\n",
      "   3   20 / 2728 loss = 0.1302\n",
      "   3   30 / 2728 loss = 0.1170\n",
      "   3   40 / 2728 loss = 0.1335\n",
      "   3   50 / 2728 loss = 0.1268\n",
      "   3   60 / 2728 loss = 0.1257\n",
      "   3   70 / 2728 loss = 0.1201\n",
      "   3   80 / 2728 loss = 0.1244\n",
      "   3   90 / 2728 loss = 0.1313\n",
      "   3  100 / 2728 loss = 0.1308\n",
      "   3  110 / 2728 loss = 0.1331\n",
      "   3  120 / 2728 loss = 0.1223\n",
      "   3  130 / 2728 loss = 0.1187\n",
      "   3  140 / 2728 loss = 0.1236\n",
      "   3  150 / 2728 loss = 0.1199\n",
      "   3  160 / 2728 loss = 0.1215\n",
      "   3  170 / 2728 loss = 0.1164\n",
      "   3  180 / 2728 loss = 0.1383\n",
      "   3  190 / 2728 loss = 0.1195\n",
      "   3  200 / 2728 loss = 0.1197\n",
      "   3  210 / 2728 loss = 0.1191\n",
      "   3  220 / 2728 loss = 0.1230\n",
      "   3  230 / 2728 loss = 0.1176\n",
      "   3  240 / 2728 loss = 0.1257\n",
      "   3  250 / 2728 loss = 0.1346\n",
      "   3  260 / 2728 loss = 0.1346\n",
      "   3  270 / 2728 loss = 0.1376\n",
      "   3  280 / 2728 loss = 0.1434\n",
      "   3  290 / 2728 loss = 0.1189\n",
      "   3  300 / 2728 loss = 0.1329\n",
      "   3  310 / 2728 loss = 0.1278\n",
      "   3  320 / 2728 loss = 0.1303\n",
      "   3  330 / 2728 loss = 0.1272\n",
      "   3  340 / 2728 loss = 0.1178\n",
      "   3  350 / 2728 loss = 0.1442\n",
      "   3  360 / 2728 loss = 0.1266\n",
      "   3  370 / 2728 loss = 0.1267\n",
      "   3  380 / 2728 loss = 0.1237\n",
      "   3  390 / 2728 loss = 0.1161\n",
      "   3  400 / 2728 loss = 0.1253\n",
      "   3  410 / 2728 loss = 0.1241\n",
      "   3  420 / 2728 loss = 0.1176\n",
      "   3  430 / 2728 loss = 0.1166\n",
      "   3  440 / 2728 loss = 0.1155\n",
      "   3  450 / 2728 loss = 0.1222\n",
      "   3  460 / 2728 loss = 0.1325\n",
      "   3  470 / 2728 loss = 0.1208\n",
      "   3  480 / 2728 loss = 0.1204\n",
      "   3  490 / 2728 loss = 0.1155\n",
      "   3  500 / 2728 loss = 0.1224\n",
      "   3  510 / 2728 loss = 0.1213\n",
      "   3  520 / 2728 loss = 0.1216\n",
      "   3  530 / 2728 loss = 0.1226\n",
      "   3  540 / 2728 loss = 0.1253\n",
      "   3  550 / 2728 loss = 0.1247\n",
      "   3  560 / 2728 loss = 0.1347\n",
      "   3  570 / 2728 loss = 0.1160\n",
      "   3  580 / 2728 loss = 0.1231\n",
      "   3  590 / 2728 loss = 0.1180\n",
      "   3  600 / 2728 loss = 0.1226\n",
      "   3  610 / 2728 loss = 0.1236\n",
      "   3  620 / 2728 loss = 0.1346\n",
      "   3  630 / 2728 loss = 0.2673\n",
      "   3  640 / 2728 loss = 0.1319\n",
      "   3  650 / 2728 loss = 0.1439\n",
      "   3  660 / 2728 loss = 0.1285\n",
      "   3  670 / 2728 loss = 0.1462\n",
      "   3  680 / 2728 loss = 0.1221\n",
      "   3  690 / 2728 loss = 0.1294\n",
      "   3  700 / 2728 loss = 0.1197\n",
      "   3  710 / 2728 loss = 0.1206\n",
      "   3  720 / 2728 loss = 0.1272\n",
      "   3  730 / 2728 loss = 0.1166\n",
      "   3  740 / 2728 loss = 0.1261\n",
      "   3  750 / 2728 loss = 0.1244\n",
      "   3  760 / 2728 loss = 0.1164\n",
      "   3  770 / 2728 loss = 0.1243\n",
      "   3  780 / 2728 loss = 0.1240\n",
      "   3  790 / 2728 loss = 0.1186\n",
      "   3  800 / 2728 loss = 0.1128\n",
      "   3  810 / 2728 loss = 0.1146\n",
      "   3  820 / 2728 loss = 0.1239\n",
      "   3  830 / 2728 loss = 0.1107\n",
      "   3  840 / 2728 loss = 0.1192\n",
      "   3  850 / 2728 loss = 0.1217\n",
      "   3  860 / 2728 loss = 0.1086\n",
      "   3  870 / 2728 loss = 0.1097\n",
      "   3  880 / 2728 loss = 0.1207\n",
      "   3  890 / 2728 loss = 0.1254\n",
      "   3  900 / 2728 loss = 0.1292\n",
      "   3  910 / 2728 loss = 0.1073\n",
      "   3  920 / 2728 loss = 0.1204\n",
      "   3  930 / 2728 loss = 0.1490\n",
      "   3  940 / 2728 loss = 0.1197\n",
      "   3  950 / 2728 loss = 0.1241\n",
      "   3  960 / 2728 loss = 0.1206\n",
      "   3  970 / 2728 loss = 0.1274\n",
      "   3  980 / 2728 loss = 0.1438\n",
      "   3  990 / 2728 loss = 0.1266\n",
      "   3 1000 / 2728 loss = 0.1204\n",
      "   3 1010 / 2728 loss = 0.1424\n",
      "   3 1020 / 2728 loss = 0.1307\n",
      "   3 1030 / 2728 loss = 0.1145\n",
      "   3 1040 / 2728 loss = 0.1208\n",
      "   3 1050 / 2728 loss = 0.1218\n",
      "   3 1060 / 2728 loss = 0.1174\n",
      "   3 1070 / 2728 loss = 0.1207\n",
      "   3 1080 / 2728 loss = 0.1181\n",
      "   3 1090 / 2728 loss = 0.1198\n",
      "   3 1100 / 2728 loss = 0.1268\n",
      "   3 1110 / 2728 loss = 0.1272\n",
      "   3 1120 / 2728 loss = 0.1239\n",
      "   3 1130 / 2728 loss = 0.1323\n",
      "   3 1140 / 2728 loss = 0.1172\n",
      "   3 1150 / 2728 loss = 0.1113\n",
      "   3 1160 / 2728 loss = 0.1373\n",
      "   3 1170 / 2728 loss = 0.1215\n",
      "   3 1180 / 2728 loss = 0.1300\n",
      "   3 1190 / 2728 loss = 0.1309\n",
      "   3 1200 / 2728 loss = 0.1687\n",
      "   3 1210 / 2728 loss = 0.1314\n",
      "   3 1220 / 2728 loss = 0.1257\n",
      "   3 1230 / 2728 loss = 0.1216\n",
      "   3 1240 / 2728 loss = 0.1368\n",
      "   3 1250 / 2728 loss = 0.1180\n",
      "   3 1260 / 2728 loss = 0.1321\n",
      "   3 1270 / 2728 loss = 0.1566\n",
      "   3 1280 / 2728 loss = 0.1418\n",
      "   3 1290 / 2728 loss = 0.1058\n",
      "   3 1300 / 2728 loss = 0.1271\n",
      "   3 1310 / 2728 loss = 0.1136\n",
      "   3 1320 / 2728 loss = 0.1314\n",
      "   3 1330 / 2728 loss = 0.1142\n",
      "   3 1340 / 2728 loss = 0.1374\n",
      "   3 1350 / 2728 loss = 0.1188\n",
      "   3 1360 / 2728 loss = 0.1276\n",
      "   3 1370 / 2728 loss = 0.1201\n",
      "   3 1380 / 2728 loss = 0.1253\n",
      "   3 1390 / 2728 loss = 0.1245\n",
      "   3 1400 / 2728 loss = 0.1101\n",
      "   3 1410 / 2728 loss = 0.1350\n",
      "   3 1420 / 2728 loss = 0.1193\n",
      "   3 1430 / 2728 loss = 0.1178\n",
      "   3 1440 / 2728 loss = 0.1388\n",
      "   3 1450 / 2728 loss = 0.2174\n",
      "   3 1460 / 2728 loss = 0.1411\n",
      "   3 1470 / 2728 loss = 0.1317\n",
      "   3 1480 / 2728 loss = 0.1175\n",
      "   3 1490 / 2728 loss = 0.1182\n",
      "   3 1500 / 2728 loss = 0.1349\n",
      "   3 1510 / 2728 loss = 0.1185\n",
      "   3 1520 / 2728 loss = 0.1195\n",
      "   3 1530 / 2728 loss = 0.1166\n",
      "   3 1540 / 2728 loss = 0.1208\n",
      "   3 1550 / 2728 loss = 0.1270\n",
      "   3 1560 / 2728 loss = 0.1247\n",
      "   3 1570 / 2728 loss = 0.1266\n",
      "   3 1580 / 2728 loss = 0.1194\n",
      "   3 1590 / 2728 loss = 0.1432\n",
      "   3 1600 / 2728 loss = 0.1087\n",
      "   3 1610 / 2728 loss = 0.1148\n",
      "   3 1620 / 2728 loss = 0.1204\n",
      "   3 1630 / 2728 loss = 0.1227\n",
      "   3 1640 / 2728 loss = 0.1195\n",
      "   3 1650 / 2728 loss = 0.1389\n",
      "   3 1660 / 2728 loss = 0.1335\n",
      "   3 1670 / 2728 loss = 0.1139\n",
      "   3 1680 / 2728 loss = 0.1239\n",
      "   3 1690 / 2728 loss = 0.1132\n",
      "   3 1700 / 2728 loss = 0.1270\n",
      "   3 1710 / 2728 loss = 0.1211\n",
      "   3 1720 / 2728 loss = 0.1131\n",
      "   3 1730 / 2728 loss = 0.1165\n",
      "   3 1740 / 2728 loss = 0.1296\n",
      "   3 1750 / 2728 loss = 0.1274\n",
      "   3 1760 / 2728 loss = 0.1115\n",
      "   3 1770 / 2728 loss = 0.1220\n",
      "   3 1780 / 2728 loss = 0.1077\n",
      "   3 1790 / 2728 loss = 0.1165\n",
      "   3 1800 / 2728 loss = 0.1229\n",
      "   3 1810 / 2728 loss = 0.1179\n",
      "   3 1820 / 2728 loss = 0.1298\n",
      "   3 1830 / 2728 loss = 0.1132\n",
      "   3 1840 / 2728 loss = 0.1384\n",
      "   3 1850 / 2728 loss = 0.1249\n",
      "   3 1860 / 2728 loss = 0.1519\n",
      "   3 1870 / 2728 loss = 0.1228\n",
      "   3 1880 / 2728 loss = 0.1191\n",
      "   3 1890 / 2728 loss = 0.1191\n",
      "   3 1900 / 2728 loss = 0.1312\n",
      "   3 1910 / 2728 loss = 0.1246\n",
      "   3 1920 / 2728 loss = 0.1076\n",
      "   3 1930 / 2728 loss = 0.1430\n",
      "   3 1940 / 2728 loss = 0.1146\n",
      "   3 1950 / 2728 loss = 0.1225\n",
      "   3 1960 / 2728 loss = 0.1430\n",
      "   3 1970 / 2728 loss = 0.1249\n",
      "   3 1980 / 2728 loss = 0.1173\n",
      "   3 1990 / 2728 loss = 0.1189\n",
      "   3 2000 / 2728 loss = 0.1259\n",
      "   3 2010 / 2728 loss = 0.1132\n",
      "   3 2020 / 2728 loss = 0.1224\n",
      "   3 2030 / 2728 loss = 0.1074\n",
      "   3 2040 / 2728 loss = 0.1116\n",
      "   3 2050 / 2728 loss = 0.1211\n",
      "   3 2060 / 2728 loss = 0.1298\n",
      "   3 2070 / 2728 loss = 0.1193\n",
      "   3 2080 / 2728 loss = 0.1174\n",
      "   3 2090 / 2728 loss = 0.1210\n",
      "   3 2100 / 2728 loss = 0.1205\n",
      "   3 2110 / 2728 loss = 0.1126\n",
      "   3 2120 / 2728 loss = 0.1146\n",
      "   3 2130 / 2728 loss = 0.1229\n",
      "   3 2140 / 2728 loss = 0.1199\n",
      "   3 2150 / 2728 loss = 0.1319\n",
      "   3 2160 / 2728 loss = 0.1163\n",
      "   3 2170 / 2728 loss = 0.1239\n",
      "   3 2180 / 2728 loss = 0.1264\n",
      "   3 2190 / 2728 loss = 0.1211\n",
      "   3 2200 / 2728 loss = 0.1245\n",
      "   3 2210 / 2728 loss = 0.1079\n",
      "   3 2220 / 2728 loss = 0.1204\n",
      "   3 2230 / 2728 loss = 0.1310\n",
      "   3 2240 / 2728 loss = 0.1255\n",
      "   3 2250 / 2728 loss = 0.1277\n",
      "   3 2260 / 2728 loss = 0.1140\n",
      "   3 2270 / 2728 loss = 0.1135\n",
      "   3 2280 / 2728 loss = 0.1250\n",
      "   3 2290 / 2728 loss = 0.1091\n",
      "   3 2300 / 2728 loss = 0.1112\n",
      "   3 2310 / 2728 loss = 0.1205\n",
      "   3 2320 / 2728 loss = 0.1183\n",
      "   3 2330 / 2728 loss = 0.1211\n",
      "   3 2340 / 2728 loss = 0.1153\n",
      "   3 2350 / 2728 loss = 0.1107\n",
      "   3 2360 / 2728 loss = 0.1581\n",
      "   3 2370 / 2728 loss = 0.1210\n",
      "   3 2380 / 2728 loss = 0.1189\n",
      "   3 2390 / 2728 loss = 0.1200\n",
      "   3 2400 / 2728 loss = 0.1107\n",
      "   3 2410 / 2728 loss = 0.1214\n",
      "   3 2420 / 2728 loss = 0.1304\n",
      "   3 2430 / 2728 loss = 0.1339\n",
      "   3 2440 / 2728 loss = 0.1176\n",
      "   3 2450 / 2728 loss = 0.1282\n",
      "   3 2460 / 2728 loss = 0.1197\n",
      "   3 2470 / 2728 loss = 0.1201\n",
      "   3 2480 / 2728 loss = 0.1132\n",
      "   3 2490 / 2728 loss = 0.1178\n",
      "   3 2500 / 2728 loss = 0.1176\n",
      "   3 2510 / 2728 loss = 0.1118\n",
      "   3 2520 / 2728 loss = 0.1121\n",
      "   3 2530 / 2728 loss = 0.1071\n",
      "   3 2540 / 2728 loss = 0.1147\n",
      "   3 2550 / 2728 loss = 0.1223\n",
      "   3 2560 / 2728 loss = 0.1124\n",
      "   3 2570 / 2728 loss = 0.1140\n",
      "   3 2580 / 2728 loss = 0.1178\n",
      "   3 2590 / 2728 loss = 0.1141\n",
      "   3 2600 / 2728 loss = 0.1146\n",
      "   3 2610 / 2728 loss = 0.1333\n",
      "   3 2620 / 2728 loss = 0.1210\n",
      "   3 2630 / 2728 loss = 0.1207\n",
      "   3 2640 / 2728 loss = 0.1160\n",
      "   3 2650 / 2728 loss = 0.1162\n",
      "   3 2660 / 2728 loss = 0.1175\n",
      "   3 2670 / 2728 loss = 0.1210\n",
      "   3 2680 / 2728 loss = 0.1203\n",
      "   3 2690 / 2728 loss = 0.1100\n",
      "   3 2700 / 2728 loss = 0.1179\n",
      "   3 2710 / 2728 loss = 0.1201\n",
      "   3 2720 / 2728 loss = 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [08:35<00:00, 171.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-22 05:36:29: epcoh =    3 , loss = 7.9540 , time = 168.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
