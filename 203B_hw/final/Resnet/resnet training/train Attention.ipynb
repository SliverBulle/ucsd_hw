{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912267b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import data_generator as dg\n",
    "from data_generator import DenoisingDataset\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16199fc2-bb38-4404-8e8c-d68853a0a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c06d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    # Simulate command line arguments (replace these with your desired defaults)\n",
    "    sys.argv = ['ipykernel_launcher.py', '--model', 'DnCNN', '--batch_size', '4', '--train_data', './data/Train400', '--sigma', '4', '--epoch', '2', '--lr', '0.0005']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch DnCNN')\n",
    "parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n",
    "parser.add_argument('--batch_size', default=4, type=int, help='batch size')\n",
    "parser.add_argument('--train_data', default='./data/Train400', type=str, help='path of train data')\n",
    "parser.add_argument('--sigma', default=4, type=int, help='noise level')\n",
    "parser.add_argument('--epoch', default=2, type=int, help='number of train epoches')\n",
    "parser.add_argument('--lr', default=5e-4, type=float, help='initial learning rate for Adam')\n",
    "args = parser.parse_args()\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "class Residual_Blocks(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=64, padding = 1):\n",
    "        super(Residual_Blocks, self).__init__()\n",
    "        self.convx_1 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.Leakyrelu = nn.LeakyReLU(inplace=True)\n",
    "        self.BN = nn.BatchNorm2d(64)\n",
    "        self.convx_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.Leakyrelu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.BN(self.Leakyrelu(self.convx_1(x)))\n",
    "        out = self.BN(self.Leakyrelu(self.convx_2(x)))\n",
    "        return out\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, reduction=8):\n",
    "        super(Attention, self).__init__()\n",
    "        self.red = reduction\n",
    "        self.query = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.value = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.key = nn.Conv2d(in_channels=64, out_channels=64//self.red, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channels=64//self.red, out_channels=64, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        query = self.query(x).view(b, -1, h*w)\n",
    "        value = self.value(x).view(b, -1, h*w)\n",
    "        key = self.key(x).view(b, -1, h*w)\n",
    "        mul_1 = torch.bmm(query, value.transpose(1,2))\n",
    "        attention_weights = mul_1 / np.sqrt(64//self.red)\n",
    "        res_1 = nn.functional.softmax(attention_weights, dim=-1)\n",
    "        mul_2 = torch.bmm(res_1, key).view(b, -1, h, w)\n",
    "        out = self.out(mul_2)\n",
    "        return x + out\n",
    "\n",
    "        \n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, n_channels=64, image_channels=1):\n",
    "        super(DnCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(image_channels, n_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.attention = Attention()\n",
    "        self.act = nn.LeakyReLU(inplace=True)\n",
    "        self.out = nn.Sequential(*[Residual_Blocks() for _ in range(1)])\n",
    "        self.dn = nn.Conv2d(64, 1, kernel_size=3, padding=1, bias=True)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.act(self.attention(self.conv1(x)))\n",
    "        out = self.out(out)\n",
    "        dn = y - self.dn(out)\n",
    "        return dn\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.orthogonal_(m.weight)\n",
    "                print('init weight')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "                \n",
    "class sum_squared_error(_Loss):  # PyTorch 0.4.1\n",
    "    \"\"\"\n",
    "    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\n",
    "    The backward is defined as: input-target\n",
    "    \"\"\"\n",
    "    def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
    "        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\n",
    "        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0953c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Attempt to manually select a CUDA device\n",
    "try:\n",
    "    torch.cuda.current_device()\n",
    "    print(\"Current CUDA device:\", torch.cuda.get_device_name())\n",
    "except Exception as e:\n",
    "    print(\"Error accessing CUDA device:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b18590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n",
      "init weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 3 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(initial_epoch, n_epoch)):\n\u001b[1;32m     21\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(epoch)  \u001b[38;5;66;03m# step to the learning rate in this epcoh\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[43mdg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatagenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     xs \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     24\u001b[0m     xs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(xs\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)))  \u001b[38;5;66;03m# tensor of the clean patches, NXCXHXW\u001b[39;00m\n",
      "File \u001b[0;32m~/code/ucsd_hw/203B_hw/final/Resnet/resnet training/data_generator.py:135\u001b[0m, in \u001b[0;36mdatagenerator\u001b[0;34m(data_dir, verbose)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(file_list)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is done ^_^\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    134\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m discard_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size\u001b[38;5;241m*\u001b[39mbatch_size  \u001b[38;5;66;03m# because of batch namalization\u001b[39;00m\n\u001b[1;32m    137\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(data, \u001b[38;5;28mrange\u001b[39m(discard_n), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/numpy/lib/shape_base.py:597\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    594\u001b[0m     axis \u001b[38;5;241m=\u001b[39m (axis,)\n\u001b[1;32m    596\u001b[0m out_ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis) \u001b[38;5;241m+\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m--> 597\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_axis_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_ndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m shape_it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    600\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(shape_it) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out_ndim)]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.11/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = 0\n",
    "    model.train()\n",
    "    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\n",
    "    criterion = sum_squared_error()\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "         # device_ids = [0]\n",
    "         # model = nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "         # criterion = criterion.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = 1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[3, 6, 9], gamma=0.2)  # learning rates\n",
    "    for epoch in tqdm(range(initial_epoch, n_epoch)):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        xs = dg.datagenerator(data_dir=args.train_data)\n",
    "        xs = xs.astype('float32')/255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\n",
    "        DDataset = DenoisingDataset(xs, sigma)\n",
    "        DLoader = DataLoader(dataset=DDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "                loss = criterion(model(batch_y), batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
